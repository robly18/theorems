\documentclass{report}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{comment}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage{changepage}

%para desenhar árvores sintáticas
\usepackage{tikz}
\usepackage{tikz-qtree}
\tikzset{level distance=2em}

%para escrever pseudocódigo
\usepackage{listings}
\lstset{mathescape=true, basicstyle=\ttfamily}

\usepackage{graphicx}

\usepackage{cite}
\usepackage{makeidx}
\makeindex
\usepackage[nottoc]{tocbibind}

%para ter [[ ]]
\usepackage{stmaryrd}
\newcommand{\bbracket}[1]{\left\llbracket #1 \right\rrbracket}


\title{Lógica}
\author{}
\date{}

\newtheorem{prop}{Proposição}
\newtheorem*{prop*}{Proposição}
\newtheorem{teorema}{Teorema}
\newtheorem{lema}{Lema}

\theoremstyle{definition}
\newtheorem{definicao}{Definição}
\newtheorem*{definicao*}{Definição}

\theoremstyle{remark}
\newtheorem{obs}{Obs}

\addto\captionsportuguese{
	\renewcommand{\proofname}{Dem}
}


\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}

\renewcommand{\bf}[1]{\mathbf{#1}}

\newcommand{\F}{\mathrm{F}}
\newcommand{\T}{\mathrm{T}}

\newcommand{\lt}{\mathsf{T}}
\newcommand{\lf}{\mathsf{F}}

\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\fv}{fv}
\DeclareMathOperator{\ar}{Ar}


\DeclareMathOperator{\pnot}{\texttt{not}}
\newcommand{\pand}{\mathbin{\texttt{and}}}
\newcommand{\por}{\mathbin{\texttt{or}}}
\newcommand{\imply}{\mathbin{\Rightarrow}}
\newcommand{\implied}{\mathbin{\Leftarrow}}
\newcommand{\eqv}{\mathbin{\Leftrightarrow}}

\begin{document}
	\maketitle
	\newpage
	
	\tableofcontents
	\newpage
	
	\chapter{Lógica Proposicional}
	
	A lógica proposicional é um sistema que nos permite expressar raciocínios sobre afirmações e relações entre elas. Mais concretamente, é um sistema no qual as variáveis representam afirmações, que tomam o valor `verdadeiro' e `falso', juntamente com um conjunto de operações lógicas com as quais o leitor já estará familiar, por exemplo o `ou' e o `não'.
	
	Não é preciso procurar muito para descobrir que este sistema tem interesse e aplicações práticas. Qualquer linguagem de programação em uso regular terá este sistema contido no seu funcionamento. Tome-se o exemplo da linguagem Python. Nesta linguagem, as variáveis podem ser do tipo \texttt{bool}. Uma variável deste tipo toma um de dois valores: \texttt{True} e \texttt{False}. Existem também os operadores \texttt{and}, \texttt{or} e \texttt{not}, que recebem valores booleanos e retornam valores booleanos. O uso de parênteses permite-nos agrupar expressões, de modo a formar expressões mais complexas. Por exemplo, \texttt{(a and b) or not (b or not c)} é uma expressão válida em Python (assumindo que as variáveis \texttt{a}, \texttt{b} e \texttt{c} estão definidas e são do tipo \texttt{bool}.)
	
	Formalizaremos e estudaremos este sistema, usando-o como `caixa de areia' para nos preparar para a lógica de primeira ordem, que apesar de semelhante, é significativamente mais complexa.
	
	\section{Noções básicas (Preliminar)}
	
	Esta subsecção tem o sufixo `Preliminar' porque não é final. Isto é, o propósito desta subsecção é apenas dar intuição para o significado das coisas, antes de avançar para as definições secas e rigorosas.
	
	\bigskip
	
	Começamos por introduzir a noção de fórmula. Para os nossos propósitos, uma fórmula é uma expressão composta por variáveis, operadores lógicos, e parênteses. Por exemplo, a expressão $(a \land b) \lor \neg (b \lor \neg c)$ é um exemplo de uma fórmula. Fórmulas são normalmente denotadas por letras gregas minúsculas, e.g. `A fórmula $\varphi$'.
	
	As variáveis (neste caso, $a$, $b$ e $c$) podem tomar os valores de verdade `verdadeiro' e `falso', que aqui denotamos por $\lt$ e $\lf$.
	
	Existem diversos operadores lógicos conhecidos, mas no que se segue usaremos os operadores existentes no Python: $\pnot$, $\pand$ e $\por$. O leitor já deverá estar familiar com o comportamento destes, mas para evitar qualquer confusão, apresentamos as respetivas tabelas de verdade.
	
	\[\label{tabela:operadores}
	\begin{array}{|c|c||c|c|c|}
	\hline
	a & b & \pnot a & a \pand b & a \por b\\
	\hline
	\lt & \lt & \lf & \lt & \lt\\
	\lf & \lt & \lt & \lf & \lt\\
	\lt & \lf &     & \lf & \lt\\
	\lf & \lf &     & \lf & \lf\\
	\hline
	\end{array}
	\]
	
	Dada uma fórmula $\varphi$, podemos tentar `interpretá-la'. Isto é, se atribuirmos valores de verdade às variáveis podemos `substituir esses valores na fórmula' e avaliá-la.
	
	A título de exemplo, consideremos a fórmula $\varphi$ descrita acima.
	\[\varphi : (a \land b) \lor \neg (b \lor \neg c).\]
	
	Suponha-se que estabelecemos $a = \lt$ e $b = c = \lf$. Então, substituindo na fórmula (e escrevendo os operadores \textit{a la} Python), ficamos com
	\begin{gather*}
	(\lt \pand \lf) \por \pnot (\lf \por \pnot \lf)\\
	\lf \por \pnot (\lf \por \lt)\\
	\lf \por \pnot \lt\\
	\lf \por \lf\\
	\lf.
	\end{gather*}
	
	Podemos tornar o processo mais rigoroso descrevendo-o da seguinte forma: definimos uma \emph{valoração} como sendo uma função $\rho : \{\text{Variáveis}\} \to \{\lt, \lf\}$. Qualquer valoração pode ser estendida de forma natural para uma função
	\[{\overline\rho : \{\text{Fórmulas}\} \to \{\lt, \lf\}},\]
	da forma que descrevemos: substitui-se cada variável $x$ pelo valor de $\rho(x)$ e `faz-se as contas'.
	
	Existe uma classe de fórmulas que tem particular interesse, que são as chamadas tautologias.
	
	Uma fórmula $\varphi$ diz-se uma tautologia se para qualquer valoração $\rho$ temos $\overline\rho(\varphi) = \lt$. Isto é, $\varphi$ é sempre verdadeira.
	
	Parte do objetivo deste capítulo é caracterizar as tautologias, de modo a podermos indentificá-las em tempo finito. Claro que, no caso de lógica proposicional, isto já está feito: dada uma fórmula $\varphi$, para determinar se esta é uma tautologia, basta listar todas as valorações possíveis nas variáveis de $\varphi$ (há aqui um detalhe escondido, mas já voltamos a ele) e fazer as contas para todas elas. Se todas elas derem $\lt$, então $\varphi$ é uma tautologia. Caso contrário, não é!
	
	A razão pela qual procuramos outra forma de caracterizar estas fórmulas é porque eventualmente atacaremos o problema mais geral, onde as variáveis, em vez de serem só $\lt$ e $\lf$, podem ser elementos de um universo qualquer arbitrário: naturais, reais, grupos... Assim sendo, deixa de ser possível testar todos os casos possíveis. Como tal, passa a ser necessário um método `sintático', isto é, que manipule as afirmações sem as tentar interpretar. É daí que nasce a formalização de `demonstração', com fim a esclarecer a relação entre o que é verdade e o que é demonstrável.
	
	Voltando a lógica proposicional, consideremos o problema de `testar todos os casos possíveis' para valores das variáveis numa fórmula. Ao fazermos isto estamos a assumir implicitamente que existe um número finito de casos, mas repare-se que, da forma que o definimos, existe um número potencialmente infinito de valorações! De facto, existe um número infinito de variáveis (por exemplo, $x_1$, $x_2$, \dots) pelo que haverá também um número (não-contável!) infinito de valorações. Assim sendo, é impossível testá-las todas.
	
	Claro que, na prática, isso não é um problema. Fixa uma fórmula $\varphi$, só existe um número finito de variáveis a considerar, visto que apenas um número finito de variáveis consta em $\varphi$, e o valor dado a variáveis que não estas é irrelevante. Estamos habituados a tomar estes princípios como garantidos, mas aproveitá-los-emos como veículo para introduzir a noção de indução na estrutura.
	
	A observação essencial é que podemos decompor uma fórmula arbitrária em fórmulas mais pequenas. Por exemplo, a fórmula $\varphi : (a \land b) \lor \neg (b \lor \neg c)$ pode ser decomposta como $\varphi_1 \lor \varphi_2$, onde $\varphi_1$ e $\varphi_2$ são fórmulas mais pequenas do que a inicial. Isto permite-nos usar o princípio de indução (forte) no tamanho de uma fórmula, em que o passo de indução corresponde a separar uma fórmula como $\varphi_1 \lor \varphi_2$, $\varphi_1 \land \varphi_2$ ou $\neg \varphi_1$. Este processo pára nas fórmulas que não podem ser simplificadas mais: chamamos a estas de fórmulas atómicas, e são aquelas compostas por apenas uma variável. Por exemplo, $x$, ou $a$.
	
	Exemplificaremos o princípio, começando por definir indutivamente a noção de `variáveis em fórmula', e demonstrando, com base nesta definição, que, se $\rho$ é uma valoração e $\varphi$ é uma fórmula, $\overline\rho(\varphi)$ depende apenas do valor de $\rho$ nas variáveis em $\varphi$.
	
	\begin{definicao*}
	Seja $\varphi$ uma fórmula. Definimos $\var \varphi$ indutivamente da seguinte forma:
	\begin{itemize}
	\item Se $\varphi$ é da forma `$x$', então $\var \varphi = \{x\}$.
	
	\item Se $\varphi$ é da forma $\neg \varphi_1$, então $\var \varphi = \var \varphi_1$.
	
	\item Se $\varphi$ é da forma $\varphi_1 \lor \varphi_2$ ou $\varphi_1 \land \varphi_2$, então $\var \varphi = \var \varphi_1 \cup \var \varphi_2$.
	\end{itemize}
	\end{definicao*}
	
	\begin{prop*}
	Seja $\varphi$ uma fórmula, $\rho$ uma valoração. Então, $\overline \rho(\varphi)$ depende apenas de $\rho|_{\var \varphi}$. Por outras palavras, se $\rho$ e $\rho'$ são duas valorações tal que para todo $x \in \var \varphi$ se tem $\rho(x) = \rho'(x)$, então $\overline \rho(\varphi) = \overline \rho'(\varphi)$.
	\end{prop*}
	
	\begin{proof}
	Como dito antes, usaremos esta demonstração para exemplificar o conceito de indução em estrutura.
	
	O caso base são as fórmulas atómicas, $\varphi : x$. Como $\overline\rho(\varphi) = \rho(x)$ neste caso, de facto $\overline\rho(\varphi)$ depende apenas de $\rho(x)$, isto é, o valor que $\rho$ toma nos elementos de $\var \varphi = \{x\}$. A demonstração do caso base está terminada.
	
	Fazemos agora o passo de indução. Seja $\varphi$ uma fórmula não-atómica, e suponha-se que o enunciado é verdadeiro para todas as fórmulas mais pequenas do que $\varphi$. Então, partimos do princípio que $\varphi$ é da forma $\neg \varphi_1$, $\varphi_1 \lor \varphi_2$ ou $\varphi_1 \land \varphi_2$. Em qualquer um destes casos, as fórmulas nas quais decompomos $\varphi$ são estritamente mais pequenas do que $\varphi$, pelo que podemos usar nelas a hipótese de indução.
	
	Usemos o caso $\varphi_1 \lor \varphi_2$ como exemplo, sabendo que os outros dois casos são idênticos.
	
	Por hipótese de indução, $\overline\rho(\varphi_1)$ depende apenas de $\rho$ aplicado a $\var \varphi_1$. Da mesma forma, $\overline\rho(\varphi_2)$ depende apenas de $\rho$ aplicado a $\var \varphi_2$. Logo, $\overline\rho(\varphi) = \overline\rho(\varphi_1) \por \overline\rho(\varphi_2)$ depende apenas de $\rho$ aplicado a $\var \varphi_1 \cup \var \varphi_2 = \var \varphi$, o que conclui a demonstração.
	\end{proof}
	
	Voltemos ao problema de identificar tautologias. Existe um conceito mais geral, que é o conceito de `consequência semântica'. A ideia é que às vezes é possível afirmar, \emph{sob certas condições}, que uma fórmula é sempre verdadeira.
	
	Por exemplo, considere-se $\varphi : (a \land c) \lor b \lor (a \land \neg c)$. Esta fórmula não é uma tautologia: por exemplo, a valoração que leva tudo em $\lf$ faz com que esta fórmula fique falsa. No entanto, se uma valoração $\rho$ satisfaz $\overline\rho(a \lor b) = \lt$, então é fácil verificar que de certeza que $\overline\rho(\varphi) = \lt$. Dito de outra forma: sabendo que $\rho$ dá o valor $\lt$ a $a \lor b$, concluímos que $\rho$ dá o valor $\lt$ a $\varphi$. Às vezes, por abuso de linguagem, omitimos as referências a valorações e dizemos apenas `se $a \lor b$ então $\varphi$'.
	
	Antes de generalizarmos este conceito, introduzimos alguma linguagem para nos ajudar a expressar.
	
	\begin{definicao*}
	Seja $\gamma$ uma fórmula, $\rho$ uma valoração. Dizemos que $\rho$ satisfaz $\gamma$, denotado $\rho \Vdash \gamma$, se $\overline\rho(\gamma) = \lt$.
	
	Se em vez de uma fórmula tivermos um conjunto de fórmulas $\Gamma$ (normalmente usamos letras gregas maiúsculas para conjuntos de fórmulas) dizemos que $\rho$ satisfaz $\Gamma$ se $\rho$ satisfizer todas as fórmulas de $\Gamma$. Isto é, simbolicamente,
	\[\rho \Vdash \Gamma \text{ se para todo $\gamma \in \Gamma$ temos } \rho \Vdash \gamma.\]
	\end{definicao*}
	
	\begin{definicao*}
	Seja $\varphi$ uma fórmula e $\Gamma$ um conjunto de fórmulas. Então, dizemos que \emph{$\varphi$ é consequência semântica de $\Gamma$}, representado simbolicamente como
	\[\Gamma \vDash \varphi\]
	se para todas as valorações $\rho$ tal que $\rho \Vdash \Gamma$ temos $\rho \Vdash \varphi$.
	
	Por outras palavras, `se todas as afirmações em $\Gamma$ são verdade, concluímos que $\varphi$ é verdade'.
	
	Normalmente, quando $\Gamma$ é um conjunto finito, abreviamos a notação, omitindo chavetas. Por exemplo, se $\Gamma = \{\gamma_1, \gamma_2, \gamma_3\}$, escreveríamos $\gamma_1, \gamma_2, \gamma_3 \vDash \varphi$.\label{convencao:consequencia}
	
	Isto sugere uma notação para tautologia. De facto, $\varphi$ é uma tautologia sse $\emptyset \vDash \varphi$ (verifique). Escrevendo $\emptyset = \{\}$ e usando a convenção de omitir chavetas, chegamos à notação para tautologias: $\vDash \varphi$.
	
	Outra convenção que seguiremos será abreviar uniões usando vírgulas. Por exemplo, escrever $\Gamma, \alpha, \beta \vDash \varphi$ em vez de $\Gamma \cup \{\alpha, \beta\} \vDash \varphi$.
	\end{definicao*}
	
	A noção de consequência semântica é útil porque, juntamente com uma regra básica que iremos discutir agora, nos permite deduzir verdades novas a partir de verdades conhecidas.
	
	Suponhamos que temos uma afirmação da forma $a \lor b$. Isto significa que pelo menos um dos termos é verdadeiro. Assim sendo, se nos for dito que uma destas duas afirmações é falsa, concluímos que a outra é necessariamente verdadeira, isto é, $a$ falso implica $b$ verdadeiro. Por outras palavras, $a \lor b, \neg a \vDash b$.
	
	Substituindo $a$ por $\neg a$ e partindo do princípio que $\neg \neg a$ é a mesma coisa que $a$, chegamos à conclusão
	\[\neg a \lor b, a \vDash b.\]
	
	Assim sendo, a afirmação $\neg a \lor b$ representa, de alguma forma, `$a$ implica $b$'. Como tal, definimos o símbolo `$a \imply b$' como sinónimo de $\neg a \lor b$, e concluímos a chamada regra de \textit{modus ponens}:
	\[a \imply b, a \vDash b.\]
	
	Esta regra será a fundação do nosso cálculo dedutivo. De facto, veremos que existe um conjunto razoavelmente pequeno de tautologias $T$ tal que qualquer outra tautologia pode ser obtida a partir de aplicação repetida de \textit{modus ponens} a tautologias em $T$. A implicação tem um papel tão central, de facto, que quando definirmos fórmulas rigorosamente usaremos como base os operadores `não' e `implica'.
	
	\smallskip
	
	Terminamos esta secção preliminar com uma introdução ao conceito de metateorema.
	
	A noção de implicação e consequência semântica estão intrinsecamente ligadas. De facto, mostraremos que, em certo sentido, `$a \imply b$ sse $a \vDash b$'. Isto diz-se um metateorema porque relaciona duas `camadas' de verdade: relaciona uma verdade `dentro do sistema' ($a \imply b$) com uma verdade `sobre o sistema' ($a \vDash b$).
	
	\begin{prop*}
	(Metateorema da dedução) Seja $\Gamma$ um conjunto de fórmulas, $a$ e $b$ proposições. Então,
	\[\Gamma, a \vDash b \text{ sse } \Gamma \vDash a \imply b.\]
	\end{prop*}
	
	\begin{proof}\label{dem:mtd}
	($\rightarrow$) Suponha-se que $\Gamma, a \vDash b$. Desejamos mostrar $\Gamma \vDash a \imply b$, isto é, $\Gamma \vDash \neg a \lor b$. Assim sendo, vamos supor que $\rho$ é uma valoração tal que $\rho \Vdash \Gamma$ e mostraremos que $\rho \Vdash \neg a \lor b$.
	
	Existem dois casos: ou $\rho(a) = \lt$ ou $\rho(a) = \lf$.
	
	Se $\rho(a) = \lf$, então $\overline\rho(\neg a \lor b) = [(\pnot \lf) \por \rho(b)] = [\lt \por \rho(b)] = \lt$.
	
	Se $\rho(a) = \lt$, então temos que $\rho \Vdash \Gamma \cup \{a\}$, donde, como $\Gamma, a \vDash b$ por hipótese, concluímos que $\rho(b) = \lt$. Temos então que $\overline\rho(\neg a \lor b) = (\pnot \lt) \por \lt = \lt$, como desejado.
	
	($\leftarrow$) Suponha-se que $\Gamma \vDash a \imply b$. Seja $\rho$ uma valoração tal que $\rho \Vdash \Gamma \cup \{a\}$. Então, em particular, $\rho \Vdash \Gamma$, donde $\rho \Vdash a \imply b$. Sabemos também que $\rho \Vdash a$, pelo que concluímos $\rho \Vdash \{a \imply b, a\}$. Pela regra de \textit{modus ponens}, como $a \imply b, a \vDash b$, concluímos que $\rho \Vdash b$.
	
	Como partimos do princípio que $\rho$ era uma valoração arbitrária tal que $\rho \Vdash \Gamma \cup \{a\}$ e concluímos $\rho \Vdash b$, temos que $\Gamma \cup \{a\} \vDash b$.
	\end{proof}
	
	Este metateorema marca a primeira ocasião em que a nossa linguagem diz algo sobre si mesma. Frases auto-referenciais terão um papel central quando falarmos dos teoremas de incompletude de Gödel, mas isso terá que esperar até ao terceiro capítulo.
	
	\section{Semântica}
	
	O que se segue assume parcialmente que o leitor já leu a secção anterior. Apesar de não haver precedência explícita ou implícita, algumas das ideias essenciais já foram explicadas, e como tal não serão detalhadas novamente. Por outras palavras, o leitor poderá ler esta secção sem ter lido a anterior, mas se der por si perdido nas definições sem entender o seu significado poderá querer voltar atrás e ler a secção introdutória.
	
	\medskip
	
	Começamos por definir o conceito de fórmula proposicional.
	
	Fixe-se, primeiro, um conjunto, que usaremos em tudo o que se segue, chamado o conjunto das variáveis. Isto é apenas um conjunto infinito contável\footnote{Algo estranhamente, a cardinalidade exata deste conjunto é relevante. Bastantes argumentos que faremos de futuro necessitam explicitamente da contabilidade de $X$!} de símbolos $X$. Normalmente usamos variáveis como $x$, $y$, $p$, $q$, e permitimos a modificação de símbolos como a adição de apóstrofos ou asteriscos. Os símbolos $c$, $c'$, $c^*$ são considerados distintos. Usaremos a convenção que variáveis serão representadas por letras romanas minúsculas.
	
	\begin{obs}
	Há a necessidade de distinguir uma variável de uma `meta-variável'. Isto é: se falamos na variável $x$, poderá ser ambíguo se nos referimos ao elemento $x \in X$ ou se a letra $x$ é uma incógnita que pode significar uma variável arbitrária.
	
	Para evitar esta ambiguidade, representamos meta-variáveis a negrito: $\bf{x}$. Ou seja: $x$ é o elemento de $X$, enquanto que $\bf x$ é uma incógnita que pode ser substituída por qualquer variável: $x$, $y$, $z$, \dots
	\end{obs}
	
	Há quem defina, agora, fórmulas como sequências de símbolos. Isto parece ser uma definição intuitiva, visto que é assim que representamos fórmulas: sequências de caracteres. No entanto, visto que no futuro teremos que escrever programas que lêm e interpretam estas fórmulas, é mais conveniente definirmos fórmulas pelas respetivas árvores semânticas.\label{intro_syntatic_trees}
	
	Para esclarecer o que se entende por isto, considere-se a expressão $a \lor b$. Isto consiste de um operador (o operador `ou') aplicado a duas variáveis. Podemos representar isto como uma árvore na seguinte forma:
	
	\begin{center}
	\Tree [.\texttt{or} $a$ $b$ ]
	\end{center}
	
	Podemos, no entanto, considerar expressões mais complexas. Por exemplo, considere-se a expressão $(a \land b) \lor \neg (b \lor \neg c)$. Interpretada como uma árvore, esta expressão fica
	
	\begin{center}
	\Tree [.\texttt{or} [.\texttt{and} $a$ $b$ ] [.\texttt{not} [.\texttt{or} $b$ [.\texttt{not} $c$ ] ] ] ]
	\end{center}
	
	Para os nossos propósitos, é mais fácil manipular árvores do que sequências de caracteres. Assim sendo, é com base nesta perspetiva que definimos o conjunto das fórmulas proposicionais.
	
	\begin{definicao}
	Definimos o conjunto das fórmulas proposicionais $\F_p$ (sobre o conjunto $X$, que deixamos implícito) indutivamente.
	
	Qualquer variável $\bf x$ é uma fórmula.
	
	Se $\alpha$ e $\beta$ são fórmulas, ambos os seguintes são fórmulas:
	
	\begin{center}
	\Tree [.\texttt{not} $\alpha$ ]
	\hspace{3em}
	\Tree [.\texttt{implies} $\alpha$ $\beta$ ]
	\end{center}
	
	Esta forma de representar fórmulas não é particularmente eficiente tipograficamente, pelo que, no que se segue, continuaremos a representá-las com a notação linear $\neg \alpha$ e $\alpha \imply \beta$.
	
	Ao darmos nomes a fórmulas, associaremos o nome ao conteúdo usando dois pontos. Por exemplo, para associar o nome $\varphi$ à fórmula $a \lor b$, escreveremos $\varphi : a \lor b$.
	\end{definicao}
	
	\begin{definicao}
	Definimos uma valoração $\rho$ como uma função $\rho : X \to \{\lt,\lf\}$.
	
	Dada uma valoração $\rho$, definimos uma função $\overline\rho : \F_p \to \{\lt, \lf\}$ indutivamente:
	
	\begin{itemize}
	\item Se $\varphi : \bf x$, definimos $\overline\rho(\varphi) = \rho(\bf x)$.
	
	\item Se $\varphi : \neg \alpha$, definimos $\overline\rho(\varphi) = \pnot \overline\rho(\alpha)$.\footnote{Se o leitor não perceber o uso dos operadores $\pnot$ e $\por$, ver página \pageref{tabela:operadores}.}
	
	\item Se $\varphi : \alpha \imply \beta$, definimos $\overline\rho(\varphi) = (\pnot \overline\rho(\alpha)) \por \overline\rho(\beta)$.
	\end{itemize}
	
	Dada uma valoração $\rho$, dizemos que $\rho \Vdash \varphi$ ($\rho$ satisfaz $\varphi$) se $\overline\rho(\varphi) = \lt$. Se em vez de uma fórmula $\varphi$ tivermos um conjunto de fórmulas $\Gamma$, dizemos que $\rho \Vdash \Gamma$ se $\rho \Vdash \gamma$ para todo $\gamma \in \Gamma$.
	\end{definicao}
	
	\begin{definicao}\label{def:prop:consequenciasemantica}
	Seja $\varphi \in \F_p$, $\Gamma \subseteq \F_p$. Dizemos que $\Gamma \vDash \varphi$ (pronunciado `$\varphi$ é consequência semântica de $\Gamma$') se todas as valorações que satisfazem $\Gamma$ também satisfazem $\varphi$. Por outras palavras, se para todas as valorações $\rho$ tal que $\rho \Vdash \Gamma$ temos $\rho \Vdash \varphi$.
	
	Para abreviar a notação, seguimos algumas convenções, detalhadas na página \pageref{convencao:consequencia}, relacionadas com omissão de chavetas em expressões do género $\{a, b\} \vDash c$.
	
	Dizemos que $\varphi$ é uma tautologia se $\emptyset \vDash \varphi$. Isto pode ser representado como $\vDash \varphi$.
	\end{definicao}
	
	Começamos por apresentar algumas regras de dedução que nos ajudarão a mostrar que certas coisas são consequência semântica de outras.
	
	\begin{prop}
	A relação $\vDash$ é transitiva. Isto é:
	
	Sejam $\Gamma, \Phi \subseteq \F_p$ e $\psi \in \F_p$. Suponha-se que $\Gamma \vDash \varphi$ para todo $\varphi \in \Phi$ (Podemos representar isto como $\Gamma \vDash \Phi$) e que $\Phi \vDash \psi$. Então $\Gamma \vDash \psi$.
	\end{prop}
	
	\begin{proof} Suponha-se $\Gamma \vDash \Phi$ e $\Phi \vDash \psi$. Então, para mostrar $\Gamma \vDash \psi$ começamos por supor que $\rho$ é uma valoração tal que $\rho \Vdash \Gamma$. Então, por definição de $\Gamma \vDash \Phi$, temos que $\Gamma \vDash \varphi$ para todo $\varphi \in \Phi$. Como $\rho \Vdash \Gamma$, obtemos que $\rho \Vdash \varphi$ para todo $\varphi \in \Phi$, ou seja, que $\rho \Vdash \Phi$. Finalmente, por definição de $\Phi \vDash \psi$, concluímos que $\rho \Vdash \psi$, terminando a demonstração.
	\end{proof}
	
	\begin{prop}\label{prop:mp} (\textit{Modus ponens}) 
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então, $\alpha \imply \beta, \alpha \vDash \beta$.
	\end{prop}
	
	\begin{proof}
	Suponha-se que $\rho \Vdash \alpha \imply \beta$ e $\rho \Vdash \alpha$. Então, $(\pnot\overline\rho(\alpha))\por\overline\rho(\beta) = \lt$ e $\overline\rho(\alpha) = \lt$. Substituindo $\overline\rho(\alpha)$ por $\lt$ na primeira afirmação, ficamos com $(\pnot\lt)\por\overline\rho(\beta) = \lt$, isto é, $\lf \por \overline\rho(\beta) = \lt$. Para isto acontecer, é necessário que $\overline\rho(\beta) = \lt$, ou seja, $\rho \Vdash \beta$.
	\end{proof}
	
	\begin{prop}\label{prop:mtd}
	(Metateorema da dedução)
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então
	\[\Gamma, \alpha \vDash \beta \text{ sse } \Gamma \vDash \alpha \imply \beta.\]
	\end{prop}
	
	\begin{proof}
	Uma possível demonstração é semelhante à demonstração feita na página \pageref{dem:mtd}, com um pequeno detalhe. Essa demonstração foi feita para variáveis $a, b$ em vez de fórmulas $\alpha, \beta$. No entanto, substituindo $\rho(a)$ por $\overline\rho(\alpha)$ e $\rho(b)$ por $\overline\rho(\beta)$, a demonstração funciona sem modificações. Apresentamos, no entanto, uma demonstração ligeiramente diferente de ($\leftarrow$), que exemplifica as proposições acima.
	
	Suponha-se que $\Gamma \vDash \alpha \imply \beta$. É trivial reparar que $\Gamma, \alpha \vDash \Gamma$ (verifique). Por transitividade,
	\begin{equation}\label{eq:mtd:1}
	\Gamma, \alpha \vDash \alpha \imply \beta.
	\end{equation}
	
	Sabemos também que
	\begin{equation}\label{eq:mtd:2}
	\Gamma, \alpha \vDash \alpha.
	\end{equation}
	
	Juntando as afirmações \eqref{eq:mtd:1} e \eqref{eq:mtd:2}, obtemos que $\Gamma, \alpha \vDash \{\alpha \imply \beta, \alpha\}$. A regra de \textit{modus ponens} diz-nos que $\{\alpha \imply \beta, \alpha\} \vDash \beta$, pelo que, por transitividade, $\Gamma, \alpha \vDash \beta$, como desejado.
	\end{proof}
	
	O leitor poderá ter reparado que os símbolos $a \land b$ e $a \lor b$ não foram definidos, visto que na nossa definição de fórmula englobámos apenas as operações $\neg a$ e $a \imply b$. Visto que o uso dos operadores $\land$ e $\lor$ são convenientes, definimo-los por abreviatura. Ou seja, escrevemo-los em termos de `não's e `implica's, e sempre que escrevemos `ou' ou `e' substituímos mentalmente pela abreviatura estabelecida.
	
	Recordamos o leitor que $\overline\rho(\alpha \imply \beta) = (\pnot \overline\rho(\alpha)) \por \overline\rho(\beta)$, pelo que desejamos escrever os operadores $\por$ e $\pand$ como uma expressão semelhante a esta forma.
	
	Afirmamos que
	\begin{gather*}
	a \por b = (\pnot (\pnot a)) \por b\\
	a \pand b = \pnot ((\pnot a) \por (\pnot b)).
	\end{gather*}
	
	Pelo que estabelecemos as seguintes abreviaturas:
	
	\begin{itemize}
	\item Quando escrevemos $\alpha \lor \beta$, substituímos mentalmente por $\neg \alpha \imply \beta$.
	
	\item Quando escrevemos $\alpha \land \beta$, substituímos mentalmente por $\neg (\alpha \imply \neg \beta)$.
	
	\item Estabelecemos também a abreviatura $a \eqv b$ como $(a \imply b) \land (b \imply a)$ (que por sua vez é abreviatura de outra expressão, mas achamos por bem não expandir por completo).
	\end{itemize}
	
	Considere-se a noção de equivalência. Estamos habituados a que afirmações equivalentes sejam `a mesma coisa', na medida em que podemos substituir uma afirmação pela outra. Por exemplo, suponha-se que provamos que $\vDash \neg \neg \alpha \eqv \alpha$. (Faremos os detalhes mais tarde.) Agora, suponhamos que se deseja provar uma afirmação na qual aparece $\neg \neg \alpha$, por exemplo, $\beta \imply \neg \neg \alpha$. Seria agradável reduzir isto a mostrar que $\beta \imply \alpha$. Felizmente, verifica-se que este tipo de atalhos é admissível. É nisto que consiste o \emph{metateorema da substituição de equivalentes}.
	
	Antes de estudarmos a relação de equivalência, no entanto, vale a pena investigar o símbolo $\land$, visto que este consta na definição de $\eqv$.
	
	\begin{prop}\label{prop:conj:prop:sem}
	Sejam $\alpha, \beta \in \F_p$. Então, $\alpha, \beta \vDash \alpha \land \beta$ e $\alpha \land \beta \vDash \{\alpha, \beta\}$.
	\end{prop}
	
	\begin{proof}
	Para mostrar isto, basta mostrar que, se $\rho$ é uma valoração arbitrária, $\rho \Vdash \alpha \land \beta$ sse $\rho \Vdash \{\alpha, \beta\}$.
	
	De facto, $\rho \Vdash \alpha \land \beta$ sse $\overline\rho(\neg(\alpha \imply \neg \beta)) = \lt$ sse $\pnot ((\pnot \overline\rho(\alpha)) \por (\pnot \overline\rho(\beta))) = \lt$. É fácil verificar que isto acontece sse $\overline\rho(\alpha) = \overline\rho(\beta) = \lt$, ou seja, $\rho \Vdash \{\alpha, \beta\}$. Isto conclui a demonstração.
	\end{proof}
	
	Com a informação que já temos até agora, podemos começar a fazer demonstrações sem pensar tanto sobre valorações e casos possíveis. Exemplificamos demonstrando que $\alpha \eqv \neg \neg \alpha$.
	
	\begin{prop}\label{alphaeqvnegnegalpha}
	Para qualquer $\alpha, \beta \in \F_p$, $\vDash \alpha \eqv \neg \neg \alpha$.
	\end{prop}
	
	\begin{proof}
	Primeiro que tudo, é preciso observar a `meta-equivalência' trivial:
	\[\pnot \pnot x = x.\]
	
	Usando isto, concluímos que $\alpha \vDash \neg \neg \alpha$ e $\neg \neg \alpha \vDash \alpha$. Aplicando o metateorema da dedução a cada um destes, obtemos $\vDash \{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\}$. Usando a proposição \ref{prop:conj:prop:sem}  temos que $\{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\} \vDash (\alpha \eqv \neg \neg \alpha)$ (recorde-se da definição de equivalência por abreviatura), e por transitividade, como $\emptyset \vDash \{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\} \vDash (\alpha \eqv \neg \neg \alpha)$, temos $\emptyset \vDash \alpha \eqv \neg \neg \alpha$.
	\end{proof}
	
	Repare-se que a maior parte da demonstração que acabámos de fazer consistiu em passar de `$\alpha \vDash \beta$ e $\beta \vDash \alpha$' para `$\vDash \alpha \eqv \beta$'. Agora que sabemos que este tipo de raciocínios é válido, abreviaremos as nossas demonstrações na medida em que deixamos esta passagem para o leitor. Por exemplo:
	
	\begin{prop}
	Para qualquer $\alpha \in \F_p$, $\vDash (\alpha \land \beta) \eqv (\beta \land \alpha)$.
	\end{prop}
	
	\begin{proof}
	Sabemos que $\alpha \land \beta \vDash \{\alpha, \beta\}$. Como $\{\alpha, \beta\} = \{\beta, \alpha\}$, obtemos que $\{\alpha, \beta\} \vDash \beta \land \alpha$. Por transitividade, conclui-se $(\alpha \land \beta) \vDash (\beta \land \alpha)$. Reproduzindo a demonstração com o papel de $\alpha$ e $\beta$ trocado, damos a prova por concluída.
	\end{proof}
	
	Visto que já temos ferramentas para mostrar equivalências, passamos agora à proposição que nos permite fazer uso de equivalências. Antes de o podermos fazer, no entanto, precisamos de formalizar o que significa `substituir'.
	
	A ideia essencial é que pretendemos, numa fórmula $\varphi$, substituir certas instâncias de uma expressão $\alpha$ por uma outra expressão (presumivelmente equivalente) $\beta$. Por exemplo, passar de $\varphi : a \land \neg \neg (b \imply c)$ para $\psi : a \land (b \imply c)$, e depois possivelmente para $\theta : (b \imply c) \land a$. Para podermos manipular o conceito de substituição e demonstrar coisas sobre ele, precisamos de o definir de forma rigorosa. Como o leitor poderá estar à espera, fá-lo-emos de forma indutiva.
	
	\begin{definicao}
	Sejam $\varphi, \psi, \alpha, \beta \in \F_p$. Dizemos que \emph{$\psi$ é obtido de $\varphi$ por substituição de $\alpha$ por $\beta$} se:
	
	\begin{itemize}
	\item Caso base: Se $\varphi$ e $\psi$ são a mesma fórmula.
	
	\item Substituição: Se $\varphi : \alpha$ e $\psi : \beta$.
	
	\item Passo de indução (negação): Se todos as seguintes afirmações se verificarem:
	\begin{itemize}
	\item $\varphi$ é da forma $\neg \varphi_1$
	
	\item $\psi$ é da forma $\neg \psi_1$
	
	\item $\psi_1$ é obtido de $\varphi_1$ por substituição de $\alpha$ por $\beta$.
	\end{itemize}
	
	\item Passo de indução (implicação): Se todas as seguintes afirmações se verificarem:
	\begin{itemize}
	\item $\varphi$ é da forma $\varphi_1 \imply \varphi_2$
	
	\item $\psi$ é da forma $\psi_1 \imply \psi_2$
	
	\item $\psi_1$ é obtido de $\varphi_1$ por substituição de $\alpha$ por $\beta$
	
	\item $\psi_2$ é obtido de $\varphi_2$ por substituição de $\alpha$ por $\beta$.
	\end{itemize}
	\end{itemize}
	\end{definicao}
	
	Note-se que esta definição é particularmente complexa, e aplicá-la na prática é chato. Claro que isto corresponde simplesmente à noção intuitiva de `pegar nalguns $\alpha$, apagá-los, e escrever $\beta$ no seu lugar', pelo que, ao afirmar que duas fórmulas são obtidas uma da outra por substituição, não nos daremos ao trabalho de fazer uma inteira justificação com base nestes casos todos. No entanto, se o leitor estiver confuso com a definição é recomendado tentar aplicá-la a alguns exemplos de substituição de fórmulas.
	
	Podemos finalmente passar à demonstração de:
	
	\begin{prop}
	(Metateorema de substituição de equivalentes) Sejam $\varphi, \psi, \alpha$ e $\beta$ fórmulas em $\F_p$ e $\Gamma \subseteq \F_p$. Suponha-se que $\Gamma \vDash \alpha \eqv \beta$ e que $\psi$ é obtido de $\varphi$ por substituição de $\alpha$ por $\beta$. Então,
	\[\Gamma \vDash \varphi \eqv \psi.\]
	\end{prop}
	
	\begin{proof}
	Como esperado, fazemos uma prova por indução usando a definição de $\psi$ ser obtido de $\varphi$ por substituição.
	
	\smallskip
	\textbf{Casos base:}
	
	Se $\varphi$ e $\psi$ são a mesma fórmula, então basta reparar que $\varphi \eqv \varphi$ é uma tautologia (deixamos a demonstração disto para o leitor).
	
	Se $\varphi : \alpha$ e $\psi : \beta$, a afirmação $\Gamma \vDash \varphi \eqv \psi$ é dada como hipótese.
	
	\smallskip
	\textbf{Passo de indução:}
	
	Se $\varphi : \neg \varphi_1$ e $\psi : \neg \psi_1$, onde $\psi_1$ é obtido de $\varphi_1$ por substituição, usamos a hipótese de indução para afirmar que $\Gamma : \varphi_1 \eqv \psi_1$. Basta agora mostrar que $\varphi_1 \eqv \psi_1 \vDash (\neg \varphi_1) \eqv (\neg \psi_1)$, e a conclusão decorre por transitividade. Deixamos a demonstração deste facto auxiliar como exercício para o leitor, de modo a não quebrar o raciocínio.
	
	Se $\varphi : \varphi_1 \imply \varphi_2$ e $\psi : \psi_1 \imply \psi_2$, onde $\psi_1$ e $\psi_2$ são obtidos por substituição a partir de $\varphi_1$ e $\varphi_2$, respetivamente, podemos aplicar a hipótese de indução para afirmar que $\Gamma \vDash \varphi_1 \eqv \psi_1$ e $\Gamma \vDash \varphi_2 \eqv \psi_2$. Por transitividade, é suficiente mostrar que $\{\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2\} \vDash (\varphi_1 \imply \varphi_2) \eqv (\psi_1 \imply \psi_2)$.
	
	Faremos a demonstração deste último facto aplicando repetidamente o metateorema da dedução. Mostraremos que
	\begin{equation}\label{eq:mse:1}
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2, \varphi_1 \imply \varphi_2, \psi_1 \vDash \psi_2.
	\end{equation}
	
	Ora, repare-se que $\varphi_1 \eqv \psi_1 \vDash \psi_1 \imply \varphi_1$, como se pode mostrar recorrendo à definição por abreviatura de $\eqv$ e a propriedades essenciais de $\land$ (proposição \ref{prop:conj:prop:sem}). De igual modo, $\varphi_2 \eqv \psi_2 \vDash \varphi_2 \imply \psi_1$. Assim sendo,
	\[\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2, \varphi_1 \imply \varphi_2, \psi_1 \vDash \psi_1, \psi_1 \imply \varphi_1, \varphi_1 \imply \varphi_2, \varphi_2 \imply \psi_2.\]
	
	Aplicando repetidamente modus ponens, chegamos à conclusão que desta última sequência de termos se conclui $\psi_2$, pelo que, por transitividade, a equação \eqref{eq:mse:1} é verdadeira. Aplicando agora o metateorema da dedução duas vezes, conclui-se
	\[
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2  \vDash (\varphi_1 \imply \varphi_2) \imply (\psi_1 \imply \psi_2).
	\]
	
	Repetindo o argumento com o papel de $\varphi$ e $\psi$ trocados, obtemos a implicação inversa, pelo que aplicando a proposição \ref{prop:conj:prop:sem} concluímos, finalmente,
	\[
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2  \vDash (\varphi_1 \imply \varphi_2) \eqv (\psi_1 \imply \psi_2).
	\]
	\end{proof}
	
	Mostramos agora um conjunto de aplicações do metateorema de substituição de equivalentes que nos será útil no futuro, quando precisarmos do operador $\lor$.
	
	Começamos por realçar duas propriedade com a qual o leitor já estará familiar: o princípio do contrarrecíproco e as leis de deMorgan.
	
	\begin{prop}
	(Contrarrecíproco)
	
	Se $\alpha$ e $\beta$ são fórmulas, temos a seguinte equivalência:
	
	\begin{equation}
	\vDash (\alpha \imply \beta) \eqv (\neg \beta \imply \neg \alpha)
	\end{equation}
	\end{prop}
	
	\begin{proof}
	Faremos esta demonstração `à bruta', usando o nosso conhecimento dos operadores $\pnot$ e $\por$.
	
	Sabemos que, se $\rho$ é uma valoração,
	\begin{align*}
	\rho \Vdash (\alpha \imply \beta) &\text{ sse } (\pnot \overline\rho(\alpha)) \por \overline\rho(\beta) = \lt\\
	&\text{ sse } (\pnot \pnot \overline\rho(\beta)) \por (\pnot \overline\rho(\alpha)) = \lt\\
	&\text{ sse } (\pnot \overline\rho(\neg \beta)) \por \overline\rho(\neg \alpha) = \lt\\
	&\text{ sse } \rho \Vdash (\neg \beta \imply \neg \alpha).
	\end{align*}
	
	Isto mostra que $\alpha \imply \beta \vDash \neg \beta \imply \neg \alpha$ e vice-versa, o que, através de duas aplicações do metateorema da dedução e uso de propriedades do operador $\land$, nos permite chegar à conclusão que
	
	\begin{equation*}
	\vDash (\alpha \imply \beta) \eqv (\neg \beta \imply \neg \alpha),
	\end{equation*}
	como desejado.
	\end{proof}
	
	\begin{prop}\label{demorgan}
	(Leis de deMorgan)
	
	Se $\alpha$ e $\beta$ são fórmulas, temos as seguintes equivalências:
	
	\begin{gather}
	\vDash \neg (\alpha \land \beta) \eqv (\neg \alpha \lor \neg \beta)\label{demorgan1}\\
	\vDash \neg (\alpha \lor \beta) \eqv (\neg \alpha \land \neg \beta)\label{demorgan2}
	\end{gather}
	\end{prop}
	
	\begin{proof}
	Recordemo-nos das definições por abreviatura de $\lor$ e $\land$.
	
	\begin{gather}
	\alpha \land \beta \text{ é o mesmo que } \neg (\alpha \imply \neg \beta)\\
	\alpha \lor \beta \text{ é o mesmo que } (\neg \alpha \imply \beta)
	\end{gather}
	
	Substituindo nas expressões \eqref{demorgan1} e \eqref{demorgan2}, fica claro que a demonstração é mera aplicação repetida do metateorema da substituição de equivalentes usando a equivalência $\alpha \eqv \neg \neg \alpha$.
	\end{proof}
	
	As leis de deMorgan encontram alguma utilidade em provar coisas sobre o operador $\lor$, visto que neste momento só temos informação sobre $\land$.
	
	\begin{lema}\label{lemaou}
	Se $\alpha, \beta$ e $\varphi$ são fórmulas, a seguinte fórmula é uma tautologia:
	\begin{equation}\label{eq:lemaou}
	\vDash (\alpha \imply \varphi) \imply ((\beta \imply \varphi) \imply ((\alpha \lor \beta) \imply \varphi))
	\end{equation}
	\end{lema}
	
	\begin{proof}
	Usando o princípio do contrarrecíproco e o metateorema da substituição de equivalentes, conclui-se que para provar \eqref{eq:lemaou} é necessário e suficiente mostrar
	\begin{equation}
	\vDash (\neg \varphi \imply \neg \alpha) \imply ((\neg \varphi \imply \neg \beta) \imply (\neg \varphi \imply \neg (\alpha \lor \beta))),
	\end{equation}
	e uma aplicação das leis de deMorgan diz-nos que isto é equivalente a mostrar
	\begin{equation}
	\vDash (\neg \varphi \imply \neg \alpha) \imply ((\neg \varphi \imply \neg \beta) \imply (\neg \varphi \imply (\neg \alpha \land \neg \beta))).
	\end{equation}
	
	O problema está agora reduzido a aplicação generosa do metateorema da dedução, \textit{modus ponens} e propriedades elementares (proposição \ref{prop:conj:prop:sem}) do operador $\land$.
	\end{proof}
	
	\section{Sintática}
	
	Como explicado na secção preliminar, o nosso objetivo final será arranjar uma forma sistemática de descobrir que afirmações são tautologias. Um pouco mais geralmente, dado um conjunto de afirmações $\Gamma$ (`hipóteses'), queremos arranjar um método para decidir, dada uma fórmula $\varphi$, se $\Gamma \vDash \varphi$. Para mais, queremos fazer isto sem recorrer a valorações, visto que, quando estivermos a trabalhar num contexto mais geral do que o cálculo proposicional, não teremos a vantagem de universos finitos.
	
	Para o fazer, formalizamos a noção de demonstração, baseando-nos na nossa experiência a escrever provas.
	
	Ao redigirmos provas geralmente escrevemos coisas linearmente (isto é, uma prova é uma sequência de afirmações), em que novas afirmações são justificadas com base em conhecimento prévio. Algumas afirmações são hipóteses (1) do teorema que estamos a tentar provar, algumas delas são afirmações que são simplesmente logicamente válidas (2), e algumas são consequências de afirmações anteriores (3). Para exemplificar, considere-se a seguinte demonstração em linguagem natural. Os passos estão anotados consoante a qual destes tipos de afirmação correspondem.
	
	\medskip
	
	\textbf{Proposição:} Sejam $a$ e $b$ valores de verdade tal que $a \por b = \lt$ e $b = \lf$. Então, $a = \lt$.
	
	\begin{adjustwidth}{1cm}{}
	1: Hipótese: $a \por b = \lt$ (1)\\
	2: Axioma: Se $a \por b = \lt$ então $a = \lt$ ou $b = \lt$ (2)\\
	3: Como consequência das linhas 1 e 2: $a = \lt$ ou $b = \lt$. (3)\\
	4: Hipótese: $b = \lf$ (1)\\
	5: Axioma: Se sabemos $a = \lt$ ou $b = \lt$, mas $b \neq \lt$, então $a = \lt$ (2)\\
	6: Como consequência das linhas 3 e 4: $a = \lt$. (3)
	\end{adjustwidth}
	
	\medskip
	
	Claro que isto pressupõe uma noção de `axiomas', ou pelo menos, afirmações tomadas como verdadeiras sem justificação. Uma escolha óbvia para o nosso caso seria tomar como axiomas todas as tautologias, mas é precisamente o problema de encontrar as tautologias que estamos a tentar resolver! No entanto, o seu uso é instrutivo visto que, apesar de tudo, o problema de encontrar consequências semânticas não fica trivializado. Isto é, a seguinte questão ainda requer algum trabalho:
	
	\begin{center}
	Sejam $\Gamma \subseteq \F_p$ e $\varphi \in \F_p$. Será possível construir uma demonstração cuja conclusão seja $\varphi$, usando como axiomas as tautologias e como hipóteses as fórmulas em $\Gamma$?
	\end{center}
	
	Em breve formalizaremos a noção de demonstração, mas a ideia principal é que criaremos um sistema em que algumas afirmações podem ser demonstradas e outras não. O objetivo é que as afirmações que podem ser demonstradas são exatamente aquelas que são verdadeiras. Ou seja, se demonstramos uma afirmação, ela tem que ser verdadeira (chamamos a isto correção), e se uma afirmação é verdadeira terá que existir uma prova dela (chamamos a isto completude). Em lógica, é normalmente bastante fácil assegurar correção de sistemas de demonstração --- basta certificarmo-nos que todos os passos individuais estão corretos ---, mas provar que qualquer afirmação verdadeira pode ser demonstrada é uma história completamente diferente!
	
	De agora em diante, tomaremos como conjunto de axiomas (chamamos a este conjunto $A$) as tautologias. De futuro, veremos que este conjunto pode ser drasticamente reduzido.
	
	\textbf{Se o leitor deseja ver os axiomas finais,} poderá avançar para a página \pageref{prop:axiomasfinais}. Não há perda de continuidade em ler esta secção mesmo sabendo os axiomas, tendo conhecimento que em qualquer momento que invocamos uma tautologia como axioma, podemos substituir essa invocação por uma demonstração (com base nos axiomas finais) da fórmula em questão.
	
	\begin{definicao}
	Seja $\Gamma \subseteq \F_p$. Uma demonstração com base em $\Gamma$, ou demonstração que tem $\Gamma$ como hipóteses, é uma sequência finita
	\[(\varphi_1, j_1), (\varphi_2, j_2), \dots, (\varphi_n, j_n)\]
	onde cada $\varphi_i$ é uma fórmula proposicional, e o respetivo $j_i$ (que simboliza a justificação de $\varphi_i$) satisfaz as seguintes regras:
	
	\begin{itemize}
	\item Cada $j_i$ é um símbolo da forma \texttt{Ax}, \texttt{Hip} ou $\texttt{MP}_{ab}$, com $a,b \in \N$
	
	\item Se $j_i = \texttt{Ax}$ é necessário que $\varphi_i \in A$, onde $A$ é o conjunto de axiomas. Recordamos que, neste momento, $A$ é para nós o conjunto das tautologias.
	
	\item Se $j_i = \texttt{Hip}$ é necessário que $\varphi_i \in \Gamma$
	
	\item Se $j_i = \texttt{MP}_{ab}$, então $a, b < i$ e $\varphi_a$ é a fórmula $\varphi_b \imply \varphi_i$.
	
	Por outras palavras, se $\varphi_a$ é da forma $\alpha \imply \beta$ e $\varphi_b$ é a fórmula $\alpha$, então podemos concluir a fórmula $\beta$, com a justificação $\texttt{MP}_{ab}$ (\textit{Modus ponens}, com hipóteses $a$ e $b$).
	\end{itemize}
	\end{definicao}
	
	\begin{definicao}
	Dizemos que $\varphi \in \F_p$ é um teorema de $\Gamma \subseteq \F_p$, denotado
	\[\Gamma \vdash \varphi\]
	se existe uma demonstração com base em $\Gamma$ cuja última afirmação seja $\varphi$.
	\end{definicao}
	
	Antes de começarmos a mostrar propriedades deste sistema, vamos ver algumas demonstrações para entender como é que o sistema funciona.
	
	\begin{prop*}
	Se $\alpha \in \F_p$ então $\vdash \alpha \eqv \neg \neg \alpha$.
	\end{prop*}
	\begin{proof}
	Recordamos primeiro o leitor da convenção de omissão de chavetas, segundo a qual a afirmação $\vdash \alpha \eqv \neg \neg \alpha$ é abreviatura de $\{\} \vdash \alpha \eqv \neg \neg \alpha$, ou seja, `$\alpha \eqv \neg \neg \alpha$ pode ser provado sem hipóteses'.
	
	Pela proposição \ref{alphaeqvnegnegalpha}, a afirmação $\alpha \eqv \neg \neg \alpha$ é uma tautologia. Assim sendo, temos uma demonstração particularmente concisa:
	\[(\alpha \eqv \neg \neg \alpha, \texttt{Ax}).\]
	\end{proof}
	
	\begin{prop*}
	Se $\alpha, \beta, \gamma \in \F_p$ então $\alpha \imply (\beta \imply \gamma), \alpha \land \beta \vdash \gamma$.
	\end{prop*}
	\begin{proof}
	Apresentamos a seguinte demonstração, que não é a mais direta. De facto, como veremos em breve, qualquer demonstração com um número finito $n$ de hipóteses pode ser feito de forma extremamente expedita em apenas $2n+1$ passos. No entanto, as tautologias necessárias para o fazer podem ser complicadas, pelo que apresentamos uma prova que usa apenas tautologias evidentes.
	
	\begin{align*}
	&\alpha \imply (\beta \imply \gamma) &\texttt{Hip}\\
	&\alpha \land \beta &\texttt{Hip}\\
	&\alpha \land \beta \imply \alpha &\texttt{Ax}&&\text{Aplicar MTD à prop \ref{prop:conj:prop:sem}}\\
	&\alpha &\texttt{MP}_{3,2}\\
	&\beta \imply \gamma &\texttt{MP}_{1, 4}\\
	&\alpha \land \beta \imply \beta &\texttt{Ax}&&\text{Aplicar MTD à prop \ref{prop:conj:prop:sem}}\\
	&\beta &\texttt{MP}_{6,2}\\
	&\gamma &\texttt{MP}_{5,7}
	\end{align*}
	\end{proof}
	
	\bigskip
	
	Como mencionado anteriormente, há duas coisas que queremos que a nossa relação $\vdash$ satisfaça. Queremos que se $\Gamma \vdash \varphi$ então $\Gamma \vDash \varphi$ (correção), e queremos que se $\Gamma \vDash \varphi$ então $\Gamma \vdash \varphi$ (completude). A primeira propriedade é a mais fácil de verificar, e como tal, será a primeira que vamos provar.
	
	\begin{prop}\label{prop:correcao} (Correção do cálculo proposicional)
	Seja $\Gamma \subseteq \F_p$, $\varphi \in \F_p$. Suponha-se que $\Gamma \vdash \varphi$. Então, $\Gamma \vDash \varphi$.
	\end{prop}
	
	\begin{proof}
	Se $\Gamma \vdash \varphi$, existe uma demonstração de $\varphi$ com base em $\Gamma$. Suponha-se que esta é dada por $(\varphi_1, j_1), \dots, (\varphi_n, j_n)$. Mostraremos por indução que todos os $\varphi_i$ são consequência semântica de $\Gamma$, e portanto, em particular, $\Gamma \vDash \varphi_n$, ou seja, $\Gamma \vDash \varphi$.
	
	Faremos esta prova usando o princípio de indução forte:
	
	\begin{center}
	Seja $S$ um subconjunto dos naturais. Suponha-se que se prova a seguinte afirmação para todo $n \in \N$:
	
	Se o conjunto $\N \cap \left[0,n\right[$ está contido em $S$, então $n \in S$.
	
	O princípio de indução forte diz-nos que, neste caso, $S = \N$.\footnote{Para justificar este princípio: suponha-se que $S \neq \N$. Então, $\N \setminus S$ é não-vazio. Qualquer subconjunto não-vazio dos naturais tem mínimo; seja, então, $n$ o mínimo de $\N \setminus S$. Por definição de mínimo, temos que $\N \cap \left[0, n\right[ \subseteq S$, e, por hipótese, isto implica que $n \in S$. Contradição, pelo que $\N \setminus S$ tem que ser vazio e portanto $S = \N$.} Note-se que não é necessário provar caso base.
	\end{center}
	
	Seja $i$ um índice tal que para todo $i' < i$ se tem $\Gamma \vDash \varphi_{i'}$. Então, mostramos que $\Gamma \vDash \varphi_i$. A prova consiste em examinar a justificação de $\varphi_i$, isto é, $j_i$.
	
	\begin{itemize}
	\item Se $j_i = \texttt{Hip}$, então $\varphi_i \in \Gamma$, donde $\Gamma \vDash \varphi_i$ trivialmente.
	
	\item Se $j_i = \texttt{Ax}$, então $\varphi_i \in A$, donde $\varphi_i$ é uma tautologia. Isto claramente implica $\Gamma\vDash\varphi_i$.
	
	\item Se $j_i = \texttt{MP}_{ab}$, basta usar a transitividade da consequência semântica. Por hipótese, $\Gamma \vDash \{\varphi_a, \varphi_b\}$. Por definição de demonstração, $\varphi_a$ é a fórmula $\varphi_b \imply \varphi_i$. Pela regra de \textit{modus ponens}, $\{\varphi_b \imply \varphi_i, \varphi_b\} \vDash \varphi_i$, pelo que, por transitividade, $\Gamma \vDash \varphi_i$, como desejado.
	\end{itemize}
	\end{proof}
	
	Iniciamos agora a demonstração da completude do cálculo. Fazemos primeiro notar que, sob certas condições, esta é uma trivialidade:
	
	\begin{prop}
	Sejam $\Gamma \subseteq \F_p$ e $\varphi \in \F_p$ tal que $\Gamma \vDash \varphi$. Suponha-se, em adição, que $\Gamma = \{\gamma_1, \dots, \gamma_n\}$ é finito. Então, $\Gamma \vdash \varphi$.
	\end{prop}
	
	\begin{proof}
	Por aplicação repetida do metateorema de dedução, sabendo que $\Gamma \vDash \varphi$ obtemos que $\vDash \gamma_1 \imply (\gamma_2 \imply \dots (\gamma_n \imply \varphi) \dots )$. Assim sendo, esta última fórmula é uma tautologia, e então um axioma. Como tal, considere-se a seguinte demonstração, com base em $\Gamma$:
	\begin{align*}
	&\gamma_1 \imply (\gamma_2 \imply (\gamma_3 \imply \dots (\gamma_n \imply \varphi) \dots )) &&\texttt{Ax}\\
	&\gamma_1 &&\texttt{Hip}\\
	&\gamma_2 \imply (\gamma_3 \imply \dots (\gamma_n \imply \varphi) \dots ) &&\texttt{MP}_{12}\\
	&\gamma_2 &&\texttt{Hip}\\
	&\gamma_3 \imply ( \dots (\gamma_n \imply \varphi) \dots)  &&\texttt{MP}_{34}\\
	&\vdots&&\vdots\\
	&\gamma_n \imply \varphi &&\texttt{MP}_{\dots}\\
	&\gamma_n &&\texttt{Hip}\\
	&\varphi &&\texttt{MP}_{\dots}
	\end{align*}
	
	Isto é uma demonstração com todas as suas hipóteses em $\Gamma$, cuja conclusão é $\varphi$, pelo que $\Gamma \vdash \varphi$ como desejado.
	\end{proof}
	
	Isto mostra que o maior obstáculo para a completude é a possibilidade de haver infinitas hipóteses.
	
	Para demonstrar a completude no caso geral, uma demonstração direta não é um bom plano de ataque. De facto, para mostrar que $\Gamma \vDash \varphi$ implica $\Gamma \vdash \varphi$ seria necessário partir de uma hipótese sobre o conjunto das valorações, e, a partir disso, construir uma demonstração. O problema é que as valorações não nos dizem grande coisa sobre como poderíamos construir a demonstração.
	
	Recorremos então ao princípio do contrarrecíproco. Isto é, provaremos a afirmação equivalente: $\Gamma \nvdash \varphi$ implica $\Gamma \nvDash \varphi$. Partimos do princípio que não existe uma demonstração de $\varphi$ a partir de $\Gamma$ e pretendemos construir uma valoração $\rho$ tal que $\rho \Vdash \Gamma$ mas $\rho \nVdash \varphi$. Felizmente, a construção de valorações é um processo razoavelmente simples, visto que é como resolver equações. Cada $\gamma \in \Gamma$ dá-nos uma `equação que $\rho$ tem que satisfazer', e juntando a estas a condição que $\rho$ satisfaça $\neg \varphi$, ficamos com um `sistema com infinitas incógnitas' ($\rho(x)$, $\rho(y)$, \dots), e a nossa esperança seria que, de alguma forma, a hipótese que não há demonstrações de $\Gamma \vdash \varphi$ fosse em algum sentido equivalente a `este sistema é não-singular'.
	
	A ideia será construir $\rho$ de forma gananciosa, atribuindo valores às variáveis sequencialmente. Cada variável nova que atribuímos `adiciona uma condição a $\Gamma$', e se nos certificarmos a cada passo que não quebramos a condição $\Gamma \nvdash \varphi$, no final acabaremos com a valoração desejada.
	
	Seguem-se os detalhes formais.
	
	\begin{teorema} (Completude do cálculo proposicional)
	Sejam $\Gamma \subseteq \F_p$ e $\varphi \in \F_p$ tal que $\Gamma \nvdash \varphi$. Então, $\Gamma \nvDash \varphi$.
	\end{teorema}
	
	\begin{proof}
	Esta demonstração é bastante elaborada, pelo que alguns detalhes são remetidos para lemas que serão demonstrados no final.
	
	Construiremos indutivamente uma valoração $\rho$ tal que $\rho \Vdash \Gamma$ e $\rho \nVdash \varphi$. Para o fazer, pressupomos uma enumeração $\bf x_1, \bf x_2, \dots$ de $X$. (Usamos aqui que o conjunto das variáveis, $X$, é contável!)
	
	Para definir $\rho(\bf x_1)$, averigue-se se $\Gamma, \bf x_1 \vdash \varphi$. Isto é: será que adicionando a afirmação `$\bf x_1$ é verdadeiro' às nossas hipóteses conseguimos demonstrar $\varphi$?
	
	\begin{itemize}
	\item Em caso afirmativo, o nosso $\rho$ não poderá atribuir $\rho(\bf x_1) = \lt$, ou então o `sistema' a resolver ($\rho \nVdash \varphi$) ficava impossível! Assim sendo, definimos $\rho(\bf x_1) = \lf$. 
	
	\item Em caso negativo, não haverá problema em definir $\rho(\bf x_1) = \lt$.
	\end{itemize}
	
	Podemos agora definir $\rho(\bf x_2)$, tendo em atenção que $\rho(\bf x_1)$ está já definido, o que condiciona a nossa escolha. Assim sendo, averiguamos se
	\[\Gamma, r(\bf x_1), \bf x_2 \vdash \varphi,\]
	onde $r(\bf x_1)$ é a fórmula $\bf x_1$ ou $\neg \bf x_1$ dependendo de como definimos $\rho(\bf x_1)$.
	
	Continuamos o processo, definindo $\rho(\bf x_n)$ para todo $n$, seguindo a regra:

	\begin{center}
	Se $\Gamma, r(\bf x_1), \dots, r(\bf x_{n-1}), \bf x_n \vdash \varphi$, definimos $\rho(\bf x_n) = \lf$. Caso contrário, $\rho(\bf x_n) = \lt$.
	\end{center}
	
	Resta agora mostrar que esta valoração $\rho$ satisfaz o desejado. Isto é, pretendemos usá-la para justificar que $\Gamma \nvDash \varphi$, pelo que há duas coisas a mostrar:
	
	\begin{itemize}
	\item Se $\gamma \in \Gamma$ então $\rho \Vdash \gamma$,
	
	\item $\rho \nVdash \varphi$.
	\end{itemize}
	
	Antes de o fazer, mostramos um facto auxiliar:
	\begin{equation}\label{eq:comp:prop:-1}
	\Gamma, r(\bf x_1), r(\bf x_2), \dots \nvdash \varphi.
	\end{equation}
	
	Para mostrar isto, começamos por fazer uma observação que nos será muito útil no futuro: as provas são finitas. Como tal, existe um número finito de hipóteses que se podem invocar, pelo que, assumindo por absurdo que
	\[\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \varphi,\]
	haveria algum $N$ tal que $\Gamma, r(\bf x_1), r(\bf x_2), \dots, r(\bf x_N) \vdash \varphi$. Mostramos por indução em $N$ que tal não pode acontecer, isto é
	\begin{equation}\label{eq:comp:prop:0}
	\text{Para todo $N \in \N_0$, } \Gamma, r(\bf x_1), r(\bf x_2), \dots r(\bf x_N) \nvdash \varphi.
	\end{equation}
	
	\begin{itemize}
	\item Caso base: $N = 0$. Neste caso, a afirmação que se deseja provar reduz-se a $\Gamma \nvdash \varphi$, que é verdadeira por hipótese.
	
	\item Suponha-se verdade para algum $N$, mostre-se verdade para $N+1$. Há dois casos.
	
	Se $\rho(\bf x_{N+1}) = \lt$, então por construção isso significa que
	\[\Gamma, r(\bf x_1), \dots, r(\bf x_N), \bf x_{N+1} \nvdash \varphi,\]
	que, como neste caso $r(\bf x_{N+1})$ é $\bf x_{N+1}$, mostra o desejado.
	
	Se $\rho(\bf x_{N+1}) = \lf$, então, por construção, temos que
	\begin{equation}\label{eq:comp:prop:1}
	\Gamma, r(\bf x_1), \dots, r(\bf x_N), \bf x_{N+1} \vdash \varphi.
	\end{equation}
	
	Faremos os detalhes mais tarde (ver lema \ref{lema:1}), mas a ideia é a seguinte: supondo, por absurdo, que
	\begin{equation}\label{eq:comp:prop:2}
	\Gamma, r(\bf x_1), \dots, r(\bf x_N), \neg \bf x_{N+1} \vdash \varphi,
	\end{equation}
	ter-se-ia, juntando \eqref{eq:comp:prop:1} e \eqref{eq:comp:prop:2},
	\[\Gamma, r(\bf x_1), \dots, r(\bf x_N), \bf x_{N+1} \lor \neg \bf x_{N+1} \vdash \varphi.\]
	
	Sabendo que a hipótese $\bf x_{N+1} \lor \neg \bf x_{N+1}$ é uma tautologia (verifique), pode ser retirada das hipóteses (basta substituir qualquer sua invocação como \texttt{Hip} por uma invocação por \texttt{Ax}), pelo que concluímos
	\[\Gamma, r(\bf x_1), \dots, r(\bf x_N) \vdash \varphi,\]
	uma contradição com a hipótese de indução. Conclui-se então que
	\[\Gamma, r(\bf x_1), \dots, r(\bf x_N), \neg \bf x_{N+1} \nvdash \varphi,\]
	como desejado.
	\end{itemize}
	
	Podemos agora mostrar $\rho \nVdash \varphi$. Para o fazer, usaremos um facto que terá que ser provado em detalhe mais tarde (ver lema \ref{lema:3}).
	
	A ideia é que, supondo que $\rho \Vdash \varphi$, das hipóteses $r(\bf x_1), r(\bf x_2), \dots$ consegue-se concluir $\varphi$. Simbolicamente,
	\[r(\bf x_1), r(\bf x_2), \dots \vdash \varphi.\]
	
	Intuitivamente, isto é verdade porque as nossas hipóteses permitem-nos `substituir cada variável pelo seu valor de verdade dado por $\rho$', e a informação $\rho \Vdash \varphi$ permite-nos concluir que `ao avaliar a expressão resultante, obtemos $\lt$'. Claro que isto não é uma demonstração, mas será talvez suficiente para o leitor aceitar o facto como plausível.
	
	Este facto é útil porque, sob esta hipótese, ter-se-ia (visto que não há problema em adicionar hipóteses) que
	\[\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \varphi,\]
	o que entra em contradição com \eqref{eq:comp:prop:0}.
	
	Mostre-se, agora, que para todo $\gamma \in \Gamma$ se tem $\rho \Vdash \gamma$. Usando novamente o lema \ref{lema:3}, temos que, assumindo por absurdo $\rho \nVdash \gamma$, ter-se-ia $\rho \Vdash \neg \gamma$ e como tal
	\begin{equation}\label{eq:comp:prop:3}
	r(\bf x_1), r(\bf x_2), \dots \vdash \neg \gamma.
	\end{equation}
	
	Assim sendo, chegamos às seguintes duas conclusões:
	\begin{gather}
	\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \neg \gamma\label{shownotgamma}\\
	\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \gamma\label{showgamma}
	\end{gather}
	a primeira por \eqref{eq:comp:prop:3}, e a segunda porque $\gamma \in \Gamma$. Recorremos agora ao chamado \emph{princípio da explosão}.
	
	Concatenando as demonstrações de \eqref{shownotgamma} e \eqref{showgamma} e ajustando índices consoante necessário, temos uma demonstração que tem $\Gamma, r(\bf x_1), r(\bf x_2), \dots$ como hipóteses e que mostra, em algum momento, $\gamma$ e $\neg \gamma$.
	
	No fim desta demonstração, adicione-se a linha
	\[(\gamma \imply (\neg \gamma \imply \varphi), \texttt{Ax}\footnote{A verificação de que a fórmula invocada é de facto uma tautologia é deixada ao leitor.}),\]
	seguida de duas aplicações de \textit{modus ponens}, de modo a construir uma prova de
	\[
	\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \varphi
	\]
	que é uma contradição com \eqref{eq:comp:prop:-1}.
	
	Isto termina a demonstração de $\rho \Vdash \Gamma$ e $\rho \nVdash \varphi$, pelo que $\Gamma \nvDash \varphi$, como desejado.
	\end{proof}
	
	Falta agora preencher alguns buracos tomados por garantidos nesta demonstração. Antes de o fazermos, mostramos que o cálculo proposicional satisfaz o metateorema da dedução, que nos será muito útil no que se segue. Note-se que, até menção em contrário, não usaremos a completude do cálculo proposicional, visto que, em rigor, ainda não acabámos a sua demonstração!
	
	\begin{prop}
	(Metateorema da dedução, versão sintática)
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então
	
	\[\Gamma, \alpha \vdash \beta \text{ sse } \Gamma \vdash \alpha \imply \beta.\]
	\end{prop}
	\begin{proof}
	Uma das implicações é trivial. ($\leftarrow$) De facto, se $\Gamma \vdash \alpha \imply \beta$, então existe uma demonstração $D$ (de comprimento, digamos, $N$) de $\alpha \imply \beta$ partindo apenas de hipóteses em $\Gamma$. Considere-se então a seguinte demonstração com hipóteses em $\Gamma \cup \{\alpha\}$:
	
	\[[\dots D \dots], (\alpha, \texttt{Hip}), (\beta, \texttt{MP}_{N, N+1})\]
	
	(A invocação de \textit{modus ponens} é justificada porque a $N$-ésima afirmação da prova, isto é, a última afirmação de $D$, é $\alpha \imply \beta$ por hipótese.)
	
	Esta demonstração mostra, então, que $\Gamma, \alpha \vdash \beta$, como desejado.
	\smallskip
	A implicação no outro sentido é um pouco mais elaborada, e introduz a ideia de prova que é construção de demonstrações.
	
	No que se segue, usaremos a sigla MTD com o significado de `metateorema da dedução, versão semântica'.
	
	Vamos partir do princípio que temos uma demonstração de $\Gamma, \alpha \vdash \beta$:
	\[(\varphi_1, j_1), \dots, (\varphi_n, j_n)\]
	e vamos, a partir desta, construir uma demonstração de $\Gamma \vdash \alpha \imply \beta$. Mais concretamente, construiremos uma demonstração (de hipóteses em $\Gamma$)
	\[(\psi_1, j'_1), \dots, (\psi_N, j'_N)\]
	em que alguns dos $\psi$, digamos $\psi_{i_1}, \dots, \psi_{i_n}$ (este último coincidindo com $\psi_N$) correspondem respetivamente a $\alpha \imply \varphi_1, \dots, \alpha \imply \varphi_n$. Esta prova terminará então com $\alpha \imply \beta$ (visto que $\varphi_n$ é $\beta$), pelo que teremos a demonstração desejada de $\Gamma \vdash \alpha \imply \beta$.
	
	Exemplificamos o processo com os primeiros três passos. O primeiro passo da demonstração é $(\varphi_1, j_1)$.
	
	\begin{itemize}
	\item Se $j_1$ é \texttt{Ax}, isso significa que $\varphi_1$ é uma tautologia. Assim sendo, (por transitividade de $\vDash$ e usando a versão semântica do MTD) temos que $\alpha \imply \varphi_1$ é também uma tautologia, pelo que a nossa prova modificada pode simplesmente começar com
	\[(\alpha \imply \varphi_1, \texttt{Ax}).\]
	
	\item Se $j_1$ é \texttt{Hip}, temos que $\varphi_1 \in \Gamma \cup \{\alpha\}$, pelo que há dois casos a considerar.
	\begin{itemize}
	\item Se $\varphi_1$ é $\alpha$, então basta reparar que a afirmação $\alpha \imply \alpha$ é uma tautologia, pelo que podemos começar a prova modificada com
	\[(\alpha \imply \varphi_1, \texttt{Ax}).\]
	
	\item Se $\varphi_1 \in \Gamma$, é preciso provar, com apenas hipóteses em $\Gamma$, que $\alpha \imply \varphi_1$. Para isto, usamos o facto que a seguinte afirmação é uma tautologia: (Como pode ser demonstrado através de dois usos do MTD)
	\[(\varphi_1 \imply (\alpha \imply \varphi_1), \texttt{Ax})\]
	e continuamos a demonstração modificada com
	\begin{gather*}
	(\varphi_1, \texttt{Hip})\\
	(\alpha \imply \varphi_1, \texttt{MP}_{12})
	\end{gather*}
	\end{itemize}
	
	\item Não consideramos aqui o caso de $j_1 = \texttt{MP}$ por razões óbvias.
	\end{itemize}
	
	O mesmo raciocínio funciona para o segundo passo, e aliás qualquer passo cuja justificação seja \texttt{Ax} ou \texttt{Hip}. Falta agora considerar o caso de \texttt{MP}.
	
	Para propósitos ilustrativos, suponha-se que $j_3 = \texttt{MP}_{12}$. A prova modificada construida até agora terá sido
	\[\dots, (\alpha \imply (\varphi_2 \imply \varphi_3), j_{i_1}), \dots, (\alpha \imply \varphi_2, j_{i_2}).\]
	
	Para completar a prova, precisamos de justificar que de $\alpha \imply (\varphi_2 \imply \varphi_3)$ e $\alpha \imply \varphi_2$ conseguimos concluir $\alpha \imply \varphi_3$.  Para tal, é necessário usar o facto que a seguinte afirmação é uma tautologia:
	
	\[[\alpha \imply (\varphi_2 \imply \varphi_3)] \imply [(\alpha \imply \varphi_2) \imply (\alpha \imply \varphi_3)]\]
	coisa esta que pode ser demonstrada semanticamente através de uso generoso do MTD e MP.
	
	Sabendo este facto, é fácil continuar a demonstração modificada, adicionando as linhas:
	\begin{gather*}
	([\alpha \imply (\varphi_2 \imply \varphi_3)] \imply [(\alpha \imply \varphi_2) \imply (\alpha \imply \varphi_3)], \texttt{Ax})\\
	((\alpha \imply \varphi_2) \imply (\alpha \imply \varphi_3), \texttt{MP}_{i_2 + 1, i_1})\\
	(\alpha \imply \varphi_3, \texttt{MP}_{i_2 + 2, i_2})
	\end{gather*}
	
	Note-se que neste raciocínio focámo-nos nos primeiro, segundo e terceiro passos, mas é evidente que este argumento poderá ser aplicado a todos os passos. Continuando o processo até o $n$-ésimo passo, obtém-se a demonstração modificada desejada, o que conclui a prova.
	\end{proof}
	
	Tal como a sua correspondente versão semântica, a versão sintática do metateorema da dedução é instrumental para simplificar imensas provas. Exemplificamos com o seguinte lema, que foi usado na demonstração de completude.
	
	\begin{lema}\label{lema:1}
	Seja $\Gamma \subseteq \F_p$ e $\alpha, \beta, \varphi \in \F_p$. Suponha-se que $\Gamma, \alpha \vdash \varphi$ e $\Gamma, \beta \vdash \varphi$. Então,
	\[\Gamma, \alpha \lor \beta \vdash \varphi.\]
	\end{lema}
	
	\begin{proof}
	Suponha-se, por hipótese, que $\Gamma, \alpha \vdash \varphi$. Então, pelo metateorema da dedução sintático, que $\Gamma \vdash \alpha \imply \varphi$. Identicamente, temos que $\Gamma \vdash \beta \imply \varphi$.
	
	Chamemos $(\varphi_1, j_1), \dots, (\varphi_n, j_n)$ e $(\psi_1, j'_1), \dots, (\psi_m, j'_m)$ às respetivas provas. Concatenando as duas (e ajustando índices de \texttt{MP}'s quando necessário) obtemos uma prova cuja $n$-ésima entrada é $\alpha \imply \varphi$ e cuja $(n+m)$-ésima entrada é $\beta \imply \varphi$.
	
	Adicionando a esta prova a linha
	\[((\alpha \imply \varphi) \imply [(\beta \imply \varphi) \imply ((\alpha \lor \beta) \imply \varphi)], \texttt{Ax})\]
	(ver lema \ref{lemaou} para justificar que esta é uma tautologia) seguida de duas aplicações de MP, obtemos uma demonstração, com hipóteses em $\Gamma$, de $(\alpha \lor \beta) \imply \varphi$. Mais uma aplicação do MTD sintático dá-nos
	\[\Gamma, \alpha \lor \beta \vdash \varphi,\]
	como desejado.
	\end{proof}
	
	\begin{lema}\label{lema:3}
	Seja $\bf x_1, \bf x_2, \dots$ uma enumeração das variáveis, $\rho$ uma valoração e $\varphi$ uma fórmula. Defina-se, para $i = 1, 2, \dots$, $r(\bf x_i)$ como sendo a fórmula $\bf x_i$ se $\rho(\bf x_i) = \lt$ e $\neg \bf x_i$ se $\rho(\bf x_i) = \lf$. Sob estas hipóteses,
	\[\rho \Vdash \varphi \text{ sse } r(\bf x_1), r(\bf x_2), \dots \vdash \varphi.\]
	\end{lema}
	
	\begin{proof}
	($\leftarrow$) Pela correção do cálculo proposicional, se
	\[r(\bf x_1), r(\bf x_2), \dots \vdash \varphi\]
	então
	\[r(\bf x_1), r(\bf x_2), \dots \vDash \varphi.\]
	
	É fácil verificar que $\rho \Vdash r(\bf x_i)$ para todo $i \in \N^+$, pelo que, por definição de consequência semântica, $\rho \Vdash \varphi$, como desejado.
	
	\medskip
	
	($\rightarrow$) Para provar esta implicação, começamos por reparar que o valor de $\overline\rho(\varphi)$ depende apenas do valor de $\rho(\bf x)$ para um número finito de variáveis $\bf x$. Isto pode ser provado diretamente, ou pode ser feito usando o facto que $\overline\rho(\varphi)$ depende apenas de $\rho|_{\var \varphi}$ e que o conjunto $\var \varphi$ é finito (em ambos os casos, a justificação pode ser concretizada com indução na estrutura da fórmula). Assim sendo, existe algum $N$ tal que $\overline\rho(\varphi)$ depende apenas de $\rho(\bf x_1), \dots, \rho(\bf x_N)$. Como tal, partindo do princípio que $\rho \Vdash \varphi$, qualquer valoração $\rho'$ que concorde com $\rho$ nestas variáveis também satisfará $\rho' \Vdash \varphi$.
	
	Repare-se agora que qualquer valoração $\rho'$ que satisfaz
	\[\rho' \Vdash r(\bf x_1), \dots, r(\bf x_N)\]
	está precisamente nestas condições, pelo que $\rho' \Vdash \varphi$. Assim sendo, conclui-se que
	\[r(\bf x_1), \dots, r(\bf x_N) \vDash \varphi.\]
	
	Pela completude do cálculo proposicional no caso finito, obtém-se
	\[r(\bf x_1), \dots, r(\bf x_N) \vdash \varphi,\]
	e visto que não há problema em adicionar hipóteses, temos
	\[r(\bf x_1), r(\bf x_2), \dots \vdash \varphi\]
	como desejado.
	\end{proof}
	
	Concluídas as demonstrações dos lemas necessários, damos por terminada a demonstração da completude do cálculo. Isto é: a partir de tautologias e \textit{modus ponens}, é possível demonstrar sintaticamente qualquer afirmação da forma $\Gamma \vDash \varphi$!
	
	Isto tem uma consequência interessante, que não tem demonstração fácil que não passe pela noção de sintática.
	
	\begin{prop}
	Seja $\Gamma \subseteq \F_p$ e $\varphi \in \F_p$. Então, se $\Gamma \vDash \varphi$ existe um subconjunto finito $\Gamma'$ de $\Gamma$ tal que $\Gamma' \vDash \varphi$.
	
	Por outras palavras, se $\varphi$ é consequência semântica das hipóteses em $\Gamma$, é possível arranjar um conjunto finito de hipóteses a partir dos quais ainda se conclui $\varphi$.
	\end{prop}
	
	\begin{proof}
	Suponha-se que $\Gamma \vDash \varphi$. Então, pela completude do cálculo proposicional, $\Gamma \vdash \varphi$, ou seja, existe uma demonstração de $\varphi$ com hipóteses em $\Gamma$. Como demonstrações são finitas, é possível apenas invocar um número finito de hipóteses. Assim sendo, se $\Gamma' \subseteq \Gamma$ é o conjunto de hipóteses invocadas nesta demonstração, temos $\Gamma' \vdash \varphi$, pelo que, por correção, $\Gamma' \vDash \varphi$.
	\end{proof}
	
	Note-se que o enunciado da proposição anterior não menciona o cálculo proposicional nem a noção de provabilidade.
	
	\section{Axiomática}
	
	Tivemos até agora bastante sucesso com o cálculo proposicional. Mostrámos que, partindo apenas do nosso conhecimento de tautologias e \textit{modus ponens}, é possível caracterizar completamente a relação de consequência semântica. Nesta secção, reduziremos o conjunto dos axiomas.
	
	Começamos por mostrar que para um conjunto de axiomas nos dar um cálculo correto e completo é necessário e suficiente que, em certo sentido, chegue para descrever as tautologias todas.
	
	\begin{prop}\label{axiomconditions}
	Seja $A$ um conjunto de fórmulas. Então, o cálculo proposicional usando $A$ como axiomas é
	
	\begin{itemize}
	\item Correto sse todos os elementos de $A$ são tautologias
	
	\item Completo sse para qualquer tautologia $\varphi$ existe uma demonstração (sem hipóteses) de $\varphi$ com os axiomas de $A$.
	\end{itemize} 
	\end{prop}
	
	\begin{proof}
	Há quatro implicações a provar.
	
	(Correção $\imply$ Todos os elementos de $A$ são tautologias) Esta implicação é trivial.
	
	(Todos os elementos de $A$ são tautologias $\imply$ Correção) A demonstração de correção feita em \ref{prop:correcao} aplica-se sem modificação.
	
	(Completude $\imply$ Qualquer tautologia é possível de provar) Esta implicação é trivial.
	
	(Qualquer tautologia é possível de provar $\imply$ Completude) Já mostrámos que sempre que $\Gamma \vDash \varphi$ existe uma demonstração de $\varphi$ com hipóteses em $\Gamma$ \emph{que usa as tautologias como axiomas}. Basta então mostrar que, sob estas hipóteses, é sempre possível substituir uma invocação de uma tautologia por uma `mini-demonstração' desta.
	
	Considere-se uma prova (no sentido de $A$ = tautologias) no meio da qual se invoca uma tautologia $\varphi$ que não esteja em $A$. Digamos que esta prova é da forma
	\[ [\dots D_1 \dots], (\varphi, \texttt{Ax}), [\dots D_2 \dots].\]
	
	Suponha-se que $[\dots C \dots]$ é uma demonstração de $\varphi$ com axiomas em $A$. Esta demonstração existe por hipótese. Então, concatenando demonstrações e ajustando índices, temos que
	\[ [\dots D_1 \dots] [\dots C \dots] [\dots D_2 \dots] \]
	é uma demonstração, com a mesma conclusão que a original, da qual foi removida uma invocação de um axioma que não está em $A$. O processo pode ser repetido até todas as tais invocações serem removidas. No final, a demonstração obtida é uma demonstração com a mesma conclusão que a original mas que só usa axiomas em $A$.
	\end{proof}
	
	O nosso problema fica então reduzido a arranjar um conjunto $A$ de tautologias, se possível `razoavelmente pequeno', a partir do qual se consiga demonstrar todas as tautologias. Para investigar este problema é razoável investigar as ferramentas que usámos para mostrar tautologias. De facto, uma ferramenta que nos foi útil em muitos casos é o metateorema da dedução. Como tal, é de esperar que o nosso conjunto $A$ tenha axiomas suficientes para o mostrar. Por inspeção da demonstração da versão sintática do MTD, vemos que as únicas tautologias que são realmente necessárias são:
	
	\begin{enumerate}
	\item Se $\varphi_1$ é um axioma, é necessário $\alpha \imply \varphi_1$
	
	\item $\alpha \imply \alpha$
	
	\item $\varphi_1 \imply (\alpha \imply \varphi_1)$
	
	\item $[\alpha \imply (\varphi_2 \imply \varphi_3)] \imply [(\alpha \imply \varphi_2) \imply (\alpha \imply \varphi_3)]$.
	\end{enumerate}
	
	Note-se que a condição 1 é trivialmente possível de demonstrar a partir de 3. Assim sendo, basta assegurar as tautologias
	\begin{gather}
	\alpha \imply \alpha\label{ax0}\\
	\alpha \imply (\beta \imply \alpha)\label{ax1}\\
	[\alpha \imply (\beta \imply \gamma)] \imply [(\alpha \imply \beta) \imply (\alpha \imply \gamma)]\label{ax2}
	\end{gather}
	para todas as fórmulas $\alpha, \beta, \gamma$.
	
	Mostramos agora que só as últimas duas é que são necessárias.
	
	\begin{prop}
	A partir dos axiomas \eqref{ax1} e \eqref{ax2} é possível mostrar \eqref{ax0}.
	\end{prop}
	
	\begin{proof}
	Usamos esta oportunidade para exemplificar uma estratégia útil para construir demonstrações usando o cálculo proposicional, que é a ideia de `construir demonstrações a partir do fim'.
	
	No nosso caso, queremos construir uma demonstração de $\alpha \imply \alpha$. Não parece óbvio que seja possível chegar a esta afirmação aplicando o axioma \eqref{ax1}, pelo que tentamos aplicar \eqref{ax2}. Para a conclusão ser $\alpha \imply \alpha$, faz sentido considerar o caso particular de $\gamma$ igual a $\alpha$. Ficamos com a seguinte instância:
	\[[\alpha \imply (\beta \imply \alpha)] \imply [(\alpha \imply \beta) \imply (\alpha \imply \alpha)].\]
	
	A afirmação $\alpha \imply (\beta \imply \alpha)$ é um dos axiomas que estamos a considerar, pelo que basta escolher $\beta$ adequadamente de modo a que a afirmação $\alpha \imply \beta$ seja verdadeira. Novamente, aplicamos o axioma \eqref{ax1}, escolhendo $\beta$ igual a, digamos $\alpha \imply \alpha$, que faz com que $\alpha \imply \beta$, isto é, $\alpha \imply (\alpha \imply \alpha)$, seja uma instância de \eqref{ax1}.
	
	Chegamos então à seguinte demonstração:
	\begin{align*}
	&[\alpha \imply ((\alpha \imply \alpha) \imply \alpha)] \imply [(\alpha \imply (\alpha \imply \alpha)) \imply (\alpha \imply \alpha)]&&\texttt{Ax}\\
	&\alpha \imply ((\alpha \imply \alpha) \imply \alpha)&&\texttt{Ax}\\
	&(\alpha \imply (\alpha \imply \alpha)) \imply (\alpha \imply \alpha)&&\texttt{MP}_{1,2}\\
	&\alpha \imply (\alpha \imply \alpha)&&\texttt{Ax}\\
	&\alpha \imply \alpha&&\texttt{MP}_{3,4}
	\end{align*}
	\end{proof}
	
	Temos então um conjunto de apenas dois (!) axiomas\footnote{Tecnicamente, é um número contável infinito de axiomas, e não apenas dois.} a partir dos quais obtemos o metateorema da dedução. Repare-se, no entanto, que os nossos axiomas não falam do operador `não'. Assim sendo, não há muita esperança de conseguir demonstrar todas as tautologias; em particular aquelas que usam este operador.
	
	Um aspeto principal a considerar para conseguir mostrar todas as tautologias é que \emph{algo} tem que fazer a ligação entre valorações e demonstrações. Na nossa demonstração de completude, este papel coube ao lema \ref{lema:3}. No entanto, a sua demonstração requereu o uso da completude no caso finito, que por sua vez requer o conhecimento que é possível mostrar qualquer tautologia. Assim sendo, é necessário uma forma mais construtiva de demonstrar este lema.
	
	Recordando o enunciado: supomos fixa uma enumeração $\bf x_1, \bf x_2, \dots$ das variáveis e uma valoração $\rho$. Pretendemos mostrar que, se $\varphi$ é uma fórmula,
	\[\rho \Vdash \varphi \text{ sse } r(\bf x_1), r(\bf x_2), \dots \vdash \varphi,\]
	onde $r(\bf x_i)$ é $\bf x_i$ ou $\neg \bf x_i$ consoante $\rho(\bf x_i)$ é $\lt$ ou $\lf$. Visto que não temos ao nosso dispor a capacidade de fazer uma demonstração direta, podemos tentar fazer uma prova por indução na estrutura da fórmula. Para nos ajudar a fazer o passo de indução, provamos aliás uma coisa algo mais forte.
	
	\begin{lema}\label{ligacao:rho:vdash}
	Seja $\rho$ uma valoração, e defina-se $r : \F_p \to \F_p$ como 
	\[r(\varphi) =
	\begin{cases}
	\varphi&\rho\Vdash\varphi\\
	\neg\varphi&\rho\nVdash\varphi
	\end{cases}
	\]
	
	Definimos também $\Gamma_\rho = \{r(\bf x_1), r(\bf x_2), \dots\}$ para abreviar a notação. Então, para qualquer fórmula $\varphi$,
	\[\Gamma_\rho \vdash r(\varphi).\]
	
	Para mais, as únicas hipóteses necessárias são as da forma $r(\bf x)$ para $\bf x \in \var \varphi$.
	\end{lema}
	
	\begin{proof}
	Apesar de nos referirmos a isto como `um lema' e `uma demonstração', não é precisamente isso que se está a passar, visto que precisaremos de usar alguns axiomas que ainda não adicionámos a $A$. O propósito desta `demonstração' é, então, determinar precisamente de que axiomas novos precisaremos.
	
	A demonstração é feita por indução na estrutura da fórmula $\varphi$.
	
	\begin{itemize}
	\item O caso base é trivial.
	
	\item Se a afirmação é verdadeira para $\varphi$, mostramos que é verdade para $\neg \varphi$.
	
	\begin{itemize}
	\item Se $\rho \Vdash \neg \varphi$, então temos que $\rho \nVdash \varphi$. Pela hipótese de indução, temos que $\Gamma_\rho \vdash \neg \varphi$, que é precisamente a conclusão desejada.
	
	\item Se $\rho \nVdash \neg \varphi$, então $\rho \Vdash \varphi$, pelo que, por hipótese de indução, existe uma demonstração de $\varphi$. Para a transformar numa demonstração de $r(\neg \varphi)$, isto é, $\neg \neg \varphi$, é necessário que o seguinte seja um teorema:
	\[\alpha \imply \neg \neg \alpha.\]
	\end{itemize}
	
	Note-se que em ambos os casos não foram adicionadas hipóteses, pelo que as únicas hipóteses necessárias são, por hipótese de indução, aquelas em que $\bf x \in \var \varphi = \var(\neg \varphi)$.
	
	\item Se a afirmação é verdade para as afirmações $\varphi_1$ e $\varphi_2$, mostramos que é verdade para $\varphi_1 \imply \varphi_2$. Há dois casos a considerar.
	
	\begin{itemize}
	\item Se $\rho \Vdash \varphi_1 \imply \varphi_2$, então ou $\overline\rho(\varphi_1) = \lf$ ou $\overline\rho(\varphi_2) = \lt$.
	\begin{itemize}
	\item Se $\overline\rho(\varphi_1) = \lf$ então $\Gamma_\rho \vdash \neg \varphi_1$ por hipótese de indução. Precisamos, então, que a seguinte tautologia seja um axioma:
	\[\neg \varphi_1 \imply (\varphi_1 \imply \varphi_2).\]
	
	\item Se $\overline\rho(\varphi_2) = \lt$ então, por hipótese de indução, $\Gamma_\rho \vdash \varphi_2$. Neste caso, $\Gamma_\rho \vdash \varphi_1 \imply \varphi_2$ visto que $\varphi_2 \imply (\varphi_1 \imply \varphi_2)$ é um axioma.
	\end{itemize}
	
	\item Se $\rho \Vdash \neg (\varphi_1 \imply \varphi_2)$, então $\overline\rho(\varphi_1) = \lt$ e $\overline\rho(\varphi_2) = \lf$. Assim sendo, por hipótese de indução, $\Gamma_\rho \vdash \varphi_1$ e $\Gamma_\rho \vdash \neg \varphi_2$. Precisamos então do axioma
	\[\varphi_1 \imply (\neg \varphi_2 \imply \neg (\varphi_1 \imply \varphi_2)).\]
	\end{itemize}
	
	Novamente, não foram adicionadas hipóteses, pelo que as únicas hipóteses necessárias são, por indução, aquelas em $\var \varphi_1 \cup \var \varphi_2 = \var \varphi$.
	\end{itemize}
	
	Necessitamos portanto de mostrar as seguintes três tautologias, todas usando o operador `não':
	\begin{gather}
	\alpha \imply \neg \neg \alpha\label{ax3}\\
	\neg \alpha \imply (\alpha \imply \beta)\label{ax4}\\
	\alpha \imply (\neg \beta \imply \neg (\alpha \imply \beta))\label{ax5}
	\end{gather}
	
	\end{proof}
	
	Repare-se que as fórmulas \eqref{ax4} e \eqref{ax5} podem facilmente ser reduzidas, usando o princípio do contrarrecíproco, a casos que já conseguimos mostrar. Isto é, suponha-se que temos ao nosso dispor os seguintes dois axiomas:
	\begin{gather}
	(\alpha \imply \beta) \imply (\neg \beta \imply \neg \alpha)\label{cr1}\\
	(\neg \alpha \imply \neg \beta) \imply (\beta \imply \alpha)\label{cr2}
	\end{gather}
	
	Então, \eqref{ax4} pode ser demonstrado facilmente, por uso do metateorema da dedução. Assumindo como hipótese $\neg \alpha$: (E supondo dado o axioma \eqref{cr2})
	\begin{align*}
	&\neg \alpha&&\texttt{Hip}\\
	&\neg \alpha \imply (\neg \beta \imply \neg \alpha)&&\texttt{Ax}\\
	&\neg \beta \imply \neg \alpha&&\texttt{MP}\\
	&(\neg \beta \imply \neg \alpha) \imply (\alpha \imply \beta)&&\texttt{Ax}\\
	&\alpha \imply \beta&&\texttt{MP}.
	\end{align*}
	
	Usando \eqref{cr1} como axioma, a fórmula \eqref{ax5} pode também ser demonstrada de forma semelhante. Isto sugere então o uso dos axiomas
	\begin{gather}
	\alpha \imply (\beta \imply \alpha) \tag{\ref{ax1}}\\
	[\alpha \imply (\beta \imply \gamma)] \imply [(\alpha \imply \beta) \imply (\alpha \imply \gamma)]\tag{\ref{ax2}}\\
	\alpha \imply \neg \neg \alpha \tag{\ref{ax3}}\\
	(\alpha \imply \beta) \imply (\neg \beta \imply \neg \alpha)\tag{\ref{cr1}}\\
	(\neg \alpha \imply \neg \beta) \imply (\beta \imply \alpha).\tag{\ref{cr2}}
	\end{gather}
	
	Acontece, no entanto, que, entre os últimos três, todos exceto \eqref{cr2} são redundantes. A justificação é elaborada, pelo que começamos por mostrar algo que parece, à primeira vista, apenas tangencial.
	
	Suponha-se que se deseja mostrar a afirmação $\neg \neg \alpha \imply \alpha$. De todos os cinco axiomas que temos até agora, o único que nos permite concluir algo sem negações a partir de hipóteses com negações é precisamente \eqref{cr2}.\footnote{Esta afirmação não é uma afirmação matemática, mas sim uma observação `empírica'.} Como tal, tentemos `des-aplicar \eqref{cr2}' de modo a descobrir o que é preciso mostrar para justificar $\neg\neg\alpha \imply \alpha$.
	\begin{gather*}
	(\neg\alpha \imply \neg\neg\neg\alpha) \imply (\neg\neg\alpha \imply \alpha)\\
	(\neg\neg\neg\neg\alpha \imply \neg\neg\alpha) \imply (\neg\alpha \imply \neg\neg\neg\alpha).
	\end{gather*}
	
	A primeira aplicação não nos dá algo em que se possa imediatamente mexer, mas após uma segunda aplicação, obtemos uma afirmação da forma $\beta \imply \neg\neg\alpha$. Nesta afirmação já é possível pegar, visto que, invocando o axioma \eqref{ax1}, temos $\neg\neg\alpha \imply (\beta \imply \neg\neg\alpha)$. Temos então material para construir a seguinte prova, que usa apenas os três axiomas \eqref{ax1}, \eqref{ax2} e \eqref{cr2}, juntamente com a hipótese $\neg\neg\alpha$.
	
	\begin{align*}
	&\neg\neg\alpha&&\texttt{Hip}\\
	&\neg\neg\alpha \imply (\neg\neg\neg\neg \alpha \imply \neg\neg\alpha)&&\texttt{Ax}\\
	&\neg\neg\neg\neg \alpha \imply \neg\neg\alpha&&\texttt{MP}\\
	&(\neg\neg\neg\neg \alpha \imply \neg\neg\alpha) \imply (\neg\alpha \imply \neg\neg\neg\alpha)&&\texttt{Ax}\\
	&\neg\alpha \imply \neg\neg\neg\alpha&&\texttt{MP}\\
	&(\neg\alpha \imply \neg\neg\neg\alpha)\imply(\neg\neg\alpha \imply \alpha)&&\texttt{Ax}\\
	&\neg\neg\alpha \imply \alpha&&\texttt{MP}\\
	&\alpha&&\texttt{MP}_{7,1}.
	\end{align*}
	
	Usando o MTD, é possível transformar isto numa demonstração de $\neg\neg\alpha \imply \alpha$.
	
	Estamos agora em posição de mostrar a redundância de \eqref{ax3} e \eqref{cr1}. Começamos primeiro por estabelecer uma proposição que temos andado a utilizar implicitamente.
	
	\begin{prop}
	Se a afirmação $\varphi$ é possível de demonstrar a partir do conjunto de axiomas $A$, então qualquer prova que use $\varphi$ como hipótese pode ser transformada numa prova que use apenas axiomas em $A$.
	\end{prop}
	
	\begin{proof}
	O raciocínio é idêntico ao usado no final da proposição \ref{axiomconditions}
	\end{proof}
	
	Como consequência desta proposição, dar-nos-emos ao luxo de, ao escrever algumas demonstrações, invocar teoremas já mostrados. Neste caso, invocá-los-emos com a justificação \texttt{Teo}. É de reparar, no entanto, que, tal como definições por abreviatura, uma demonstração em que usamos um teorema é suposto ser interpretada como uma \emph{abreviação de uma demonstração} usando apenas axiomas, hipóteses e \textit{modus ponens}!
	
	\begin{prop}
	Dados os cinco axiomas descritos acima, \eqref{ax3} e \eqref{cr1} são redundantes. Isto é, são ambos teoremas dos três restantes.
	\end{prop}
	
	\begin{proof}
	Comecemos por mostrar que a fórmula $\alpha \imply \neg\neg\alpha$ é um teorema dos três restantes. Infelizmente, não temos ao nosso imediato dispor ferramentas para `adicionar negações'. No entanto, o axioma \eqref{cr2} permite-nos trocar a ordem de implicações. `Des-aplicando' este axioma a $\alpha \imply \neg\neg\alpha$, obtemos
	\[(\neg\neg\neg\alpha \imply \neg\alpha) \imply (\alpha \imply \neg\neg\alpha).\]
	
	Note-se que $\neg\neg\neg\alpha \imply \neg\alpha$ é uma instância do teorema $\neg\neg\varphi \imply \varphi$, com $\varphi$ igual a $\neg \alpha$. Assim sendo, temos a seguinte prova:
	\begin{align*}
	&\neg\neg\neg\alpha \imply \neg\alpha&&\texttt{Teo}\\
	&(\neg\neg\neg\alpha \imply \neg\alpha) \imply (\alpha \imply \neg\neg\alpha)&&\texttt{Ax}\\
	&\alpha \imply \neg\neg\alpha&&\texttt{MP}.
	\end{align*}
	
	Isto mostra que \eqref{ax3} é redundante, pelo que basta agora mostrar que \eqref{cr1} também o é.
	
	A ideia é, partindo de $\alpha \imply \beta$, concluir $\neg \neg \alpha \imply \neg \neg \beta$, e depois, usando $\eqref{cr2}$, remover uma das negações. Começamos por mostrar $(\alpha \imply \beta) \imply (\neg\neg\alpha \imply \neg\neg\beta)$. Considere-se a seguinte demonstração:
	
	\begin{align*}
	&\alpha \imply \beta&&\texttt{Hip}\\
	&\neg\neg\alpha&&\texttt{Hip}\\
	&\neg\neg\alpha \imply \alpha&&\texttt{Teo}\\
	&\alpha&&\texttt{MP}\\
	&\beta&&\texttt{MP}\\
	&\beta \imply \neg\neg\beta&&\texttt{Teo}\\
	&\neg\neg\beta&&\texttt{MP}
	\end{align*}
	
	Através de duas aplicações do metateorema da dedução, obtemos que
	\[(\alpha \imply \beta) \imply (\neg\neg\alpha \imply \neg\neg\beta)\]
	é um teorema.
	
	O axioma \eqref{cr2} diz-nos
	\[
	(\neg\neg\alpha \imply \neg\neg\beta) \imply (\neg \beta \imply \neg \alpha)
	\]
	pelo que é fácil construir, através do MTD, uma demonstração de
	\[(\alpha \imply \beta) \imply (\neg \beta \imply \neg \alpha),\]
	como desejado. (Deixamos esta última parte como exercício.)
	\end{proof}
	
	Chegamos então à nossa lista \textbf{final} de axiomas $A$:
	
	\begin{gather}\label{prop:axiomasfinais}
	\alpha \imply (\beta \imply \alpha) \tag{\ref{ax1}}\\
	[\alpha \imply (\beta \imply \gamma)] \imply [(\alpha \imply \beta) \imply (\alpha \imply \gamma)]\tag{\ref{ax2}}\\
	(\neg \alpha \imply \neg \beta) \imply (\beta \imply \alpha).\tag{\ref{cr2}}
	\end{gather}
	
	Ainda não mostrámos, claro, que estes são suficientes. É nisso que consiste a seguinte proposição.
	
	\begin{teorema}
	A lista de axiomas $A$ acima é suficiente para mostrar qualquer tautologia. Como tal, visto que todos eles são tautologias, o cálculo proposicional que tem a lista $A$ como axiomas é correto e completo, pela proposição \ref{axiomconditions}.
	\end{teorema}
	
	\begin{proof}
	Seja $\varphi$ uma tautologia, e sejam $\bf x_1, \dots, \bf x_n$ as suas variáveis. Então, o lema \ref{ligacao:rho:vdash} diz-nos que, para qualquer valoração $\rho$, definindo $r$ como neste lema,
	\[r(\bf x_1), \dots, r(\bf x_n) \vdash \varphi,\]
	pois $r(\varphi)$ é sempre $\varphi$. Isto implica, por aplicação repetida do MTD,
	\[\vdash r(\bf x_1) \imply ( \dots (r(\bf x_n) \imply \varphi) \dots ).\]
	
	Como isto é para qualquer valoração $\rho$, temos os dois seguintes teoremas:
	\begin{gather*}
	\bf x_1 \imply ( r(\bf x_2) \imply (\dots (r(\bf x_n) \imply \varphi) \dots ))\\
	\neg \bf x_1 \imply ( r(\bf x_2) \imply (\dots (r(\bf x_n) \imply \varphi) \dots ))
	\end{gather*}
	
	Afirmamos que a seguinte fórmula é um teorema:
	\begin{equation}\label{eq:aornota}
	(\alpha \imply \psi) \imply ((\neg \alpha \imply \psi) \imply \psi).
	\end{equation}
	
	Esta afirmação é deixada como lema (lema \ref{lema:aornota}) de modo a não quebrar a prova.
	
	O teorema \eqref{eq:aornota} é-nos útil porque nos permite eliminar as hipóteses $r(\bf x_i)$ e então concluir $\vdash \varphi$. Concretamente, considere-se a seguinte prova, onde $r(\bf x_2) \imply (\dots (r(\bf x_n) \imply \varphi) \dots )$ é abreviado a $\psi$.
	\begin{align*}
	&\bf x_1 \imply \psi&&\texttt{Teo}\\
	&\neg \bf x_1 \imply \psi&&\texttt{Teo}\\
	&(\bf x_1 \imply \psi) \imply ((\neg \bf x_1 \imply \psi) \imply \psi)&&\texttt{Teo}\\
	&(\neg \bf x_1 \imply \psi) \imply \psi&&\texttt{MP}\\
	&\psi&&\texttt{MP}.
	\end{align*}
	
	Logo, para qualquer valoração $\rho$, a fórmula
	\[r(\bf x_2) \imply (\dots (r(\bf x_n) \imply \varphi) \dots )\]
	é um teorema. Ora, o mesmo raciocínio pode agora ser aplicado para eliminar a hipótese $r(\bf x_2)$, e assim por diante, para concluir, como desejado, que a tautologia $\varphi$ é também um teorema. Isto conclui a demonstração.
	\end{proof}
	
	Isto quase conclui a nossa exploração do sistema proposicional, faltando apenas provar o seguinte lema:
	
	\begin{lema}\label{lema:aornota}
	A seguinte fórmula é um teorema:
	\[(\alpha \imply \psi) \imply ((\neg \alpha \imply \psi) \imply \psi)\]
	\end{lema}
	
	\begin{proof}
	Comecemos com as hipóteses $\alpha \imply \psi$ e $\neg \alpha \imply \psi$. A partir da primeira, usando o princípio do contrarrecíproco, obtemos $\neg \psi \imply \neg \alpha$. Da segunda, conclui-se $\neg \psi \imply \neg \neg \alpha$. Logo, adicionando a hipótese $\neg \psi$, concluímos $\neg \alpha$ e $\neg\neg\alpha$.
	
	É razoavelmente intuitivo que a partir de factos contraditórios seja possível concluir qualquer coisa. E de facto, aplicando o princípio do contrarrecíproco ao axioma
	\[\neg \alpha \imply (\beta \imply \neg \alpha)\]
	é possível concluir que, para qualquer $\beta$,
	\[\neg \alpha \imply (\neg \neg \alpha \imply \neg \beta).\]
	
	Assim sendo, juntando os ingredientes que já temos, a partir das hipóteses
	\begin{gather*}
	\alpha \imply \psi\\
	\neg \alpha \imply \psi\\
	\neg \psi
	\end{gather*}
	é possível concluir $\neg \beta$, onde $\beta$ é uma fórmula arbitrária. Aplicando o MTD, obtemos
	\[\alpha \imply \psi, \neg \alpha \imply \psi \vdash \neg \psi \imply \neg \beta,\]
	e aplicando o princípio do contrarrecíproco mais uma vez
	\[\alpha \imply \psi, \neg \alpha \imply \psi \vdash \beta \imply \psi.\]
	
	Note-se que $\beta$ permanece uma fórmula arbitrária. Se escolhermos $\beta$ igual a, digamos, um axioma, é claro que de $\beta \imply \psi$ se conclui $\psi$, pelo que, finalmente,
	\[\alpha \imply \psi, \neg \alpha \imply \psi \vdash \psi.\]
	
	Duas aplicações do MTD permitem-nos concluir o teorema desejado.
	\end{proof}
	
	
	\chapter{Lógica de primeira ordem}
	
	A lógica proposicional é uma forma de relacionar afirmações. No entanto, é muito pouco expressiva. Não é possível, por exemplo, expressar afirmações sobre grupos ou números naturais na lógica proposicional.
	
	É neste contexto que surge a lógica de primeira ordem, que se aproxima mais do tipo de raciocínios que estamos habituados a fazer. Para além de manipular afirmações, temos a capacidade de manipular valores. Isto é, uma variável $x$, em vez de representar uma afirmação, representa agora um elemento do universo. Neste contexto, as hipóteses representam axiomas do universo de discurso (por exemplo, os axiomas de grupo para falar sobre grupos, ou os axiomas de Peano (ver adiante) para falar sobre números naturais).
	
	O poder expressivo adicional vem ao custo que o sistema é razoavelmente mais complexo. Por exemplo, em lógica de primeira ordem há dois tipos de expressões: expressões que simbolizam valores (e.g. $x + f(y)$, chamamos a estas termos) e expressões que simbolizam afirmações (e.g. $x = y \lor x < y$, chamamos a estas fórmulas). Para além disto, é necessário surgir a noção de assinatura, para identificar que símbolos e operações temos ao nosso dispor (na teoria dos naturais temos $+$ e $\times$, mas em teoria de grupos temos apenas uma operação $\cdot$) e a noção de valoração tem de ser alargada para permitir universos diversos. Pelo lado positivo, a lógica de primeira ordem é suficiente para expressar os axiomas de teoria de conjuntos, na qual é possível construir maior parte da matemática. Assim sendo, para estudar o raciocínio matemático em geral, é muito satisfatório estudar esta lógica.
	
	O objetivo deste capítulo é generalizar os resultados do capítulo anterior para este novo contexto. Por outras palavras, pretendemos descobrir um conjunto de regras de dedução que nos permita provar afirmações de primeira ordem de forma correta e completa. Isto é, queremos um conjunto de regras que nos permita concluir apenas afirmações verdadeiras, mas que nos deixe concluir \emph{todas} as afirmações verdadeiras.
	
	Um par de observações antes de iniciar a teoria:
	
	\begin{obs}
	O leitor poderá questionar porque é que esta se chama `lógica de \emph{primeira} ordem'. De facto, isto sugere a existência de lógicas de segunda ordem, terceira ordem, etc. Aquilo que distingue lógica de primeira ordem é o conceito de quantificador, isto é, os quantificadores $\forall$ e $\exists$. Na lógica de primeira ordem, estes podem ser usados para quantificar \emph{variáveis do universo}. Isto é importante, porque não nos permite expressar, por exemplo, o axioma do supremo no contexto da teoria dos reais. De facto, o axioma do supremo diz:
	
	\begin{center}
	Para qualquer conjunto de reais $X$ tal que $X \neq \emptyset$ e $X$ é majorado, existe um número real $m$ tal que $m$ é majorante de $X$ e para qualquer majorante $m'$ de $X$, $m' \geq m$.
	\end{center}
	
	Note-se que este axioma requer quantificar em `para qualquer \textbf{conjunto de reais}'. `Conjuntos de reais' não são elementos do universo $\R$, pelo que este axioma não pode ser expresso em lógica de primeira ordem.
	
	O conceito de lógica de segunda ordem provém da possibilidade de quantificar sobre conjuntos de elementos do universo. Lógica de terceira ordem permite quantificar sobre conjuntos de conjuntos de elementos do universo, e assim por diante. Estas lógicas de ordem superior a um não são frequentemente usadas porque têm algumas propriedades desagradáveis. Em particular, não existe nenhuma generalização do teorema de completude. Por outras palavras, não existe nenhum sistema razoável de demonstrações que nos permita demonstrar tudo o que é verdade em lógica de segunda ordem.
	\end{obs}
	
	\begin{obs}
	Note-se que as nossas variáveis representam sempre objetos do universo de discurso, e este universo é único. Isto não permite, por exemplo, expressar os axiomas de espaços vetoriais, visto que nestes espaços há dois `tipos de objetos': vetores e escalares. Existem lógicas que permitem lidar com isto, mas estas não estão no âmbito da cadeira de Lógica.
	\end{obs}
	
	\section{Fórmulas}
	
	Antes de podermos definir as expressões que vamos eventualmente manipular, é preciso estabelecer que operações temos ao nosso dispor.
	
	Novamente, consideramos fixo o conjunto $X$ das variáveis. Suponha-se dado um conjunto $F$ de \emph{símbolos de funções}. Isto são apenas símbolos sem significado, que usaremos para escrever expressões do género $f(x)$. Associamos também a cada símbolo $f \in F$ uma \emph{aridade}, isto é, quantos argumentos a função que será denotada por $f$ toma. A aridade de um símbolo de função é um número $\ar(f) \in \N_0$. Observe-se a possibilidade de um símbolo de função ter aridade zero. Isto corresponde a ser uma função sem argumentos. Em linguagens de programação, este tipo de funções aparece na forma $f()$. Para os nossos propósitos, funções de aridade zero correspondem a constantes, por exemplo, \textbf{0}, \textbf{1} ou a matriz identidade $\mathbf{I}$.
	
	Estamos agora em condições de definir o conjunto dos termos. Isto é, o conjunto das expressões que representam valores.
	
	\begin{definicao}
	O conjunto dos \emph{termos em $F$}, onde $F$ é um conjunto de símbolos de funções com aridades associadas, é representado como $\T_F$ e é definido indutivamente como:
	
	\begin{enumerate}
	\item Se $\bf x$ é uma variável, $\bf x$ é um termo. (Chamamos a estes termos atómicos.)
	
	\item Se $f \in F$ é um símbolo de função com aridade $n$ e $t_1,\dots,t_n$ são termos, a seguinte expressão é um termo:\footnote{Recordamos o leitor que adotamos a convenção de interpretar expressões como sendo árvores sintáticas. Ver página \pageref{intro_syntatic_trees}.}
	
	\begin{center}
	\Tree [.$f$ $t_1$ $\dots$ $t_n$ ]
	\end{center}
	\end{enumerate}
	
	Normalmente, esta expressão é representada como $f(t_1, \dots, t_n)$. Apontamos o caso particular de $n = 0$, no qual temos um símbolo de função constante. Em rigor, deveríamos representar este caso como $f()$, mas por conveniência e hábito omitimos os parênteses neste caso.
	
	Outra notação muito comum é no caso de símbolos de funções de aridade 2 que normalmente estamos habituados a escrever com notação \textit{infix}. Por exemplo, se estamos a escrever os axiomas dos números naturais, provavelmente escreveremos $x + y$ em vez de $+(x, y)$.
	
	Termos são normalmente representados pela letra $t$.
	\end{definicao}
	
	Antes de podermos construir expressões que comparam termos, é necessário estabelecer que comparações temos ao nosso dispor.
	
	Suponha-se dado um conjunto $P$ de \emph{símbolos de predicado}. Novamente, estes são símbolos sem significado, com uma aridade em $\N_0$ associada. Ao passo que os símbolos de função representavam aplicação de funções a termos, os símbolos de predicado representam, em certo sentido, `inspeção'. Exemplos de símbolos de predicado seriam o $=$ ou o $\leq$, ambos de aridade 2. Um exemplo de um símbolo de predicado de ordem 1 seria uma afirmação $p(n) : \text{`$n$ é par'}$, e um exemplo mais exótico seria um predicado $q(x, y, z)$ que diz se três números estão em progressão aritmética.
	
	\begin{definicao}
	Fixos um conjunto $F$ de símbolos de funções e um conjunto $P$ de símbolos de predicado, definimos o conjunto das \emph{fórmulas em $F$ e $P$}, representado como $\F_{FP}$, indutivamente da seguinte forma:
	
	\begin{enumerate}
	\item Se $p \in P$ é um símbolo de predicado com aridade $n$ e $t_1,\dots,t_n$ são termos em $F$, a seguinte expressão é uma fórmula:
	
	\begin{center}
	\Tree [.$p$ $t_1$ $\dots$ $t_n$ ]
	\end{center}
	
	Chamamos a estas fórmulas \emph{atómicas}.
	
	\item Se $\alpha$ e $\beta$ são fórmulas e $\bf x$ é uma variável, as três seguintes são fórmulas:
	\begin{center}
	\Tree [.\texttt{not} $\alpha$ ]
	\qquad
	\Tree [.\texttt{implies} $\alpha$ $\beta$ ]
	\qquad
	\Tree [.\texttt{forall} $\bf x$ $\alpha$ ]
	\end{center}
	\end{enumerate}
	
	Estes quatro tipos de fórmulas são normalmente representados em notação linear, respetivamente, como
	
	\[p(t_1, \dots, t_n) \qquad \neg \alpha \qquad \alpha \imply \beta \qquad \forall_{\bf x} \alpha.\]
	\end{definicao}
	
	Para não termos de levar o conjunto $F$ e $P$ para todo o lado, é normal juntá-los num único objeto ao qual chamamos assinatura,
	\[\Sigma = (F, P, \ar).\]
	
	Assim sendo, normalmente falaremos do conjunto de termos em $\Sigma$ ($\T_\Sigma = \T_F$) e conjunto de fórmulas em $\Sigma$ ($\F_\Sigma = \F_{FP}$). Frequentemente consideraremos a assinatura $\Sigma$ fixa e omitiremos o subscrito, escrevendo apenas $\T$ e $\F$.
	
	Para além da distinção entre termos e fórmulas, há uma grande novidade na lógica de primeira ordem em relação ao cálculo proposicional: quantificação de variáveis. Note-se, no entanto, que nem todas as variáveis de uma fórmula precisam de estar quantificadas. Por exemplo, no contexto dos naturais, $\forall_x (x = y)$ é uma fórmula legítima (mas não verdadeira), apesar de a variável $y$ não estar quantificada. (Dizemos que $y$ é uma variável livre; ver adiante.)
	
	Para interpretar estas fórmulas com variáveis livres, basta pensar no contexto do cálculo proposicional. Neste, as fórmulas não eram quantificadas, mas dizíamos que uma fórmula era uma tautologia se fosse verdade para \emph{qualquer} atribuição das variáveis. Da mesma forma, na lógica de primeira ordem dizemos que uma fórmula é verdadeira se for verdade `em qualquer universo, para qualquer atribuição das variáveis'. (Ver abaixo.)
	
	\section{Semântica}
	
	Introduzimos agora o conceito de estrutura de interpretação.
	
	No cálculo proposicional, interpretar fórmulas era muito fácil, visto que o universo estava fixo: cada variável ou era $\lt$ ou $\lf$. No contexto de primeira ordem, no entanto, há muitos universos plausíveis, pelo que, para além de dizer os valores que as variáveis tomam, é necessário especificar em que universo é que estas vivem.
	
	\begin{definicao}	
	Fixe-se uma assinatura $\Sigma = (F, P, \ar)$. Uma \emph{estrutura de interpretação} $I$ em $\Sigma$ consiste em:
	
	\begin{itemize}
	\item Um conjunto não-vazio(!) $U_I$, que representa o universo;
	
	\item Para cada símbolo $f \in F$, uma função $f_I : U^{\ar f} \to U$;\footnote{Novamente, chamamos atenção para o caso específico de $\ar f = 0$. Neste caso, $U^{\ar f} = U^0$. Isto é o conjunto que contém apenas o `zero-uplo' $()$. Ou seja, uma função $U^0 \to U$ é definida univocamente pela imagem do elemento único do seu domínio, e portanto podemos identificar as funções $U^0 \to U$ com os elementos de $U$. Dito por outras palavras: de acordo com o que foi dito antes, se $\ar f = 0$ então $f_I$ corresponde a um elemento constante de U.}
	
	\item Para cada símbolo $p \in P$, uma função $p_I : U^{\ar p} \to \{\lt, \lf\}$.
	\end{itemize}
	\end{definicao}
	
	Agora que podemos definir os universos nos quais os nossos objetos vivem, podemos definir valoração:
	
	\begin{definicao}
	Fixe-se uma assinatura $\Sigma$ e uma estrutura de interpretação $I$ (sobre $\Sigma$). Uma \emph{valoração sobre $I$} é uma função $\rho : X \to U_I$.
	\end{definicao}
	
	Para evitar sobrecarregar a notação, frequentemente omitiremos `sobre $I$' e `sobre $\Sigma$'s quando óbvio de contexto. Por exemplo, a afirmação `Seja $I$ uma estrutura de interpretação e $\rho$ uma valoração' deverá ser entendida como `Seja $\Sigma$ uma assinatura (se não estiver já uma implícita), $I$ uma estrutura de interpretação sobre $\Sigma$ e $\rho$ uma valoração sobre $I$'.
	
	Fixa uma estrutura de interpretação $I$ e uma valoração $\rho$, tal como no caso do cálculo propositcional, é possível extender $\rho$ a uma função $\T \to U_I$, `substituindo cada variável $\bf x$ por $\rho(\bf x)$ e fazendo as contas'. Concretizamos novamente esta noção usando uma definição por indução nas fórmulas:
	
	\begin{definicao}
	Fixo $\rho : X \to U_I$, definimos $\rho_\T : \T \to U_I$ indutivamente como:
	
	\begin{itemize}
	\item Se $t$ é um termo da forma $\bf x$, define-se $\rho_T(t) = \rho(\bf x)$
	
	\item Se $t$ é um termo da forma $f(t_1, \dots, t_n)$, define-se
	\[\rho_\T(t) = f_I(\rho_\T(t_1), \dots, \rho_\T(t_n)).\]
	\end{itemize}
	
	Podemos também extender a função para se aplicar a fórmulas, dizendo se a fórmula é verdadeira ou falsa. Isto é, definimos $\rho_\F : \F \to \{\lt, \lf\}$ como:
	
	\begin{itemize}
	\item Se $\varphi$ é uma fórmula atómica da forma $p(t_1, \dots, t_n)$, definimos
	\[\rho_\F(\varphi) = p_I(\rho_\T(t_1), \dots, \rho_\T(t_n))\]
	
	\item Se $\varphi$ é da forma $\neg \alpha$, definimos $\rho_\F(\varphi) = \pnot \rho_\F(\alpha)$
	
	\item Se $\varphi$ é da forma $\alpha \imply \beta$, definimos $\rho_\F(\varphi) = (\pnot \rho_\F(\alpha)) \por \rho_\F(\beta)$
	
	\item Deixamos o caso em que $\varphi$ é da forma $\forall_{\bf x} \alpha$ para adiante, visto que este caso requer alguma explicação.
	\end{itemize}
	\end{definicao}
	
	Para averiguar a definição de $\rho_\F(\forall_{\bf x} \alpha)$, é preciso averiguar o significado intuitivo do símbolo $\forall_{\bf x}$, particularmente em casos `esquisitos'.
	
	Por exemplo, não há nada a proibir a construção de uma fórmula da forma $\forall_{\bf x} \forall_{\bf x} (\bf x = \bf x)$. À primeira vista, no entanto, é difícil perceber o que esta fórmula significa. A solução é semelhante ao que é feito nalgumas linguagens de programação, que nestas tem o nome de `local scoping'.
	
	Considere-se o seguinte programa em Python:
	
	\begin{lstlisting}
x = 2
def f(x):
    print(x)
	\end{lstlisting}
	Suponha-se agora que se escreve a expressão \texttt{f(4)}. O que acontece? Sabemos que \texttt{f} imprimirá o valor de \texttt{x}, mas há dois \texttt{x} em jogo: o valor global de \texttt{x = 2} e o \texttt{x} que foi dado à função que tem o valor de \texttt{4}.
	
	O leitor poderá experimentar este exemplo por si próprio, mas o que se verifica é que o valor impresso é \texttt{4}. O que acontece é que o \texttt{x} de dentro da função `esconde' o \texttt{x} global, isto é, qualquer referência a \texttt{x} em que estão os dois \texttt{x} definidos é interpretada como referindo-se ao \texttt{x} da função. Em geral, a expressão \texttt{x} refere-se à variável \texttt{x} definida no contexto mais interior possível. É esta a estratégia que tomaremos na nossa formalização de lógica. Assim sendo, a expressão $\forall_{\bf x} \forall_{\bf x} (\bf x = \bf x)$ terá o mesmo significado que $\forall_{\bf x} \forall_{\bf x'} (\bf x' = \bf x')$, pois como a variável $\bf x$ está contida em dois quantificadores, o objeto a que se refere é àquele quantificado pelo quantificador mais interior.
	
	Podemos agora completar a nossa definição de $\rho_\F(\forall_{\bf x} \alpha)$:
	
	\begin{itemize}
	\item Establecemos a seguinte definição: se $\rho : X \to U_I$ é uma valoração, $\bf x$ é uma variável e $u \in U_I$, definimos o símbolo $\rho\!\downarrow^{\bf x}_u$ como a valoração:
	
	\[\rho\!\downarrow^{\bf x}_u (\bf y) = \begin{cases}
	\rho(\bf y) & \text{se $\bf y$ não é $\bf x$}\\
	u & \text{se $\bf y$ é $\bf x$}
	\end{cases}\]
	
	Então, dizemos que $\rho_\F(\forall_{\bf x} \alpha) = \lt$ sse, para todo $u \in U_I$,
	
	\[(\rho\!\downarrow^{\bf x}_u)_\F(\alpha) = \lt.\]
	\end{itemize}
	
	Estamos agora em condições de definir o conceito de consequência semântica no contexto de lógica de primeira ordem. A definição é muito parecida com aquela dada para o cálculo proposicional (definição \ref{def:prop:consequenciasemantica}), mas repare-se que aqui há dois `níveis' diferentes a ter em conta: o nível de estrutura de interpretação e o nível de valoração.
	
	\begin{definicao}
	Seja $\varphi$ uma fórmula e $I$ uma estrutura de interpretação, ambas sobre uma assinatura comum $\Sigma$.
	
	Se $\rho$ é uma valoração sobre $I$, dizemos que $\rho$ satisfaz $\varphi$, denotado $\rho \Vdash \varphi$, se $\rho_\F(\varphi) = \lt$. Isto é: substituindo cada variável $\bf x$ pelo seu valor $\rho(\bf x)$, a afirmação $\varphi$ fica verdadeira.
	
	Dizemos que $I$ satisfaz $\varphi$, escrito $I \Vdash \varphi$, se, para \emph{todas} as valorações $\rho$ sobre $I$, $\rho \Vdash \varphi$. Por outras palavras, `$\varphi$ é sempre verdade no universo $I$'.
	
	De forma análoga à definição \ref{def:prop:consequenciasemantica}, uma afirmação da forma $I \Vdash \Gamma$ (onde $\Gamma$ é um conjunto de fórmulas) equivale a dizer $I \Vdash \gamma$ para todo $\gamma \in \Gamma$.
	\end{definicao}
	
	Note-se que esta distinção entre uma fórmula ser satisfeita por um universo ou por uma valoração não existia no cálculo proposicional, visto que havia apenas um universo: $\{\lt, \lf\}$.
	
	Estas duas noções de satisfação dão azo a duas noções ligeiramente diferentes de consequência semântica: local e global.
	
	\begin{definicao}
	Fixa uma assinatura $\Sigma$, sejam $\Gamma \subseteq \F_\Sigma$ e $\varphi \in \F_\Sigma$. Dizemos que $\varphi$ é \emph{consequência semântica} (global) de $\Gamma$, denotado $\Gamma \vDash \varphi$, se para toda a estrutura de interpretação $I$ tal que $I \Vdash \Gamma$ temos que $I \Vdash \varphi$. Em particular, dizemos que $\varphi$ é uma afirmação verdadeira se $\emptyset \vDash \varphi$.
	
	Dizemos que $\varphi$ é \emph{consequência semântica} (local) de $\Gamma$, denotado $\Gamma \vDash_L \varphi$, se para toda a estrutura de interpretação $I$ e valoração $\rho$ sobre $I$ tal que $\rho \Vdash \Gamma$ temos que $\rho \Vdash \varphi$. Podemos definir uma afirmação como sendo localmente verdadeira se $\emptyset \vDash_L \varphi$, mas é fácil reparar que uma afirmação é verdadeira sse é localmente verdadeira, o que faz desta última definição desnecessária.
	\end{definicao}
	
	No que se segue, a noção de consequência semântica global estará em destaque. Como tal, quando nos referirmos a `consequência semântica', sem menção a local ou global, é pressuposto que nos referimos a consequência semântica global.
	
	Para entender a distinção entre estes dois conceitos, consideremos um exemplo. Seja $\mathbf{Gr}$ o conjunto dos axiomas de grupo, assumindo-se subjacente uma assinatura apropriada. Não entraremos nos detalhes técnicos, visto que não é esse o propósito da exposição atual. Por exemplo, para estes propósitos, os axiomas de grupo deveriam incluir axiomas para a igualdade. No entanto, no que se segue, assumiremos que o símbolo $=$ funciona como esperado.
	
	Neste caso, temos que $\varphi$ é consequência semântica global de $\mathbf{Gr} \cup \Gamma$ se em todos grupos $G$ que satisfazem $\Gamma$ também satisfazem $\varphi$. Por exemplo, considere-se $\Gamma = \{x = y\}$ e averigue-se que grupos o satisfazem.
	
	Note-se que um grupo $G$ satisfaz $x = y$ sse, para qualquer valoração das variáveis $\rho$, $\rho(x) = \rho(y)$. Note-se que a única forma possível de isto acontecer é se $G$ é o grupo trivial com um só elemento \textbf{id}, a identidade. Assim sendo, todos os grupos que satisfazem $\Gamma$ também satisfazem, por exemplo, $\varphi : (z \cdot w) = (w \cdot z)$, visto que o grupo trivial é comutativo. Como tal, concluímos a seguinte consequência semântica global:
	\[\mathbf{Gr}, (x = y) \vDash (z \cdot w) = (w \cdot z).\]
	
	Vamos agora ver que a correspondente afirmação \emph{local} não é verdade. De facto, a afirmação
	\[\mathbf{Gr}, (x = y) \vDash_L (z \cdot w) = (w \cdot z)\]
	corresponde ao seguinte: Se $G$ é um grupo e $\rho : X \to G$ é uma valoração tal que $\rho \Vdash (x = y)$, então $\rho \Vdash (z \cdot w) = (w \cdot z)$. É então fácil arranjar um contraexemplo. Seja $G$ é um grupo não-comutativo e sejam $a, b \in G$ elementos que não comutam. Então, se $\rho$ satisfaz
	\begin{gather*}
	\rho(x) = \rho(y) = \rho(z) = a\\
	\rho(w) = b
	\end{gather*}
	temos que $\rho$ satisfaz todas as premissas ($x = y$) mas não satisfaz a conclusão ($z\cdot w = w\cdot z$), donde concluímos, finalmente,
	\[\mathbf{Gr}, (x = y) \nvDash_L (z \cdot w) = (w \cdot z).\]
	
	Isto foi um exemplo que mostra que consequência semântica global não implica consequência semântica local. No entanto, o converso é verdade, isto é:
	\[\text{Se } \Gamma \vDash_L \varphi \text{ então } \Gamma \vDash \varphi.\]
	
	Deixamos a demonstração deste facto como exercício para o leitor.
	
	\section{Regras de dedução}
	
	Recordamos que o objetivo deste capítulo é arranjar um conjunto de regras a partir das quais é possível concluir afirmações verdadeiras. No contexto do cálculo proposicional, a primeira e mais importante tal regra era a regra de \textit{modus ponens}. Esta regra também se aplica a este novo contexto.
	
	Em tudo o que se segue, $\Sigma$ é uma assinatura fixa que deixamos implícita.
	
	\begin{prop}
	Sejam $\alpha, \beta \in \F$. Então,
	\[(\alpha \imply \beta), \alpha \vDash_L \beta.\]
	\end{prop}
	
	\begin{proof}
	A demonstração é completamente idêntica à da proposição \ref{prop:mp}.
	\end{proof}
	
	Note-se que enunciámos esta propriedade usando consequência semântica local. Implícito está, claro, que a mesma propriedade também é verdade para consequência semântica global, visto que uma implica a outra.
	
	A regra de \emph{modus ponens} não é a única propriedade do cálculo proposicional que se transpõe para a lógica de primeira ordem. De facto, em certo sentido, qualquer tautologia é verdadeira.
	
	Por exemplo, considere-se uma fórmula da forma $\varphi : \alpha \lor \neg \alpha$. Desejamos mostrar que esta fórmula é verdadeira. A prova não é particularmente difícil: basta considerar que, se $\rho$ é uma valoração sobre alguma estrutura de interpretação $I$, $\rho_\F(\alpha)$ é $\lt$ ou $\lf$. Verificando os dois casos, vemos que $\rho_\F(\varphi)$ é, respetivamente $\lt \lor \lf$ ou $\lf \lor \lt$. Em ambos os casos a expressão é avaliada para $\lt$, pelo que para qualquer valoração $\rho$ temos $\rho \Vdash \varphi$, que é a definição de fórmula verdadeira.
	
	Na realidade, há uma justificação que se aproxima mais do cerne da questão. A observação essencial é que a fórmula (proposicional!) $a \lor \neg a$ é uma tautologia e que, de alguma forma, isto implica que qualquer fórmula com essa forma é uma tautologia. De forma semelhante, por exemplo, sabendo que $a \imply (b \imply a)$ é uma tautologia conseguiríamos concluir que uma fórmula da forma $\varphi \imply (\psi \imply \varphi)$ é verdadeira.
	
	Para conseguirmos formalizar esta noção, formalizamos o que significa `uma fórmula de primeira ordem vir de uma fórmula proposicional'.
	
	\begin{definicao}
	Seja $\varphi$ uma fórmula proposicional. Suponha-se que a cada variável $\bf x \in X$ se atribui uma fórmula (de primeira ordem) $\psi(\bf x) \in \F_\Sigma$. Então, definimos $\overline\psi(\varphi)$ como a fórmula (de primeira ordem) obtida de substituir cada variável $\bf x$ por $\psi(\bf x)$.
	
	Por exemplo, a fórmula $\alpha \lor \neg \alpha$ vem de substituição de $a \lor \neg a$, substituindo a letra $a$ pela fórmula $\alpha$, isto é, $\psi(a) = \alpha$.
	
	Deixamos a formalização (por indução em $\varphi$) desta definição ao leitor.
	\end{definicao}
	
	\begin{prop}\label{fol:tautoistheo}
	Seja $\varphi \in \F_p$ uma tautologia e seja $\psi : X \to \F_\Sigma$. Então, $\overline\psi(\varphi)$ é uma fórmula verdadeira.
	\end{prop}
	
	\begin{proof}
	Seja $I$ uma estrutura de interpretação e $\rho$ uma valoração em $I$. Pretendemos mostrar que $\rho_\F(\overline\psi(\varphi)) = \lt$. Para o fazer, construimos, a partir de $\rho$, uma valoração (proposicional) $\rho_p$ tal que, para qualquer fórmula proposicional $\gamma$,
	\begin{equation}\label{fol:tautoistheo:eq1}
	\rho_\F(\overline\psi(\gamma)) = \overline \rho_p (\gamma).
	\end{equation}
	
	Defina-se simplesmente $\rho_p(\bf x) = \rho_\F(\psi(\bf x))$. É fácil provar por indução na estrutura da fórmula que para qualquer fórmula proposicional $\gamma$ a equação \eqref{fol:tautoistheo:eq1} é verdadeira.
	
	Em particular, isto é verdade para a nossa tautologia $\varphi$, donde, por definição de tautologia, temos que, para qualquer valoração $\rho$,
	\[\rho_\F(\overline\psi(\varphi)) = \overline \rho_p (\varphi) = \lt.\]
	
	Como tal, a fórmula $\overline\psi(\varphi)$ é verdadeira.
	\end{proof}
	
	Note-se que a proposição anterior poderia ser fortalecida: é possível pegar numa afirmação da forma $\Gamma \vDash \varphi$ (fórmulas proposicionais) e concluir algo da forma
	\begin{equation}\label{fol:tautoistheo:eq2}
	\overline\psi(\Gamma) \vDash \overline\psi(\varphi).
	\end{equation}
	
	O leitor interessado poderá fazer os detalhes, e deixamos como exercício a seguinte questão: será que o símbolo $\vDash$ em \eqref{fol:tautoistheo:eq2} poderia ser substituído por $\vDash_L$?
	
	\smallskip
	
	Outra ferramenta muito útil no cálculo proposicional era o metateorema da dedução. Veremos que este também se aplica no contexto de lógica de primeira ordem, apesar de ser preciso algum cuidado. Em particular, é este um caso em que consequência semântica local acaba por ser mais bem-comportada do que consequência semântica global.
	
	\begin{prop}(Metateorema da dedução, versão semântica, primeira ordem)
	
	Sejam $\Gamma \subseteq \F$ e $\alpha, \beta \in \F$. Então,
	\[\Gamma, \alpha \vDash_L \beta \text{ sse } \Gamma \vDash_L (\alpha \imply \beta).\]
	\end{prop}
	
	\begin{proof}
	A demonstração é muito semelhante à demonstração da proposição \ref{prop:mtd}.
	
	($\leftarrow$) Suponha-se que $\Gamma \vDash_L (\alpha \imply \beta)$. Seja $\rho$ uma valoração tal que $\rho \Vdash \Gamma \cup \{\alpha\}$. Então, $\rho \Vdash (\alpha \imply \beta)$, por definição de consequência semântica local. Temos também $\rho \Vdash \alpha$, por razões óbvias. Como tal, por \textit{modus ponens}, temos $\rho \Vdash \beta$. Como $\rho$ é uma valoração arbitrária tal que $\rho \Vdash \Gamma \cup \{\alpha\}$, concluímos, como desejado,
	\[\Gamma, \alpha \vDash_L \beta.\]
	
	($\rightarrow$) Suponha-se $\Gamma, \alpha \vDash_L \beta$. Seja $\rho$ uma valoração tal que $\rho \Vdash \Gamma$. Mostraremos que $\rho \Vdash (\alpha \imply \beta)$.
	
	Há dois casos a considerar: $\rho_\F(\alpha) = \lt$ ou $\rho_\F(\alpha) = \lf$.
	
	\begin{itemize}
	\item Se $\rho_\F(\alpha) = \lt$, então, sabendo que $\rho \Vdash \Gamma$ e  $\Gamma, \alpha \vDash_L \beta$, temos que $\rho \Vdash \beta$. Assim sendo, temos, como desejado,
	\begin{align*}
	\rho_\F(\alpha \imply \beta) &= (\pnot \rho_\F(\alpha)) \por \rho_\F(\beta)\\
	&= (\pnot \lt) \por \lt\\
	&= \lt.
	\end{align*}
	
	\item Se $\rho_\F(\alpha) = \lf$ então, como desejado,
	\begin{align*}
	\rho_\F(\alpha \imply \beta) &= (\pnot \rho_\F(\alpha)) \por \rho_\F(\beta)\\
	&= (\pnot \lf) \por \rho_\F(\beta)\\
	&= \lt \por \rho_\F(\beta)\\
	&= \lt.
	\end{align*}
	\end{itemize}
	
	Independentemente do caso temos $\rho \Vdash (\alpha \imply \beta)$. Isto conclui a demonstração.
	\end{proof}
	
	Mostramos agora um exemplo para exemplificar onde é que este metateorema falha para consequência semântica global. Obviamente o contraexemplo terá que ser no sentido ($\rightarrow$), visto que a implicação ($\leftarrow$), que é uma consequência direta de \textit{modus ponens}, também é verdade para consequência semântica global.
	
	Novamente, considere-se o exemplo dos axiomas de grupo $\Gamma = \textbf{Gr}$. Consideremos as fórmulas
	\begin{gather*}
	\alpha : x = \mathbf{id}\\
	\beta : y = \mathbf{id}
	\end{gather*}
	
	Então, é certamente verdade que
	\begin{equation}\label{mtd:contraex1}
	\Gamma, \alpha \vDash \beta,
	\end{equation}
	visto que se $I$ é um grupo que satisfaz $\alpha$, $I$ é necessariamente o grupo trivial, pois para qualquer valor de $\rho(x)$ temos $\rho(x) = \mathbf{id}_I$. O grupo trivial satisfaz também $\beta$, pelo que a afirmação \eqref{mtd:contraex1} é verdadeira.
	
	No entanto, a conclusão que seria dada pelo MTD é falsa. Isto é:
	\begin{equation}\label{mtd:contraex2}
	\Gamma \nvDash (\alpha \imply \beta).
	\end{equation}
	
	Para justificar esta afirmação, seja $I$ um grupo com pelo menos dois elementos, digamos $a = \mathbf{id}_I$ e $b \neq \mathbf{id}_I$. Como $I$ é um grupo, decerto que $I \Vdash \Gamma$. No entanto, $I \nVdash (\alpha \imply \beta)$. De facto, considere-se uma valoração $\rho$ que atribui
	\begin{gather*}
	\rho(x) = a\\
	\rho(y) = b.
	\end{gather*}
	
	Então, temos que
	\begin{align*}
	\rho_\F(\alpha \imply \beta) &= \rho_\F((x = \mathbf{id}) \imply (y = \mathbf{id}))\\
	&= (\pnot \rho_\F((x = \mathbf{id})) \por \rho_\F(y = \mathbf{id}))\\
	&= (\pnot \mathbf{eq}(\rho(x), \mathbf{id}_I)) \por \mathbf{eq}(\rho(y), \mathbf{id}_I)
	\end{align*}
	onde \textbf{eq} é a função que corresponde a $=_I$, que devolve $\lt$ sse ambos os seus argumentos são iguais.
	
	Sabendo que atribuímos $\rho(x) = \mathbf{id}_I$ e $\rho(y) \neq \mathbf{id}_I$, isto dá igual a
	\[(\pnot \lt) \por \lf = \lf,\]
	o que mostra que $\rho \nVdash (\alpha \imply \beta)$, e então, como consequência, $I \nVdash (\alpha \imply \beta)$. Isto termina a demonstração de \eqref{mtd:contraex2}.
	
	\smallskip
	
	Mostrámos agora um exemplo em que consequência semântica local tem propriedades agradáveis. Mostramos agora uma propriedade útil da consequência semântica global.
	
	Um género de raciocínio que fazemos a toda a hora é o seguinte. Pretende-se mostrar que todos os objetos $x$ de algum universo satisfazem $A$. Por exemplo, para todos os elementos $x$ de um anel, $0 \cdot x = 0$. Então, pegamos num $x$ arbitrário, e mostramos que satisfaz $A$. Como $x$ era arbitrário, concluímos que \emph{todos os $x$} satisfazem $A$.
	
	Simbolicamente, este tipo de raciocínio traduz-se na lógica de primeira ordem da seguinte forma:
	
	\begin{prop}
	Seja $\varphi \in \F$ e $\bf x \in X$. Então
	
	\[\varphi \vDash \forall_{\bf x} \varphi.\]
	\end{prop}
	
	\begin{proof}
	Seja $I$ uma estrutura de interpretação tal que $I \Vdash \varphi$. Desejamos mostrar que $I \Vdash \forall_{\bf x} \varphi$. Para tal, seja $\rho$ uma valoração arbitrária sobre $I$. Queremos verificar que $\rho \Vdash \forall_{\bf x} \varphi$.
	
	Por definição, isto acontece sse, para qualquer $u \in U_I$,
	
	\[\rho\!\downarrow^{\bf x}_u \Vdash \varphi.\]
	
	Visto que $I \Vdash \varphi$, para qualquer valoração $\rho'$ temos
	\[\rho' \Vdash \varphi\]
	e em particular
	\[\rho\!\downarrow^{\bf x}_u \Vdash \varphi,\]
	como desejado.
	\end{proof}
	
	Esta nova regra ($\varphi \vDash \forall_{\bf x} \varphi$) tem o nome de \emph{Generalização}. A generalização e \textit{modus ponens} formarão as regras de dedução do chamado \emph{cálculo de Hilbert}, o sistema de demonstração que, como provaremos, engloba completamente a noção de consequência semântica global.
	
	\section{Sintática}
	
	Definimos agora um sistema de demonstração, à semelhança do que foi feito no caso do cálculo proposicional.
	
	\begin{definicao}
	Suponha-se fixa uma assinatura $\Sigma$ e um conjunto de axiomas $A \subseteq \F_\Sigma$.
	
	Se $\Gamma \subseteq \F_\Sigma$, uma \emph{demonstração com base em $\Gamma$} é uma sequência
	\[(\varphi_1, j_1), \dots, (\varphi_n, j_n),\]
	em que cada $\varphi_i \in \F_\Sigma$ e $j_i$, que representa a justificação de $\varphi_i$, satisfaz as seguintes regras:
	
	\begin{itemize}
	\item Cada $j_i$ é um símbolo da forma \texttt{Ax}, \texttt{Hip}, $\texttt{MP}_{ab}$ com $a, b \in \N$ ou $\texttt{Gen}_a$ com $a \in \N$
	
	\item Se $j_i = \texttt{Ax}$ é necessário que $\varphi_i \in A$
	
	\item Se $j_i = \texttt{Hip}$ é necessário que $\varphi_i \in \Gamma$
	
	\item Se $j_i = \texttt{MP}_{ab}$, então $a, b < i$ e $\varphi_a$ é a fórmula $\varphi_b \imply \varphi_i$
	
	\item Se $j_i = \texttt{Gen}_a$, então $a < i$ e $\varphi_i$ é da forma $\forall_{\bf x} \varphi_a$ para alguma variável $\bf x$.
	\end{itemize}
	\end{definicao}
	
	À semelhança do que foi feito com o cálculo proposicional, supomos por agora que que qualquer afirmação verdadeira é um axioma. Mais tarde, identificaremos um conjunto mais pequeno de axiomas que se mostrará ser suficiente para justificar qualquer afirmação verdadeira.
	
	Seria desejado exemplificar agora uma demonstração em lógica de primeira ordem, mas infelizmente o cálculo de Hilbert é particularmente inadequado para uso humano. De facto, a prova de algo tão simples como `Num grupo, se $e \cdot x = x$ para todo o $x$, temos $e = \textbf{id}$' requer uma página inteira de demonstração, apesar de a ideia de prova ser simplesmente reparar que $\textbf{id} = e \cdot \textbf{id} = e$. Para nos permitir manusear e fabricar demonstrações em espaço útil, é necessário o uso de metateoremas.
	
	Um dos metateoremas mais úteis é o metateorema da dedução. No entanto, como visto anteriormente, este não pode ser usado tão livremente como no cálculo proposicional. Em particular, é preciso ter cuidado com a generalização. De facto, a demonstração do metateorema da dedução do cálculo proposicional pode facilmente ser adaptada para demonstrar:
	
	\begin{prop*}
	(Metateorema da dedução, versão semântica fraca, primeira ordem)
	
	Sejam $\Gamma \subseteq \F$ e $\alpha, \beta \in \F$. Suponha-se que existe uma demonstração de $\Gamma, \alpha \vdash \beta$ que não utiliza generalização. Então, $\Gamma \vdash \alpha \imply \beta$.
	\end{prop*}
	
	De modo a poder concluir um metateorema mais forte, é preciso encontrar condições nas quais de $\alpha \imply \varphi$ se conclua $\alpha \imply \forall_{\bf x} \varphi$. A única regra que temos que permita introduzir um quantificador é a generalização, pelo que é suficiente que a seguinte afirmação seja verdadeira:
	\begin{equation}\label{folax4}
	(\forall_{\bf x} (\alpha \imply \varphi)) \imply (\alpha \imply \forall_{\bf x} \varphi).
	\end{equation}
	
	Infelizmente, isto nem sempre é uma afirmação verdadeira. Por exemplo, no contexto dos naturais, se $\alpha : x = 0$ e $\varphi : x = 0$ obtemos que $\forall_x (\alpha \imply \varphi)$ é uma afirmação verdadeira, mas $\alpha \imply \forall_x \varphi$ não é (basta considerar uma valoração que atribui $\rho(x) = 0$). É, no entanto, suficiente exigir que $\alpha$ não dependa de $\bf x$. Intuitivamente, se $\alpha$ não depender de $\bf x$, se soubermos $\forall_{\bf x} (\alpha \imply \varphi)$ e $\alpha$, fixo um $\bf x$ arbitrário, temos que $\alpha \imply \varphi$ (porque se algo é verdade para todos os $\bf x$ é verdade para este em particular), temos $\alpha$, e portanto temos, para este $\bf x$ particular, $\varphi$. Como $\bf x$ é arbitrário, $\varphi$ é verdade para todo o $\bf x$.
	
	Claro que este argumento não é de todo rigoroso. Para o formalizar, é primeiro entender o que significa $\alpha$ depender de $\bf x$. Daí surge a noção de variável livre.
	
	Dada uma fórmula $\varphi$, o valor de verdade desta poderá depender da valoração usada. Em particular, poderá depender do valor de certas variáveis. Por exemplo, no contexto dos naturais, a fórmula $\forall_x (x \geq y)$ é verdadeira para $y = 0$ mas falsa caso contrário. Por outras palavras, a variável $y$ é um parâmetro que pode ser modificado para mudar o valor de verdade da fórmula. Note-se que o mesmo não pode ser dito de $x$, visto que, como essa variável está quantificada, o valor de verdade da fórmula não depende do valor que uma valoração atribui a $x$.
	
	\begin{definicao}
	Dada uma fórmula $\varphi$, define-se o conjunto das variáveis livres de $\varphi$, denotado $\fv \varphi$ (free variables) como as variáveis em $\varphi$ que são `visíveis do exterior', isto é, que não estão quantificadas. Isto pode ser formalizado indutivamente como:
	
	\begin{enumerate}
	\item Se $\varphi : p(t_1,\dots,t_n)$ então $\fv \varphi = \var t_1 \cup \dots \cup \var t_n$ (ver abaixo)
	
	\item Se $\varphi : \alpha \imply \beta$ então $\fv \varphi = \fv \alpha \cup \fv \beta$
	
	\item Se $\varphi : \neg \alpha$ então $\fv \varphi = \fv \alpha$
	
	\item Se $\varphi : \forall_{\bf x} \alpha$ então $\fv \varphi = \fv \alpha \setminus \{\bf x\}$.
	\end{enumerate}
	
	Por sua vez, esta definição requer definir $\var t$ para $t \in \T$. Por sua vez, isto também é definido indutivamente:
	
	\begin{enumerate}
	\item $\var \bf x = \{\bf x\}$
	
	\item $\var f(t_1, \dots, t_n) = \var t_1 \cup \dots \var t_n$.
	\end{enumerate}
	\end{definicao}
	
	Note-se o caso algo patológico em que algumas instâncias de uma variável estão quantificadas e outras não. Por exemplo, na fórmula $\varphi : p(x) \imply \forall_x p(x)$, a variável $x$ é livre, porque existe pelo menos uma instância de $x$ que é visível no exterior, apesar de haver também outra instância que está quantificada e como tal não conta como livre.
	
	Variáveis livres têm a particularidade que, tal como as variáveis do cálculo proposicional, o valor atribuido a uma fórmula $\varphi$ por uma valoração $\rho$ depende apenas do valor das variáveis livres.
	
	\begin{prop} (Lema das variáveis omissas) No que se segue, considere-se fixa uma estrutura de interpretação $I$.
	
	Seja $t \in \T$. Então, $\rho_\T(t)$ depende apenas do valor que $\rho$ atribui às variáveis em $\var t$.
	
	Seja $\varphi \in \F$. Então, $\rho_\F(\varphi)$ depende apenas do valor de $\rho$ atribui às variáveis em $\fv \varphi$.
	\end{prop}
	
	\begin{proof}
	Esta demonstração é feita por indução. Exemplificamos com a primeira parte (referente aos termos):
	
	\begin{enumerate}
	\item Se $t$ é da forma $\bf x$, então $\rho_\T(t) = \rho(\bf x)$ depende apenas de $\rho(\bf x)$, ou seja, do valor que $\rho$ atribui às variáveis em $\var t$.
	
	\item Se $t$ é da forma $f(t_1, \dots, t_n)$ então $\rho_\T(t)$ é igual a $f_I(\rho_T(t_1), \dots, \rho_T(t_n))$, que depende apenas dos valores de $\rho_\T(t_1), \dots, \rho_\T(t_n)$. Por sua vez, estes dependem apenas de $\var t_1, \dots, \var t_n$ respetivamente, pelo que a sequencia total, e então $\rho_\T(t)$, depende apenas de $\var t_1 \cup \dots \cup \var t_n = \var t$.
	\end{enumerate}
	
	A demonstração da a versão para fórmulas é semelhante, excetuando o caso de quantificadores no passo de indução. É este o caso que fazemos no que se segue, deixando os três outros casos para o leitor.
	
	Suponha-se, por hipótese de indução, que $\rho_\F(\varphi)$ depende apenas de $\rho|_{\fv \varphi}$. Então, mostramos que $\rho_\F(\forall_{\bf x} \varphi)$ depende apenas de $\rho|_{\fv \varphi \setminus \{\bf x\}}$.
	
	Sejam $\rho$ e $\rho'$ duas valorações que concordam em $\fv \varphi \setminus \{\bf x\}$. Então, por hipótese de indução, $(\rho\!\downarrow^{\bf x}_u)_\F(\varphi) = (\rho'\!\downarrow^{\bf x}_u)_\F(\varphi)$, visto que ambas estas valorações concordam em $\fv \varphi$. Como tal,
	\[\rho\!\downarrow^{\bf x}_u \Vdash \varphi \text{ para todo o $u \in U_I$}\]
	sse
	\[\rho'\!\downarrow^{\bf x}_u \Vdash \varphi \text{ para todo o $u \in U_I$.}\]
	
	Logo, $\rho_\F(\varphi) = \rho'_\F(\varphi)$, como desejado.
	\end{proof}
	
	Estamos agora prontos para provar que, se $\alpha$ não depende de $\bf x$, a fórmula \eqref{folax4} é verdadeira.
	
	\begin{prop}
	Sejam $\alpha$ e $\varphi$ duas fórmulas e $\bf x$ uma variável tal que $\bf x \not \in \fv\alpha$. Então, a fórmula
	\begin{equation}\tag{\ref{folax4}}
	\psi : (\forall_{\bf x} (\alpha \imply \varphi)) \imply (\alpha \imply \forall_{\bf x} \varphi)
	\end{equation}
	é verdadeira,
	\end{prop}
	
	\begin{proof}
	Seja $I$ uma estrutura de interpretação e $\rho$ uma valoração arbitrária sobre esta estrutura. Então, averigue-se $\rho_\F(\psi)$. Há três casos a considerar, dependendo de $\rho_\F(\forall_{\bf x}(\alpha \imply \varphi))$ e $\rho_\F(\alpha)$:
	
	\begin{enumerate}
	\item Se $\rho_\F(\forall_{\bf x}(\alpha \imply \varphi)) = \lf$, então $\rho_\F(\psi)$ é da forma $(\pnot \lf) \lor \text{(algo)}$, que é garantidamente $\lt$;
	
	\item Se $\rho_\F(\alpha) = \lf$, então $\rho_\F(\alpha \imply \forall_{\bf x} \varphi)$ é garantidamente $\lt$, pelo que $\rho_\F(\psi)$ é necessariamente $\lt$;
	
	\item Se $\rho_\F(\forall_{\bf x}(\alpha \imply \varphi)) = \rho_\F(\alpha) = \lt$, então, para qualquer $u \in U_I$, $\rho\!\downarrow^{\bf x}_u \Vdash (\alpha \imply \varphi)$. Pelo lema das variáveis omissas, como $\bf x \not \in \fv \alpha$ e $\rho \Vdash \alpha$, temos também $\rho\!\downarrow^{\bf x}_u \Vdash \alpha$. Pela versão local do \emph{modus ponens}, temos, para todo $u \in U_I$, $\rho\!\downarrow^{\bf x}_u \Vdash \varphi$. Como tal, temos $\rho \Vdash \forall_{\bf x} \varphi$, o que implica, como o leitor poderá verificar, que $\rho_\F(\psi) = \lt$.
	\end{enumerate}
	
	Como em qualquer dos casos temos $\rho \Vdash \psi$, a fórmula $\psi$ é verdadeira, como desejado.
	\end{proof}
	
	
	
	\chapter{Introdução à computação}
	
	Introdução à teoria das funções computáveis, ligando-a à lógica de primeira ordem, culminando nos teoremas de incompletude de Gödel.
	
	
	\nocite{fltc}
	\nocite{shoenfield}
	
	\bibliographystyle{plain}
	\bibliography{bibliography}
\end{document}
