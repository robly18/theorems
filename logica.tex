\documentclass{report}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{comment}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage{changepage}

%para desenhar árvores sintáticas
\usepackage{tikz}
\usepackage{tikz-qtree}
\tikzset{level distance=2em}

\usepackage{graphicx}


\title{Lógica}
\author{}
\date{}

\newtheorem{prop}{Proposição}
\newtheorem*{prop*}{Proposição}
\newtheorem{teorema}{Teorema}
\newtheorem{lema}{Lema}

\theoremstyle{definition}
\newtheorem{definicao}{Definição}
\newtheorem*{definicao*}{Definição}

\theoremstyle{remark}
\newtheorem{obs}{Obs}

\addto\captionsportuguese{
	\renewcommand{\proofname}{Dem}
}


\newcommand{\N}{\mathbb{N}}

\renewcommand{\bf}[1]{\mathbf{#1}}

\newcommand{\F}{\mathrm{F}}

\newcommand{\lt}{\mathrm{T}}
\newcommand{\lf}{\mathrm{F}}

\DeclareMathOperator{\var}{Var}


\DeclareMathOperator{\pnot}{\texttt{not}}
\newcommand{\pand}{\mathbin{\texttt{and}}}
\newcommand{\por}{\mathbin{\texttt{or}}}
\newcommand{\imply}{\mathbin{\Rightarrow}}
\newcommand{\implied}{\mathbin{\Leftarrow}}
\newcommand{\eqv}{\mathbin{\Leftrightarrow}}

\begin{document}
	\maketitle
	\newpage
	
	\tableofcontents
	\newpage
	
	\chapter{Lógica Proposicional}
	
	A lógica proposicional é um sistema que nos permite expressar raciocínios sobre afirmações e relações entre elas. Mais concretamente, é um sistema no qual as variáveis representam afirmações, que tomam o valor `verdadeiro' e `falso', juntamente com um conjunto de operações lógicas com as quais o leitor já estará familiar, por exemplo o `ou' e o `não'.
	
	Não é preciso procurar muito para descobrir que este sistema tem interesse e aplicações práticas. Qualquer linguagem de programação em uso regular terá este sistema contido no seu funcionamento. Tome-se o exemplo da linguagem Python. Nesta linguagem, as variáveis podem ser do tipo \texttt{bool}. Uma variável deste tipo toma um de dois valores: \texttt{True} e \texttt{False}. Existem também os operadores \texttt{and}, \texttt{or} e \texttt{not}, que recebem valores booleanos e retornam valores booleanos. O uso de parênteses permite-nos agrupar expressões, de modo a formar expressões mais complexas. Por exemplo, \texttt{(a and b) or not (b or not c)} é uma expressão válida em Python (assumindo que as variáveis \texttt{a}, \texttt{b} e \texttt{c} estão definidas e são do tipo \texttt{bool}.)
	
	Formalizaremos e estudaremos este sistema, usando-o como `caixa de areia' para nos preparar para a lógica de primeira ordem, que apesar de semelhante, é significativamente mais complexa.
	
	\section{Noções básicas (Preliminar)}
	
	Esta subsecção tem o sufixo `Preliminar' porque não é final. Isto é, o propósito desta subsecção é apenas dar intuição para o significado das coisas, antes de avançar para as definições secas e rigorosas.
	
	\bigskip
	
	Começamos por introduzir a noção de fórmula. Para os nossos propósitos, uma fórmula é uma expressão composta por variáveis, operadores lógicos, e parênteses. Por exemplo, a expressão $(a \land b) \lor \neg (b \lor \neg c)$ é um exemplo de uma fórmula. Fórmulas são normalmente denotadas por letras gregas minúsculas, e.g. `A fórmula $\varphi$'.
	
	As variáveis (neste caso, $a$, $b$ e $c$) podem tomar os valores de verdade `verdadeiro' e `falso', que aqui denotamos por $\lt$ e $\lf$.
	
	Existem diversos operadores lógicos conhecidos, mas no que se segue usaremos os operadores existentes no Python: $\pnot$, $\pand$ e $\por$. O leitor já deverá estar familiar com o comportamento destes, mas para evitar qualquer confusão, apresentamos as respetivas tabelas de verdade.
	
	\[\label{tabela:operadores}
	\begin{array}{|c|c||c|c|c|}
	\hline
	a & b & \pnot a & a \pand b & a \por b\\
	\hline
	\lt & \lt & \lf & \lt & \lt\\
	\lf & \lt & \lt & \lf & \lt\\
	\lt & \lf &     & \lf & \lt\\
	\lf & \lf &     & \lf & \lf\\
	\hline
	\end{array}
	\]
	
	Dada uma fórmula $\varphi$, podemos tentar `interpretá-la'. Isto é, se atribuirmos valores de verdade às variáveis podemos `substituir esses valores na fórmula' e avaliá-la.
	
	A título de exemplo, consideremos a fórmula $\varphi$ descrita acima.
	\[\varphi : (a \land b) \lor \neg (b \lor \neg c).\]
	
	Suponha-se que estabelecemos $a = \lt$ e $b = c = \lf$. Então, substituindo na fórmula (e escrevendo os operadores \textit{a la} Python), ficamos com
	\begin{gather*}
	(\lt \pand \lf) \por \pnot (\lf \por \pnot \lf)\\
	\lf \por \pnot (\lf \por \lt)\\
	\lf \por \pnot \lt\\
	\lf \por \lf\\
	\lf.
	\end{gather*}
	
	Podemos tornar o processo mais rigoroso descrevendo-o da seguinte forma: definimos uma \emph{valoração} como sendo uma função $\rho : \{\text{Variáveis}\} \to \{\lt, \lf\}$. Afirmamos que qualquer valoração pode ser extendida de forma natural para uma função ${\overline\rho : \{\text{Fórmulas}\} \to \{\lt, \lf\}}$, da forma que descrevemos: substitui-se cada variável $x$ pelo valor de $\rho(x)$ e `faz-se as contas'.
	
	Existe uma classe de fórmulas que tem particular interesse, que são as chamadas tautologias.
	
	Uma fórmula $\varphi$ diz-se uma tautologia se para qualquer valoração $\rho$ temos $\rho(\varphi) = \lt$. Isto é, $\rho$ é sempre verdadeira.
	
	Parte do objetivo deste capítulo é caracterizar as tautologias, de modo a podermos indentificá-las em tempo finito. Claro que, no caso de lógica proposicional, isto já está feito: dada uma fórmula $\varphi$, para determinar se esta é uma tautologia, basta listar todas as valorações possíveis nas variáveis de $\varphi$ (há aqui um detalhe escondido, mas já voltamos a ele) e fazer as contas para todas elas. Se todas elas derem $\lt$, então $\varphi$ é uma tautologia. Caso contrário, não é!
	
	A razão pela qual procuramos outra forma de caracterizar estas fórmulas é porque eventualmente atacaremos o problema mais geral, onde as variáveis, em vez de serem só $\lt$ e $\lf$, podem ser elementos de um universo qualquer arbitrário: naturais, reais, grupos... Assim sendo, deixa de ser possível testar todos os casos possíveis. Como tal, passa a ser necessário um método `sintático', isto é, que manipule as afirmações sem as tentar interpretar. É daí que nasce a formalização de `demonstração', com fim a esclarecer a relação entre o que é verdade e o que é demonstrável.
	
	Voltando a lógica proposicional, consideremos o problema de `testar todos os casos possíveis' para valores das variáveis numa fórmula. Ao fazermos isto estamos a assumir implícitamente que existe um número finito de casos, mas repare-se que, da forma que o definímos, existe um número potencialmente infinito de valorações! De facto, existe um número infinito de variáveis (por exemplo, $x_1$, $x_2$, \dots) pelo que haverá também um número (não-contável!) infinito de valorações. Assim sendo, é impossível testá-las todas.
	
	Claro que, na prática, isto é uma parvoíce. Fixa uma fórmula $\varphi$, só existe um número finito de variáveis a considerar, visto que apenas um número finito de variáveis consta em $\varphi$, e o valor dado a variáveis que não estas é irrelevante. Estamos habituados a tomar estes princípios como garantidos, mas aproveitá-los-emos como veículo para introduzir a noção de indução na estrutura.
	
	A observação essencial é que podemos decompôr uma fórmula arbitrária em fórmulas mais pequenas. Por exemplo, a fórmula $\varphi : (a \land b) \lor \neg (b \lor \neg c)$ pode ser decomposta como $\varphi_1 \lor \varphi_2$, onde $\varphi_1$ e $\varphi_2$ são fórmulas mais pequenas do que a inicial. Isto permite-nos usar o princípio de indução (forte) no tamanho de uma fórmula, em que o passo de indução corresponde a separar uma fórmula como $\varphi_1 \lor \varphi_2$, $\varphi_1 \land \varphi_2$ ou $\neg \varphi_1$. Este processo para nas fórmulas que não podem ser simplificadas mais: chamamos a estas de fórmulas atómicas, e são aquelas compostas por apenas uma variável. Por exemplo, $x$, ou $a$.
	
	Exemplificaremos o princípio, começando por definir indutivamente a noção de `variáveis em fórmula', e demonstrando, com base nesta definição, que, se $\rho$ é uma valoração e $\varphi$ é uma fórmula, $\overline\rho(\varphi)$ depende apenas do valor de $\rho$ nas variáveis em $\varphi$.
	
	\begin{definicao*}
	Seja $\varphi$ uma fórmula. Definimos $\var \varphi$ indutivamente da seguinte forma:
	\begin{itemize}
	\item Se $\varphi$ é da forma `$x$', então $\var \varphi = \{x\}$.
	
	\item Se $\varphi$ é da forma $\neg \varphi_1$, então $\var \varphi = \var \varphi_1$.
	
	\item Se $\varphi$ é da forma $\varphi_1 \lor \varphi_2$ ou $\varphi_1 \land \varphi_2$, então $\var \varphi = \var \varphi_1 \cup \var \varphi_2$.
	\end{itemize}
	\end{definicao*}
	
	\begin{prop*}
	Seja $\varphi$ uma fórmula, $\rho$ uma valoração. Então, $\overline \rho(\varphi)$ depende apenas de $\rho|_{\var \varphi}$. Por outras palavras, se $\rho$ e $\rho'$ são duas valorações tal que para todo $x \in \var \varphi$ se tem $\rho(x) = \rho'(x)$, então $\overline \rho(\varphi) = \overline \rho'(\varphi)$.
	\end{prop*}
	
	\begin{proof}
	Como dito antes, usaremos esta demonstração para exemplificar o conceito de indução em estrutura.
	
	O caso base são as fórmulas atómicas, $\varphi : x$. Como $\overline\rho(\varphi) = \rho(x)$ neste caso, de facto $\overline\rho(\varphi)$ depende apenas de $\rho(x)$, isto é, o valor que $\rho$ toma nos elementos de $\var \varphi = \{x\}$. A demonstração do caso base está terminada.
	
	Fazemos agora o passo de indução. Seja $\varphi$ uma fórmula não-atómica, e suponha-se que o enunciado é verdadeiro para todas as fórmulas mais pequenas do que $\varphi$. Então, partimos do princípio que $\varphi$ é da forma $\neg \varphi_1$, $\varphi_1 \lor \varphi_2$ ou $\varphi_1 \land \varphi_2$. Em qualquer um destes casos, as fórmulas nas quais decompômos $\varphi$ são estritamente mais pequenas do que $\varphi$, pelo que podemos usar nelas a hipótese de indução.
	
	Usemos o caso $\varphi_1 \lor \varphi_2$ como exemplo, sabendo que os outros dois casos são idênticos.
	
	Por hipótese de indução, $\overline\rho(\varphi_1)$ depende apenas de $\rho$ aplicado a $\var \varphi_1$. Da mesma forma, $\overline\rho(\varphi_2)$ depende apenas de $\rho$ aplicado a $\var \varphi_2$. Logo, $\overline\rho(\varphi) = \overline\rho(\varphi_1) \por \overline\rho(\varphi_2)$ depende apenas de $\rho$ aplicado a $\var \varphi_1 \cup \var \varphi_2 = \var \varphi$, o que conclui a demonstração.
	\end{proof}
	
	Voltemos ao problema de identificar tautologias. Existe um conceito mais geral, que é o conceito de `consequência semântica'. A ideia é que às vezes é possível afirmar, \emph{sob certas condições}, que uma fórmula é sempre verdadeira.
	
	Por exemplo, considere-se $\varphi : (a \land c) \lor b \lor (a \land \neg c)$. Esta fórmula não é uma tautologia: por exemplo, a valoração que leva tudo em $\lf$ faz com que esta fórmula fique falsa. No entanto, se uma valoração $\rho$ satisfaz $\overline\rho(a \lor b) = \lt$, então é fácil verificar que de certeza que $\overline\rho(\varphi) = \lt$. Dito de outra forma: sabendo que $\rho$ dá o valor $\lt$ a $a \lor b$, concluímos que $\rho$ dá o valor $\lt$ a $\varphi$. Às vezes, por abuso de linguagem, omitimos as referências a valorações e dizemos apenas `se $a \lor b$ então $\varphi$'.
	
	Antes de generalizarmos este conceito, introduzimos alguma linguagem para nos ajudar a expressar.
	
	\begin{definicao*}
	Seja $\gamma$ uma fórmula, $\rho$ uma valoração. Dizemos que $\rho$ satisfaz $\gamma$, denotado $\rho \Vdash \gamma$, se $\overline\rho(\gamma) = \lt$.
	
	Se em vez de uma fórmula tivermos um conjunto de fórmulas $\Gamma$ (normalmente usamos letras gregas maiúsculas para conjuntos de fórmulas) dizemos que $\rho$ satisfaz $\Gamma$ se $\rho$ satisfizer todas as fórmulas de $\Gamma$. Isto é, simbolicamente,
	\[\rho \Vdash \Gamma \text{ se para todo $\gamma \in \Gamma$ temos } \rho \Vdash \gamma.\]
	\end{definicao*}
	
	\begin{definicao*}
	Seja $\varphi$ uma fórmula e $\Gamma$ um conjunto de fórmulas. Então, dizemos que \emph{$\varphi$ é consequência semântica de $\Gamma$}, representado simbolicamente como
	\[\Gamma \vDash \varphi\]
	se para todas as valorações $\rho$ tal que $\rho \Vdash \Gamma$ temos $\rho \Vdash \varphi$.
	
	Por outras palavras, `se todas as afirmações em $\Gamma$ são verdade, concluímos que $\varphi$ é verdade'.
	
	Normalmente, quando $\Gamma$ é um conjunto finito, abreviamos a notação, omitindo chavetas. Por exemplo, se $\Gamma = \{\gamma_1, \gamma_2, \gamma_3\}$, escreveríamos $\gamma_1, \gamma_2, \gamma_3 \vDash \varphi$.\label{convencao:consequencia}
	
	Isto sugere uma notação para tautologia. De facto, $\varphi$ é uma tautologia sse $\emptyset \vDash \varphi$ (verifique). Escrevendo $\emptyset = \{\}$ e usando a convenção de omitir chavetas, chegamos à notação para tautologias: $\vDash \varphi$.
	
	Outra convenção que seguiremos será abreviar uniões usando vírgulas. Por exemplo, escrever $\Gamma, \alpha, \beta \vDash \varphi$ em vez de $\Gamma \cup \{\alpha, \beta\} \vDash \varphi$.
	\end{definicao*}
	
	A noção de consequência semântica é útil porque, juntamente com uma regra básica que iremos discutir agora, nos permite deduzir verdades novas a partir de verdades conhecidas.
	
	Suponhamos que temos uma afirmação da forma $a \lor b$. Isto significa que pelo menos um dos termos é verdadeiro. Assim sendo, se nos for dito que uma destas duas afirmações é falsa, concluímos que a outra é necessariamente verdadeira, isto é, $a$ falso implica $b$ verdadeiro. Por outras palavras, $a \lor b, \neg a \vDash b$.
	
	Substituindo $a$ por $\neg a$ e partindo do princípio que $\neg \neg a$ é a mesma coisa que $a$, chegamos à conclusão
	\[\neg a \lor b, a \vDash b.\]
	
	Assim sendo, a afirmação $\neg a \lor b$ representa, de alguma forma, `$a$ implica $b$'. Como tal, definimos o símbolo `$a \imply b$' como sinónimo de $\neg a \lor b$, e concluímos a chamada regra de \textit{modus ponens}:
	\[a \imply b, a \vDash b.\]
	
	Esta regra será a fundação do nosso cálculo dedutivo. De facto, veremos que existe um conjunto razoavelmente pequeno de tautologias $T$ tal que qualquer outra tautologia pode ser obtida a partir de aplicação repetida de \textit{modus ponens} a tautologias em $T$. A implicação tem um papel tão central, de facto, que quando definirmos fórmulas rigorosamente usaremos como base os operadores `não' e `implica'.
	
	\smallskip
	
	Terminamos esta secção preliminar com uma introdução ao conceito de metateorema.
	
	A noção de implicação e consequência semântica estão intrinsicamente ligadas. De facto, mostraremos que, em certo sentido, `$a \imply b$ sse $a \vDash b$'. Isto diz-se um metateorema porque relaciona duas `camadas' de verdade: relaciona uma verdade `dentro do sistema' ($a \imply b$) com uma verdade `sobre o sistema' ($a \vDash b$).
	
	\begin{prop*}
	(Metateorema da dedução) Seja $\Gamma$ um conjunto de fórmulas, $a$ e $b$ proposições. Então,
	\[\Gamma, a \vDash b \text{ sse } \Gamma \vDash a \imply b.\]
	\end{prop*}
	
	\begin{proof}\label{dem:mtd}
	($\imply$) Suponha-se que $\Gamma, a \vDash b$. Desejamos mostrar $\Gamma \vDash a \imply b$, isto é, $\Gamma \vDash \neg a \lor b$. Assim sendo, vamos supor que $\rho$ é uma valoração tal que $\rho \Vdash \Gamma$ e mostraremos que $\rho \Vdash \neg a \lor b$.
	
	Existem dois casos: ou $\rho(a) = \lt$ ou $\rho(a) = \lf$.
	
	Se $\rho(a) = \lf$, então $\overline\rho(\neg a \lor b) = (\pnot \lf) \por \rho(b) = \lt \por \rho(b) = \lt$.
	
	Se $\rho(a) = \lt$, então temos que $\rho \Vdash \Gamma \cup \{a\}$, donde, como $\Gamma, a \vDash b$ por hipótese, concluímos que $\rho(b) = \lt$. Concluímos então que $\overline\rho(\neg a \lor b) = (\pnot \lt) \por \lt = \lt$, como desejado.
	
	($\leftarrow$) Suponha-se que $\Gamma \vDash a \imply b$. Seja $\rho$ uma valoração tal que $\rho \Vdash \Gamma \cup \{a\}$. Então, em particular, $\rho \Vdash \Gamma$, donde $\rho \Vdash a \imply b$. Sabemos também que $\rho \Vdash a$, pelo que concluímos $\rho \Vdash \{a \imply b, a\}$. Pela regra de \textit{modus ponens}, como $a \imply b, a \vDash b$, concluímos que $\rho \Vdash b$.
	
	Como partimos do princípio que $\rho$ era uma valoração arbitrária tal que $\rho \Vdash \Gamma \cup \{a\}$ e concluímos $\rho \Vdash b$, temos que $\Gamma \cup \{a\} \vDash b$.
	\end{proof}
	
	Este metateorema marca a primeira ocasião em que a nossa linguagem diz algo sobre si mesma. Frases autorreferenciais terão um papel central quando falarmos dos teoremas de incompletude de Gödel, mas isso terá que esperar até ao terceiro capítulo.
	
	\section{Semântica}
	
	O que se segue assume parcialmente que o leitor já leu a secção anterior. Apesar de não haver precedência explícita ou implícita, algumas das ideias essenciais já foram explicadas, e como tal não serão detalhadas novamente. Por outras palavras, o leitor poderá ler esta secção sem ter lido a anterior, mas se der por si perdido nas definições sem entender o seu significado poderá querer voltar atrás e ler a secção introdutória.
	
	\medskip
	
	Começamos por definir o conceito de fórmula proposicional.
	
	Fixe-se, primeiro, um conjunto, que usaremos em tudo o que se segue, chamado o conjunto das variáveis. Isto é apenas um conjunto infinito contável\footnote{Algo estranhamente, a cardinalidade exata deste conjunto é relevante. Bastantes argumentos que faremos de futuro necessitam explicitamente da contabilidade de $X$!} de símbolos $X$. Normalmente usamos variáveis como $x$, $y$, $p$, $q$, e permitimos a modificação de símbolos como a adição de apóstrofos ou asteriscos. Os símbolos $c$, $c'$, $c^*$ são considerados distintos. Usaremos a convenção que variáveis serão representadas por letras romanas minúsculas.
	
	\begin{obs}
	Há a necessidade de distinguir uma variável de uma `meta-variável'. Isto é: se falamos na variável $x$, poderá ser ambíguo se nos referimos ao elemento $x \in X$ ou se a letra $x$ é uma incógnita que pode significar uma variável arbitrária.
	
	Para evitar esta ambíguidade, representamos meta-variáveis a negrito: $\bf{x}$. Ou seja: $x$ é o elemento de $X$, enquanto que $\bf x$ é uma incógnita que pode ser substituída por qualquer variável: $x$, $y$, $z$, \dots
	\end{obs}
	
	Há quem defina, agora, fórmulas como sequências de símbolos. Isto parece ser uma definição intuitiva, visto que é assim que representamos fórmulas: sequências de caracteres. No entanto, visto que no futuro teremos que escrever programas que lêm e interpretam estas fórmulas, é mais conveniente definirmos fórmulas pelas respetivas árvores semânticas.
	
	Para esclarecer o que se entende por isto, considere-se a expressão $a \lor b$. Isto consiste de um operador (o operador `ou') aplicado a duas variáveis. Podemos representar isto como uma árvore na seguinte forma:
	
	\begin{center}
	\Tree [.\texttt{or} $a$ $b$ ]
	\end{center}
	
	Podemos, no entanto, considerar expressões mais complexas. Por exemplo, considere-se a expressão $(a \land b) \lor \neg (b \lor \neg c)$. Interpretada como uma árvore, esta expressão fica
	
	\begin{center}
	\Tree [.\texttt{or} [.\texttt{and} $a$ $b$ ] [.\texttt{not} [.\texttt{or} $b$ [.\texttt{not} $c$ ] ] ] ]
	\end{center}
	
	Para os nossos propósitos, é mais fácil manipular àrvores do que sequências de caracteres. Assim sendo, é com base nesta perspetiva que definimos o conjunto das fórmulas proposicionais.
	
	\begin{definicao}
	Definimos o conjunto das fórmulas proposicionais $\F_p$ (sobre o conjunto $X$, que deixamos implícito) indutivamente.
	
	Qualquer variável $\bf x$ é uma fórmula.
	
	Se $\alpha$ e $\beta$ são fórmulas, ambos os seguintes são fórmulas:
	
	\begin{center}
	\Tree [.\texttt{not} $\alpha$ ]
	\hspace{3em}
	\Tree [.\texttt{implies} $\alpha$ $\beta$ ]
	\end{center}
	
	Esta forma de representar fórmulas não é particularmente eficiente tipográficamente, pelo que, no que se segue, continuaremos a representá-las com a notação linear $\neg \alpha$ e $\alpha \imply \beta$.
	
	Ao darmos nomes a fórmulas, associaremos o nome ao conteúdo usando dois pontos. Por exemplo, para associar o nome $\varphi$ à fórmula $a \lor b$, escreveremos $\varphi : a \lor b$.
	\end{definicao}
	
	\begin{definicao}
	Definimos uma valoração $\rho$ como uma função $\rho : X \to \{\lt,\lf\}$.
	
	Dada uma valoração $\rho$, definimos uma função $\overline\rho : \F_p \to \{\lt, \lf\}$ indutivamente:
	
	\begin{itemize}
	\item Se $\varphi : \bf x$, definimos $\overline\rho(\varphi) = \rho(\bf x)$.
	
	\item Se $\varphi : \neg \alpha$, definimos $\overline\rho(\varphi) = \pnot \overline\rho(\alpha)$.\footnote{Se o leitor não perceber o uso dos operadores $\pnot$ e $\por$, ver página \pageref{tabela:operadores}.}
	
	\item Se $\varphi : \alpha \imply \beta$, definimos $\overline\rho(\varphi) = (\pnot \overline\rho(\alpha)) \por \overline\rho(\beta)$.
	\end{itemize}
	
	Dada uma valoração $\rho$, dizemos que $\rho \Vdash \varphi$ ($\rho$ satisfaz $\varphi$) se $\overline\rho(\varphi) = \lt$. Se em vez de uma fórmula $\varphi$ tivermos um conjunto de fórmulas $\Gamma$, dizemos que $\rho \Vdash \Gamma$ se $\rho \Vdash \gamma$ para todo $\gamma \in \Gamma$.
	\end{definicao}
	
	\begin{definicao}
	Seja $\varphi \in \F_p$, $\Gamma \subseteq \F_p$. Dizemos que $\Gamma \vDash \varphi$ (pronunciado `$\varphi$ é consequência semântica de $\Gamma$') se todas as valorações que satisfazem $\Gamma$ também satisfazem $\varphi$. Por outras palavras, se para todas as valorações $\rho$ tal que $\rho \Vdash \Gamma$ temos $\rho \Vdash \varphi$.
	
	Para abreviar a notação, seguimos algumas convenções, detalhadas na página \pageref{convencao:consequencia}, relacionadas com omissão de chavetas em expressões do género $\{a, b\} \vDash c$.
	
	Dizemos que $\varphi$ é uma tautologia se $\emptyset \vDash \varphi$. Isto pode ser representado como $\vDash \varphi$.
	\end{definicao}
	
	Começamos por apresentar algumas regras de decução que nos ajudarão a mostrar que certas coisas são consequência semântica de outras.
	
	\begin{prop}
	A relação $\vDash$ é transitiva. Isto é:
	
	Sejam $\Gamma, \Phi \subseteq \F_p$ e $\psi \in \F_p$. Suponha-se que $\Gamma \vDash \varphi$ para todo $\varphi \in \Phi$ (Podemos representar isto como $\Gamma \vDash \Phi$) e que $\Phi \vDash \psi$. Então $\Gamma \vDash \psi$.
	\end{prop}
	
	\begin{proof} Suponha-se $\Gamma \vDash \Phi$ e $\Phi \vDash \psi$. Então, para mostrar $\Gamma \vDash \psi$ começamos por supor que $\rho$ é uma valoração tal que $\rho \Vdash \Gamma$. Então, por definição de $\Gamma \vDash \Phi$, temos que $\Gamma \vDash \varphi$ para todo $\varphi \in \Phi$. Como $\rho \Vdash \Gamma$, obtemos que $\rho \Vdash \varphi$ para todo $\varphi \in \Phi$, ou seja, que $\rho \Vdash \Phi$. Finalmente, por definição de $\Phi \vDash \psi$, concluímos que $\rho \Vdash \psi$, terminando a demonstração.
	\end{proof}
	
	\begin{prop} (\textit{Modus ponens}) 
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então, $\alpha \imply \beta, \alpha \vDash \beta$.
	\end{prop}
	
	\begin{proof}
	Suponha-se que $\rho \Vdash \alpha \imply \beta$ e $\rho \Vdash \alpha$. Então, $(\pnot\overline\rho(\alpha))\por\overline\rho(\beta) = \lt$ e $\overline\rho(\alpha) = \lt$. Substituindo $\overline\rho(\alpha)$ por $\lt$ na primeira afirmação, ficamos com $(\pnot\lt)\por\overline\rho(\beta) = \lt$, isto é, $\lf \por \overline\rho(\beta) = \lt$. Para isto acontecer, é necessário que $\overline\rho(\beta) = \lt$, ou seja, $\rho \Vdash \beta$.
	\end{proof}
	
	\begin{prop}
	(Metateorema da dedução)
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então
	\[\Gamma, \alpha \vDash \beta \text{ sse } \Gamma \vDash \alpha \imply \beta.\]
	\end{prop}
	
	\begin{proof}
	Uma possível demonstração é semelhante à demonstração feita na página \pageref{dem:mtd}, com um pequeno detalhe. Essa demonstração foi feita para variáveis $a, b$ em vez de fórmulas $\alpha, \beta$. No entanto, substituindo $\rho(a)$ por $\overline\rho(\alpha)$ e $\rho(b)$ por $\overline\rho(\beta)$, a demonstração funciona sem modificações. Apresentamos, no entanto, uma demonstração ligeiramente diferente de ($\leftarrow$), que exemplifica as proposições acima.
	
	Suponha-se que $\Gamma \vDash \alpha \imply \beta$. É trivial reparar que $\Gamma, \alpha \vDash \Gamma$ (verifique). Por transitividade,
	\begin{equation}\label{eq:mtd:1}
	\Gamma, \alpha \vDash \alpha \imply \beta.
	\end{equation}
	
	Sabemos também que
	\begin{equation}\label{eq:mtd:2}
	\Gamma, \alpha \vDash \alpha.
	\end{equation}
	
	Juntando as afirmações \eqref{eq:mtd:1} e \eqref{eq:mtd:2}, obtemos que $\Gamma, \alpha \vDash \{\alpha \imply \beta, \alpha\}$. A regra de \textit{modus ponens} diz-nos que $\{\alpha \imply \beta, \alpha\} \vDash \beta$, pelo que, por transitividade, $\Gamma, \alpha \vDash \beta$, como desejado.
	\end{proof}
	
	O leitor poderá ter reparado que os símbolos $a \land b$ e $a \lor b$ não foram definidos, visto que na nossa definição de fórmula englobámos apenas as operações $\neg a$ e $a \imply b$. Visto que o uso dos operadores $\land$ e $\lor$ são convenientes, definimo-los por abreviatura. Ou seja, escrevemo-los em termos de `não's e `implica's, e sempre que escrevemos `ou' ou `e' substituimos mentalmente pela abreviatura establecida.
	
	Recordamos o leitor que $\overline\rho(\alpha \imply \beta) = (\pnot \overline\rho(\alpha)) \por \overline\rho(\beta)$, pelo que desejamos escrever os operadores $\por$ e $\pand$ como uma expressão semelhante a esta forma.
	
	Afirmamos que
	\begin{gather*}
	a \por b = (\pnot (\pnot a)) \por b\\
	a \pand b = \pnot ((\pnot a) \por (\pnot b)).
	\end{gather*}
	
	Pelo que estabelecemos as seguintes abreviaturas:
	
	\begin{itemize}
	\item Quando escrevemos $\alpha \lor \beta$, substituimos mentalmente por $\neg \alpha \imply \beta$.
	
	\item Quando escrevemos $\alpha \land \beta$, substituimos mentalmente por $\neg (\alpha \imply \neg \beta)$.
	
	\item Estabelecemos também a abreviatura $a \eqv b$ como $(a \imply b) \land (b \imply a)$ (que por sua vez é abreviatura de outra expressão, mas achamos por bem não expandir por completo).
	\end{itemize}
	
	Considere-se a noção de equivalência. Estamos habituados a que afirmações equivalentes sejam `a mesma coisa', na medida em que podemos substituir uma afirmação pela outra. Por exemplo, suponha-se que provamos que $\vDash \neg \neg \alpha \eqv \alpha$. (Faremos os detalhes mais tarde.) Agora, suponhamos que se deseja provar uma afirmação na qual aparece $\neg \neg \alpha$, por exemplo, $\beta \imply \neg \neg \alpha$. Seria agradável reduzir isto a mostrar que $\beta \imply \alpha$. Felizmente, verifica-se que este tipo de atalhos é admissível. É nisto que consiste o \emph{metateorema da substituição de equivalentes}.
	
	Antes de estudarmos a relação de equivalência, no entanto, vale a pena investigar o símbolo $\land$, visto que este consta na definição de $\eqv$.
	
	\begin{prop}\label{prop:conj:prop:sem}
	Sejam $\alpha, \beta \in \F_p$. Então, $\alpha, \beta \vDash \alpha \land \beta$ e $\alpha \land \beta \vDash \{\alpha, \beta\}$.
	\end{prop}
	
	\begin{proof}
	Para mostrar isto, basta mostrar que, se $\rho$ é uma valoração arbitrária, $\rho \Vdash \alpha \land \beta$ sse $\rho \Vdash \{\alpha, \beta\}$.
	
	De facto, $\rho \Vdash \alpha \land \beta$ sse $\overline\rho(\neg(\alpha \imply \neg \beta)) = \lt$ sse $\pnot ((\pnot \overline\rho(\alpha)) \por (\pnot \overline\rho(\beta))) = \lt$. É fácil verificar que isto acontece sse $\overline\rho(\alpha) = \overline\rho(\beta) = \lt$, ou seja, $\rho \Vdash \{\alpha, \beta\}$. Isto conclui a demonstração.
	\end{proof}
	
	Com a informação que já temos até agora, podemos começar a fazer demonstrações sem pensar tanto sobre valorações e casos possíveis. Exemplificamos demonstrando que $\alpha \eqv \neg \neg \alpha$.
	
	\begin{prop}\label{alphaeqvnegnegalpha}
	Para qualquer $\alpha \in \F_p$, $\vDash \alpha \eqv \neg \neg \alpha$.
	\end{prop}
	
	\begin{proof}
	Primeiro que tudo, é preciso observar a `meta-equivalência' trivial:
	\[\pnot \pnot x = x.\]
	
	Usando isto, concluímos que $\alpha \vDash \neg \neg \alpha$ e $\neg \neg \alpha \vDash \alpha$. Aplicando o metateorema da dedução a cada um destes, obtemos $\vDash \{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\}$. Usando a proposição \ref{prop:conj:prop:sem}  temos que $\{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\} \vDash (\alpha \eqv \neg \neg \alpha)$ (recorde-se da definição de equivalência por abreviatura), e por transitividade, como $\emptyset \vDash \{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\} \vDash (\alpha \eqv \neg \neg \alpha)$, temos $\emptyset \vDash \alpha \eqv \neg \neg \alpha$.
	\end{proof}
	
	Repare-se que a maior parte da demonstração que acabámos de fazer consistiu em passar de `$\alpha \vDash \beta$ e $\beta \vDash \alpha$' para `$\vDash \alpha \eqv \beta$'. Agora que sabemos que este tipo de raciocínios é válido, abreviaremos as nossas demonstrações na medida em que deixamos esta passagem para o leitor. Por exemplo:
	
	\begin{prop}
	Para qualquer $\alpha \in \F_p$, $\vDash (\alpha \land \beta) \eqv (\beta \land \alpha)$.
	\end{prop}
	
	\begin{proof}
	Sabemos que $\alpha \land \beta \vDash \{\alpha, \beta\}$. Como $\{\alpha, \beta\} = \{\beta, \alpha\}$, obtemos que $\{\alpha, \beta\} \vDash \beta \land \alpha$. Por transitividade, conclui-se $(\alpha \land \beta) \vDash (\beta \land \alpha)$. Reproduzindo a demonstração com o papel de $\alpha$ e $\beta$ trocado, damos a prova por concluída.
	\end{proof}
	
	Visto que já temos ferramentas para mostrar equivalências, passamos agora à proposição que nos permite fazer uso de equivalências. Antes de o podermos fazer, no entanto, precisamos de formalizar o que significa `substituir'.
	
	A ideia essencial é que pretendemos, numa fórmula $\varphi$, substituir certas instâncias de uma expressão $\alpha$ por uma outra expressão (presumivelmente equivalente) $\beta$. Por exemplo, passar de $\varphi : a \land \neg \neg (b \imply c)$ para $\psi : a \land (b \imply c)$, e depois possívelmente para $\theta : (b \imply c) \land a$. Para podermos manipular o conceito de substituição e demonstrar coisas sobre ele, precisamos de o definir de forma rigorosa. Como o leitor poderá estar à espera, fá-lo-emos de forma indutiva.
	
	\begin{definicao}
	Sejam $\varphi, \psi, \alpha, \beta \in \F_p$. Dizemos que \emph{$\psi$ é obtido de $\varphi$ por substituição de $\alpha$ por $\beta$} se:
	
	\begin{itemize}
	\item Caso base: Se $\varphi$ e $\psi$ são a mesma fórmula.
	
	\item Substituição: Se $\varphi : \alpha$ e $\psi : \beta$.
	
	\item Passo de indução (negação): Se $\varphi : \neg \varphi_1$, $\psi : \neg \psi_1$ e $\psi_1$ é obtido de $\varphi_1$ por substituição de $\alpha$ por $\beta$.
	
	\item Passo de indução (implicação): Se $\varphi : \varphi_1 \imply \varphi_2$, $\psi : \psi_1 \imply \psi_2$, $\psi_1$ é obtido de $\varphi_1$ por substituição de $\alpha$ por $\beta$ e $\psi_2$ é obtido de $\varphi_2$ por substituição de $\alpha$ por $\beta$.
	\end{itemize}
	\end{definicao}
	
	Note-se que esta definição é particularmente complexa, e aplicá-la na prática é chato. Claro que isto corresponde simplesmente à noção intuitiva de `pegar nalguns $\alpha$, apagá-los, e escrever $\beta$ no seu lugar', pelo que, ao afirmar que duas fórmulas são obtidas uma da outra por substituição, não nos daremos ao trabalho de fazer uma inteira justificação com base nestes casos todos. No entanto, se o leitor estiver confuso com a definição é recomendado tentar aplicá-la a alguns exemplos de substituição de fórmulas.
	
	Podemos finalmente passar à demonstração de:
	
	\begin{prop}
	(Metateorema de substituição de equivalentes) Sejam $\varphi, \psi, \alpha, \beta \in \F_p$ e $\Gamma \subseteq \F_p$. Suponha-se que $\Gamma \vDash \alpha \eqv \beta$ e que $\psi$ é obtido de $\varphi$ por substituição de $\alpha$ por $\beta$. Então,
	\[\Gamma \vDash \varphi \eqv \psi.\]
	\end{prop}
	
	\begin{proof}
	Como esperado, fazemos uma prova por indução usando a definição de $\psi$ ser obtido de $\varphi$ por substituição.
	
	\smallskip
	\textbf{Casos base:}
	
	Se $\varphi$ e $\psi$ são a mesma fórmula, então basta reparar que $\varphi \eqv \varphi$ é uma tautologia (deixamos a demonstração disto para o leitor).
	
	Se $\varphi : \alpha$ e $\psi : \beta$, a afirmação $\Gamma \vDash \varphi \eqv \psi$ é dada como hipótese.
	
	\smallskip
	\textbf{Passo de indução:}
	
	Se $\varphi : \neg \varphi_1$ e $\psi : \neg \psi_1$, onde $\psi_1$ é obtido de $\varphi_1$ por substituição, usamos a hipótese de indução para afirmar que $\Gamma : \varphi_1 \eqv \psi_1$. Basta agora mostrar que $\varphi_1 \eqv \psi_1 \vDash (\neg \varphi_1) \eqv (\neg \psi_1)$, e a conclusão decorre por transitividade. Deixamos a demonstração deste facto auxiliar como exercício para o leitor, de modo a não quebrar o raciocínio.
	
	Se $\varphi : \varphi_1 \imply \varphi_2$ e $\psi : \psi_1 \imply \psi_2$, onde $\psi_1$ e $\psi_2$ são obtidos por substituição a partir de $\varphi_1$ e $\varphi_2$, respetivamente, podemos aplicar a hipótese de indução para afirmar que $\Gamma \vDash \varphi_1 \eqv \psi_1$ e $\Gamma \vDash \varphi_2 \eqv \psi_2$. Por transitividade, é suficiente mostrar que $\{\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2\} \vDash (\varphi_1 \imply \varphi_2) \eqv (\psi_1 \imply \psi_2)$.
	
	Faremos a demonstração deste último facto aplicando repetidamente o metateorema da dedução. Mostraremos que
	\begin{equation}\label{eq:mse:1}
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2, \varphi_1 \imply \varphi_2, \psi_1 \vDash \psi_2.
	\end{equation}
	
	Ora, repare-se que $\varphi_1 \eqv \psi_1 \vDash \psi_1 \imply \varphi_1$, como se pode mostrar recorrendo à definição por abreviatura de $\eqv$ e a propriedades essenciais de $\land$ (proposição \ref{prop:conj:prop:sem}). De igual modo, $\varphi_2 \eqv \psi_2 \vDash \varphi_2 \imply \psi_1$. Assim sendo,
	\[\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2, \varphi_1 \imply \varphi_2, \psi_1 \vDash \psi_1, \psi_1 \imply \varphi_1, \varphi_1 \imply \varphi_2, \varphi_2 \imply \psi_2.\]
	
	Aplicando repetidamente modus ponens, chegamos à conclusão que desta última sequência de termos se conclui $\psi_2$, pelo que, por transitividade, a equação \eqref{eq:mse:1} é verdadeira. Aplicando agora o metateorema da dedução duas vezes, conclui-se
	\[
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2  \vDash (\varphi_1 \imply \varphi_2) \imply (\psi_1 \imply \psi_2).
	\]
	
	Repetindo o argumento com o papel de $\varphi$ e $\psi$ trocados, obtemos a implicação inversa, pelo que aplicando a proposição \ref{prop:conj:prop:sem} concluímos, finalmente,
	\[
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2  \vDash (\varphi_1 \imply \varphi_2) \eqv (\psi_1 \imply \psi_2).
	\]
	\end{proof}
	
	Mostramos agora um conjunto de aplicações do metateorema de substituição de equivalentes que nos será útil no futuro, quando precisarmos do operador $\lor$.
	
	Começamos por realçar duas propriedade com a qual o leitor já estará familiar: o princípio do contrarrecíproco e as leis de deMorgan.
	
	\begin{prop}
	(Contrarrecíproco)
	
	Se $\alpha$ e $\beta$ são fórmulas, temos a seguinte equivalência:
	
	\begin{equation}
	\vDash (\alpha \imply \beta) \eqv (\neg \beta \imply \neg \alpha)
	\end{equation}
	\end{prop}
	
	\begin{proof}
	Faremos esta demonstração `à bruta', usando o nosso conhecimento dos operadores $\pnot$ e $\por$.
	
	Sabemos que, se $\rho$ é uma valoração,
	\begin{align*}
	\rho \Vdash (\alpha \imply \beta) &\text{ sse } (\pnot \overline\rho(\alpha)) \por \overline\rho(\beta) = \lt\\
	&\text{ sse } (\pnot \pnot \overline\rho(\beta)) \por (\pnot \overline\rho(\alpha)) = \lt\\
	&\text{ sse } (\pnot \overline\rho(\neg \beta)) \por \overline\rho(\neg \alpha) = \lt\\
	&\text{ sse } \rho \Vdash (\neg \beta \imply \neg \alpha).
	\end{align*}
	
	Isto mostra que $\alpha \imply \beta \vDash \neg \beta \imply \neg \alpha$ e vice-versa, o que, através de duas aplicações do metateorema da dedução e uso de propriedades do operador $\land$, nos permite chegar à conclusão que
	
	\begin{equation*}
	\vDash (\alpha \imply \beta) \eqv (\neg \beta \imply \neg \alpha),
	\end{equation*}
	como desejado.
	\end{proof}
	
	\begin{prop}\label{demorgan}
	(Leis de deMorgan)
	
	Se $\alpha$ e $\beta$ são fórmulas, temos as seguintes equivalências:
	
	\begin{gather}
	\vDash \neg (\alpha \land \beta) \eqv (\neg \alpha \lor \neg \beta)\label{demorgan1}\\
	\vDash \neg (\alpha \lor \beta) \eqv (\neg \alpha \land \neg \beta)\label{demorgan2}
	\end{gather}
	\end{prop}
	
	\begin{proof}
	Recordemo-nos das definições por abreviatura de $\lor$ e $\land$.
	
	\begin{gather}
	\alpha \land \beta \text{ é o mesmo que } \neg (\alpha \imply \neg \beta)\\
	\alpha \lor \beta \text{ é o mesmo que } (\neg \alpha \imply \beta)
	\end{gather}
	
	Substituindo nas expressões \eqref{demorgan1} e \eqref{demorgan2}, fica claro que a demonstração é mera aplicação repetida do metateorema da substituição de equivalentes usando a equivalência $\alpha \eqv \neg \neg \alpha$.
	\end{proof}
	
	As leis de deMorgan encontram alguma utilidade em provar coisas sobre o operador $\lor$, visto que neste momento só temos informação sobre $\land$.
	
	\begin{lema}\label{lemaou}
	Se $\alpha, \beta$ e $\varphi$ são fórmulas, a seguinte fórmula é uma tautologia:
	\begin{equation}\label{eq:lemaou}
	\vDash (\alpha \imply \varphi) \imply ((\beta \imply \varphi) \imply ((\alpha \lor \beta) \imply \varphi))
	\end{equation}
	\end{lema}
	
	\begin{proof}
	Usando o princípio do contrarrecíproco e o metateorema da equivalência, conclui-se que para provar \eqref{eq:lemaou} é necessário e suficiente mostrar
	\begin{equation}
	\vDash (\neg \varphi \imply \neg \alpha) \imply ((\neg \varphi \imply \neg \beta) \imply (\neg \varphi \imply \neg (\alpha \lor \beta))),
	\end{equation}
	e uma aplicação das leis de deMorgan diz-nos que isto é equivalente a mostrar
	\begin{equation}
	\vDash (\neg \varphi \imply \neg \alpha) \imply ((\neg \varphi \imply \neg \beta) \imply (\neg \varphi \imply (\neg \alpha \land \neg \beta))).
	\end{equation}
	
	O problema está agora reduzido a aplicação generosa do metateorema da dedução, \textit{modus ponens} e propriedades elementares (proposição \ref{prop:conj:prop:sem}) do operador $\land$.
	\end{proof}
	
	\section{Sintática}
	
	Como explicado na secção preliminar, o nosso objetivo final será arranjar uma forma sistemática de descobrir que afirmações são tautologias. Um pouco mais geralmente, dado um conjunto de afirmações $\Gamma$ (`hipóteses'), queremos arranjar um método para decidir, dada uma fórmula $\varphi$, se $\Gamma \vDash \varphi$. Para mais, queremos fazer isto sem recorrer a valorações, visto que, quando estivermos a trabalhar num contexto mais geral do que o cálculo proposicional, não teremos a vantagem de universos finitos.
	
	Para o fazer, formalizamos a noção de demonstração, baseando-nos na nossa experiência a escrever provas.
	
	Ao redigirmos provas geralmente escrevemos coisas linearmente (uma sequência de afirmações), em que novas afirmações são justificadas com base em conhecimento prévio. Algumas afirmações são hipóteses (1) do teorema que estamos a tentar provar, algumas delas são afirmações que são simplesmente logicamente válidas (2), e algumas são consequências de afirmações anteriores (3). Para exemplificar, considere-se a seguinte demonstração em linguagem natural. Os passos estão anotados consoante a qual destes tipos de afirmação correspondem.
	
	\medskip
	
	\textbf{Proposição:} Sejam $a$ e $b$ valores de verdade tal que $a \por b = \lt$ e $b = \lf$. Então, $a = \lt$.
	
	\begin{adjustwidth}{1cm}{}
	1: Hipótese: $a \por b = \lt$ (1)\\
	2: Axioma: Se $a \por b = \lt$ então $a = \lt$ ou $b = \lt$ (2)\\
	3: Como consequência das linhas 1 e 2: $a = \lt$ ou $b = \lt$. (3)\\
	4: Hipótese: $b = \lf$ (1)\\
	5: Axioma: Se sabemos $a = \lt$ ou $b = \lt$, mas $b \neq \lt$, então $a = \lt$ (2)\\
	6: Como consequência das linhas 3 e 4: $a = \lt$. (3)
	\end{adjustwidth}
	
	\medskip
	
	Claro que isto pressupõe uma noção de `axiomas', ou pelo menos, afirmações tomadas como verdadeiras sem justificação. Uma escolha óbvia para o nosso caso seria tomar como axiomas todas as tautologias, mas é precisamente o problema de encontrar as tautologias que estamos a tentar resolver! No entanto, o seu uso é instrutivo e não totalmente inútil, visto que, apesar de tudo, o problema de encontrar consequências semânticas não fica trivializado. Isto é, a seguinte questão ainda requer algum trabalho:
	
	\begin{center}
	Sejam $\Gamma \subseteq \F_p$ e $\varphi \in \F_p$. Será possível construir uma demonstração cuja conclusão seja $\varphi$, usando como axiomas as tautologias e como hipóteses as fórmulas em $\Gamma$?
	\end{center}
	
	Em breve formalizaremos a noção de demonstração, mas a ideia principal é que criaremos um sistema em que algumas afirmações podem ser demonstradas e outras não. O objetivo é que as afirmações que podem ser demonstradas são exatamente aquelas que são verdadeiras. Ou seja, se demonstramos uma afirmação, ela tem que ser verdadeira (chamamos a isto correção), e se uma afirmação é verdadeira terá que existir uma prova dela (chamamos a isto completude). Em lógica, é normalmente bastante fácil assegurar correção de sistemas de demonstração --- basta certificarmo-nos que todos os passos individuais estão corretos ---, mas provar que qualquer afirmação verdadeira pode ser demonstrada é uma história completamente diferente!
	
	De agora em diante, tomaremos como conjunto de axiomas (chamamos a este conjunto $A$) as tautologias. De futuro, veremos que este conjunto pode ser drásticamente reduzido.
	
	\textbf{Se o leitor deseja ver os axiomas finais,} poderá avançar para a página \pageref{def:prop:ax}. Não há perda de continuidade em ler esta secção mesmo sabendo os axiomas, tendo conhecimento que em qualquer momento que invocamos uma tautologia como axioma, podemos substituir essa invocação por uma demonstração (com base nos axiomas finais) da fórmula em questão.
	
	\begin{definicao}
	Seja $\Gamma \subseteq \F_p$. Uma demonstração com base em $\Gamma$, ou demonstração que tem $\Gamma$ como hipóteses, é uma sequência finita
	\[(\varphi_1, j_1), (\varphi_2, j_2), \dots, (\varphi_n, j_n)\]
	onde cada $\varphi_i$ é uma fórmula proposicional, e o respetivo $j_i$ (que simboliza a justificação de $\varphi_i$) satisfaz as seguintes regras:
	
	\begin{itemize}
	\item Cada $j_i$ é um símbolo da forma \texttt{Ax}, \texttt{Hip} ou $\texttt{MP}_{ab}$, com $a,b \in \N$
	
	\item Se $j_i = \texttt{Ax}$ é necessário que $\varphi_i \in A$, onde $A$ é o conjunto de axiomas. Recordamos que, neste momento, $A$ é para nós o conjunto das tautologias.
	
	\item Se $j_i = \texttt{Hip}$ é necessário que $\varphi_i \in \Gamma$
	
	\item Se $j_i = \texttt{MP}_{ab}$, então $a, b < i$ e $\varphi_a$ é a fórmula $\varphi_b \imply \varphi_i$.
	
	Por outras palavras, se $\varphi_a$ é da forma $\alpha \imply \beta$ e $\varphi_b$ é a fórmula $\alpha$, então podemos concluír a fórmula $\beta$, com a justificação $\texttt{MP}_{ab}$ (\textit{Modus ponens}, com hipóteses $a$ e $b$).
	\end{itemize}
	\end{definicao}
	
	\begin{definicao}
	Dizemos que $\varphi \in \F_p$ é um teorema de $\Gamma \subseteq \F_p$, denotado
	\[\Gamma \vdash \varphi\]
	se existe uma demonstração com base em $\Gamma$ cuja última afirmação seja $\varphi$.
	\end{definicao}
	
	Antes de começarmos a mostrar propriedades deste sistema, vamos ver algumas demonstrações para entender como é que o sistema funciona.
	
	\begin{prop*}
	Se $\alpha \in \F_p$ então $\vdash \alpha \eqv \neg \neg \alpha$.
	\end{prop*}
	\begin{proof}
	Recordamos primeiro o leitor da convenção de omissão de chavetas, segundo a qual a afirmação $\vdash \alpha \eqv \neg \neg \alpha$ é abreviatura de $\{\} \vdash \alpha \eqv \neg \neg \alpha$, ou seja, `$\alpha \eqv \neg \neg \alpha$ pode ser provado sem hipóteses'.
	
	Pela proposição \ref{alphaeqvnegnegalpha}, a afirmação $\alpha \eqv \neg \neg \alpha$ é uma tautologia. Assim sendo, temos uma demonstração particularmente concisa:
	\[(\alpha \eqv \neg \neg \alpha, \texttt{Ax}).\]
	\end{proof}
	
	\begin{prop*}
	Se $\alpha, \beta, \gamma \in \F_p$ então $\alpha \imply (\beta \imply \gamma), \alpha \land \beta \vdash \gamma$.
	\end{prop*}
	\begin{proof}
	Apresentamos a seguinte demonstração, que não é a mais direta. De facto, como veremos em breve, qualquer demonstração com um número finito $n$ de hipóteses pode ser feito de forma extremamente expedita em apenas $2n+1$ passos. No entanto, as tautologias necessárias para o fazer podem ser complicadas, pelo que apresentamos uma prova que usa apenas tautologias evidentes.
	
	\begin{align*}
	&\alpha \imply (\beta \imply \gamma) &\texttt{Hip}\\
	&\alpha \land \beta &\texttt{Hip}\\
	&\alpha \land \beta \imply \alpha &\texttt{Ax}&&\text{Aplicar MTD à prop \ref{prop:conj:prop:sem}}\\
	&\alpha &\texttt{MP}_{3,2}\\
	&\beta \imply \gamma &\texttt{MP}_{1, 4}\\
	&\alpha \land \beta \imply \beta &\texttt{Ax}&&\text{Aplicar MTD à prop \ref{prop:conj:prop:sem}}\\
	&\beta &\texttt{MP}_{6,2}\\
	&\gamma &\texttt{MP}_{5,7}
	\end{align*}
	\end{proof}
	
	\bigskip
	
	Como mencionado anteriormente, há duas coisas que queremos que a nossa relação $\vdash$ satisfaça. Queremos que se $\Gamma \vdash \varphi$ então $\Gamma \vDash \varphi$ (correção), e queremos que se $\Gamma \vDash \varphi$ então $\Gamma \vdash \varphi$ (completude). A primeira propriedade é a mais fácil de verificar, e como tal, será a primeira que vamos provar.
	
	\begin{prop}
	Seja $\Gamma \subseteq \F_p$, $\varphi \in \F_p$. Suponha-se que $\Gamma \vdash \varphi$. Então, $\Gamma \vDash \varphi$.
	\end{prop}
	
	\begin{proof}
	Se $\Gamma \vdash \varphi$, existe uma demonstração de $\varphi$ com base em $\Gamma$. Suponha-se que esta é dada por $(\varphi_1, j_1), \dots, (\varphi_n, j_n)$. Mostraremos por indução que todos os $\varphi_i$ são consequência semântica de $\Gamma$, e portanto, em particular, $\Gamma \vDash \varphi_n$, ou seja, $\Gamma \vDash \varphi$.
	
	Faremos esta prova usando o princípio de indução forte:
	
	\begin{center}
	Seja $S$ um subconjunto dos naturais. Suponha-se que para todo $n \in \N$ o conjunto $\N \cap \left[0,n\right[$ está contido em $S$. Então, o princípio de indução forte diz que $S = \N$.\footnote{Para justificar este princípio: suponha-se que $S \neq \N$. Então, $\N \setminus S$ é não-vazio. Qualquer subconjunto não-vazio dos naturais tem mínimo; seja, então, $n$ o mínimo de $\N \setminus S$. Por definição de mínimo, temos que $\N \cap \left[0, n\right[ \subseteq S$, e, por hipótese, isto implica que $n \in S$. Contradição, pelo que $\N \setminus S$ tem que ser vazio e portanto $S = \N$.} Note-se que não é necessário provar caso base.
	\end{center}
	
	Seja $i$ um índice tal que para todo $i' < i$ se tem $\Gamma \vDash \varphi_{i'}$. Então, mostramos que $\Gamma \vDash \varphi_i$. A prova consiste em examinar a justificação de $\varphi_i$, isto é, $j_i$.
	
	\begin{itemize}
	\item Se $j_i = \texttt{Hip}$, então $\varphi_i \in \Gamma$, donde $\Gamma \vDash \varphi_i$ trivialmente.
	
	\item Se $j_i = \texttt{Ax}$, então $\varphi_i \in A$, donde $\varphi_i$ é uma tautologia. Isto claramente implica $\Gamma\vDash\varphi_i$.
	
	\item Se $j_i = \texttt{MP}_{ab}$, basta usar a transitividade da consequência semântica. Por hipótese, $\Gamma \vDash \{\varphi_a, \varphi_b\}$. Por definição de demonstração, $\varphi_a$ é a fórmula $\varphi_b \imply \varphi_i$. Pela regra de \textit{modus ponens}, $\{\varphi_b \imply \varphi_i, \varphi_b\} \vDash \varphi_i$, pelo que, por transitividade, $\Gamma \vDash \varphi_i$, como desejado.
	\end{itemize}
	\end{proof}
	
	Iniciamos agora a demonstração da completude do cálculo. Fazemos primeiro notas que, sob certas condições, esta é uma trivialidade:
	
	\begin{prop}
	Sejam $\Gamma \subseteq \F_p$ e $\varphi \in \F_p$ tal que $\Gamma \vDash \varphi$. Suponha-se, em adição, que $\Gamma = \{\gamma_1, \dots, \gamma_n\}$ é finito. Então, $\Gamma \vdash \varphi$.
	\end{prop}
	
	\begin{proof}
	Por aplicação repetida do metateorema de dedução, sabendo que $\Gamma \vDash \varphi$ obtemos que $\vDash \gamma_1 \imply (\gamma_2 \imply \dots (\gamma_n \imply \varphi) \dots )$. Assim sendo, esta última fórmula é uma tautologia, e então um axioma. Como tal, considere-se a seguinte demonstração, com base em $\Gamma$:
	\begin{align*}
	&\gamma_1 \imply (\gamma_2 \imply (\gamma_3 \imply \dots (\gamma_n \imply \varphi) \dots )) &&\texttt{Ax}\\
	&\gamma_1 &&\texttt{Hip}\\
	&\gamma_2 \imply (\gamma_3 \imply \dots (\gamma_n \imply \varphi) \dots ) &&\texttt{MP}_{12}\\
	&\gamma_2 &&\texttt{Hip}\\
	&\gamma_3 \imply ( \dots (\gamma_n \imply \varphi) \dots)  &&\texttt{MP}_{34}\\
	&\vdots&&\vdots\\
	&\gamma_n \imply \varphi &&\texttt{MP}_{\dots}\\
	&\gamma_n &&\texttt{Hip}\\
	&\varphi &&\texttt{MP}_{\dots}
	\end{align*}
	
	Isto é uma demonstração com todas as suas hipóteses em $\Gamma$, cuja conclusão é $\varphi$, pelo que $\Gamma \vdash \varphi$ como desejado.
	\end{proof}
	
	Isto mostra que o maior obstáculo para a completude é a possibilidade de haver infinitas hipóteses.
	
	Para demonstrar a completude no caso geral, uma demonstração direta não é um bom plano de ataque. De facto, para mostrar que $\Gamma \vDash \varphi$ implica $\Gamma \vdash \varphi$ seria necessário partir de uma hipótese sobre o conjunto das valorações, e, a partir disso, construír uma demonstração. O problema é que as valorações não nos dizem grande coisa sobre como poderíamos construir a demonstração.
	
	Recorremos então ao princípio do contrarrecíproco. Isto é, provaremos a afirmação equivalente: $\Gamma \nvdash \varphi$ implica $\Gamma \nvDash \varphi$. Partimos do princípio que não existe uma demonstração de $\varphi$ a partir de $\Gamma$ e pretendemos construír uma valoração $\rho$ tal que $\rho \Vdash \Gamma$ mas $\rho \nVdash \varphi$. Felizmente, a construção de valorações é um processo razoávelmente simples, visto que é como resolver equações. Cada $\gamma \in \Gamma$ dá-nos uma `equação que $\rho$ tem que satisfazer', e juntando a estas a condição que $\rho$ satisfaça $\neg \varphi$, ficamos com um `sistema com infinitas incógnitas' ($\rho(x)$, $\rho(y)$, \dots), e a nossa esperança seria que, de alguma forma, a hipótese que não há demonstrações de $\Gamma \vdash \varphi$ fosse em algum sentido equivalente a `este sistema é não-singular'.
	
	A ideia será construir $\rho$ de forma gananciosa, atribuindo valores às variáveis sequencialmente. Cada variável nova que atribuímos `adiciona uma condição a $\Gamma$', e se nos certificarmos a cada passo que não quebramos a condição $\Gamma \nvdash \varphi$, no final acabaremos com a valoração desejada.
	
	Seguem-se os detalhes formais.
	
	\begin{teorema}
	Sejam $\Gamma \subseteq \F_p$ e $\varphi \in \F_p$ tal que $\Gamma \nvdash \varphi$. Então, $\Gamma \nvDash \varphi$.
	\end{teorema}
	
	\begin{proof}
	Esta demonstração é bastante elaborada, pelo que alguns detalhes são remetidos para lemas que serão demonstrados no final.
	
	Construiremos indutivamente uma valoração $\rho$ tal que $\rho \Vdash \Gamma$ e $\rho \nVdash \varphi$. Para o fazer, pressupomos uma enumeração $\bf x_1, \bf x_2, \dots$ de $X$. (Usamos aqui que o conjunto das variáveis, $X$, é contável!)
	
	Para definir $\rho(\bf x_1)$, averigue-se se $\Gamma, \bf x_1 \vdash \varphi$. Isto é: será que adicionando a afirmação `$\bf x_1$ é verdadeiro' às nossas hipóteses conseguimos demonstrar $\varphi$?
	
	\begin{itemize}
	\item Em caso afirmativo, o nosso $\rho$ não poderá atribuir $\rho(\bf x_1) = \lt$, ou então o `sistema' a resolver ($\rho \nVdash \varphi$) ficava impossível! Assim sendo, definimos $\rho(\bf x_1) = \lf$. 
	
	\item Em caso negativo, não haverá problema em definir $\rho(\bf x_1) = \lt$.
	\end{itemize}
	
	Podemos agora definir $\rho(\bf x_2)$, tendo em atenção que $\rho(\bf x_1)$ está já definido, o que condiciona a nossa escolha. Assim sendo, averiguamos se
	\[\Gamma, r(\bf x_1), \bf x_2 \vdash \varphi,\]
	onde $r(\bf x_1)$ é a fórmula $\bf x_1$ ou $\neg \bf x_1$ dependendo de como definimos $\rho(\bf x_1)$.
	
	Continuamos o processo, definindo $\rho(\bf x_n)$ para todo $n$, seguindo a regra:

	\begin{center}
	Se $\Gamma, r(\bf x_1), \dots, r(\bf x_{n-1}), \bf x_n \vdash \varphi$, definimos $\rho(\bf x_n) = \lf$. Caso contrário, $\rho(\bf x_n) = \lt$.
	\end{center}
	
	Resta agora mostrar que esta valoração $\rho$ satisfaz o desejado. Isto é, pretendemos usá-la para justificar que $\Gamma \nvDash \varphi$, pelo que há duas coisas a mostrar:
	
	\begin{itemize}
	\item Se $\gamma \in \Gamma$ então $\rho \Vdash \gamma$,
	
	\item $\rho \nVdash \varphi$.
	\end{itemize}
	
	Antes de o fazer, mostramos um facto auxiliar:
	\begin{equation}\label{eq:comp:prop:-1}
	\Gamma, r(\bf x_1), r(\bf x_2), \dots \nvdash \varphi.
	\end{equation}
	
	Para mostrar isto, começamos por fazer uma observação que nos será muito útil no futuro: as provas são finitas. Como tal, existe um número finito de hipóteses que se podem invocar, pelo que, assumindo por absurdo que
	\[\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \varphi,\]
	haveria algum $N$ tal que $\Gamma, r(\bf x_1), r(\bf x_2), \dots, r(\bf x_N) \vdash \varphi$. Mostramos por indução em $N$ que tal não pode acontecer, isto é
	\begin{equation}\label{eq:comp:prop:0}
	\text{Para todo $N \in \N_0$, } \Gamma, r(\bf x_1), r(\bf x_2), \dots r(\bf x_N) \nvdash \varphi.
	\end{equation}
	
	\begin{itemize}
	\item Caso base: $N = 0$. Neste caso, a afirmação que se deseja provar reduz-se a $\Gamma \nvdash \varphi$, que é verdadeira por hipótese.
	
	\item Suponha-se verdade para algum $N$, mostre-se verdade para $N+1$. Há dois casos.
	
	Se $\rho(\bf x_{N+1}) = \lt$, então por construção isso significa que
	\[\Gamma, r(\bf x_1), \dots, r(\bf x_N), \bf x_{N+1} \nvdash \varphi,\]
	que, como neste caso $r(\bf x_{N+1})$ é $\bf x_{N+1}$, mostra o desejado.
	
	Se $\rho(\bf x_{N+1}) = \lf$, então, por construção, temos que
	\begin{equation}\label{eq:comp:prop:1}
	\Gamma, r(\bf x_1), \dots, r(\bf x_N), \bf x_{N+1} \vdash \varphi.
	\end{equation}
	
	Faremos os detalhes mais tarde (ver lema \ref{lema:1}), mas a ideia é a seguinte: supondo, por absurdo, que
	\begin{equation}\label{eq:comp:prop:2}
	\Gamma, r(\bf x_1), \dots, r(\bf x_N), \neg \bf x_{N+1} \vdash \varphi,
	\end{equation}
	ter-se-ia, juntando \eqref{eq:comp:prop:1} e \eqref{eq:comp:prop:2},
	\[\Gamma, r(\bf x_1), \dots, r(\bf x_N), \bf x_{N+1} \lor \neg \bf x_{N+1} \vdash \varphi.\]
	
	Sabendo que a hipótese $\bf x_{N+1} \lor \neg \bf x_{N+1}$ é uma tautologia, pode ser retirada das hipóteses (basta substituir qualquer sua invocação como \texttt{Hip} por uma invocação por \texttt{Ax}), pelo que concluímos
	\[\Gamma, r(\bf x_1), \dots, r(\bf x_N) \vdash \varphi,\]
	uma contradição com a hipótese de indução. Conclui-se então que
	\[\Gamma, r(\bf x_1), \dots, r(\bf x_N), \neg \bf x_{N+1} \nvdash \varphi,\]
	como desejado.
	\end{itemize}
	
	Podemos agora mostrar $\rho \nVdash \varphi$. Para o fazer, usaremos um facto que terá que ser provado em detalhe mais tarde (ver lema \ref{lema:3}).
	
	A ideia é que, supondo que $\rho \Vdash \varphi$, das hipóteses $r(\bf x_1), r(\bf x_2), \dots$ consegue-se concluir $\varphi$. Simbolicamente,
	\[r(\bf x_1), r(\bf x_2), \dots \vdash \varphi.\]
	
	Intuitivamente, isto é verdade porque as nossas hipóteses permitem-nos `substituir cada variável pelo seu valor de verdade dado por $\rho$', e a informação $\rho \Vdash \varphi$ permite-nos concluir que `ao avaliar a expressão resultante, obtemos $\lt$'. Claro que isto não é uma demonstração, mas será talvez suficiente para o leitor aceitar o facto como plausível.
	
	Este facto é útil porque, sob esta hipótese, ter-se-ia (visto que não há problema em adicionar hipóteses) que
	\[\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \varphi,\]
	o que entra em contradição com \eqref{eq:comp:prop:0}.
	
	Mostre-se, agora, que para todo $\gamma \in \Gamma$ se tem $\rho \Vdash \gamma$. Usando novamente o lema \ref{lema:3}, temos que, assumindo por absurdo $\rho \nVdash \gamma$, ter-se-ia $\rho \Vdash \neg \gamma$ e como tal
	\begin{equation}\label{eq:comp:prop:3}
	r(\bf x_1), r(\bf x_2), \dots \vdash \neg \gamma.
	\end{equation}
	
	Assim sendo, chegamos às seguintes duas conclusões:
	\begin{gather}
	\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \neg \gamma\label{shownotgamma}\\
	\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \gamma\label{showgamma}
	\end{gather}
	a primeira por \eqref{eq:comp:prop:3}, e a segunda porque $\gamma \in \Gamma$. Recorremos agora ao chamado \emph{princípio da explosão}.
	
	Concatenando as demonstrações de \eqref{shownotgamma} e \eqref{showgamma} e ajustando índices consoante necessário, temos uma demonstração que tem $\Gamma, r(\bf x_1), r(\bf x_2), \dots$ como hipóteses e que mostra, em algum momento, $\gamma$ e $\neg \gamma$.
	
	No fim desta demonstração, adicione-se a linha
	\[(\gamma \imply (\neg \gamma \imply \neg \varphi), \texttt{Ax}\footnote{A verificação de que a fórmula invocada é de facto uma tautologia é deixada ao leitor.}),\]
	seguida de duas aplicações de \textit{modus ponens}, de modo a construir uma prova de
	\[
	\Gamma, r(\bf x_1), r(\bf x_2), \dots \vdash \varphi
	\]
	que é uma contradição com \eqref{eq:comp:prop:-1}.
	
	Isto termina a demonstração de $\rho \Vdash \Gamma$ e $\rho \nVdash \varphi$, pelo que $\Gamma \nvDash \varphi$, como desejado.
	\end{proof}
	
	Falta agora preencher alguns buracos tomados por garantidos nesta demonstração. Antes de o fazermos, mostramos que o cálculo proposicional satisfaz o metateorema da dedução, que nos será muito útil no que se segue. Note-se que, até menção em contrário, não usaremos a completude do cálculo proposicional, visto que, em rigor, ainda não acabámos a sua demonstração!
	
	\begin{prop}
	(Metateorema da dedução, versão sintática)
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então
	
	\[\Gamma, \alpha \vdash \beta \text{ sse } \Gamma \vdash \alpha \imply \beta.\]
	\end{prop}
	\begin{proof}
	Uma das implicações é trivial. ($\leftarrow$) De facto, se $\Gamma \vdash \alpha \imply \beta$, então existe uma demonstração $D$ (de comprimento, digamos, $N$) de $\alpha \imply \beta$ partindo apenas de hipóteses em $\Gamma$. Considere-se então a seguinte demonstração com hipóteses em $\Gamma \cup \{\alpha\}$:
	
	\[[\dots D \dots], (\alpha, \texttt{Hip}), (\beta, \texttt{MP}_{N, N+1})\]
	
	(A invocação de \textit{modus ponens} é justificada porque a $N$-ésima afirmação da prova, isto é, a última afirmação de $D$, é $\alpha \imply \beta$ por hipótese.)
	
	Esta demonstração mostra, então, que $\Gamma, \alpha \vdash \beta$, como desejado.
	\smallskip
	A implicação no outro sentido é um pouco mais elaborada, e introduz a ideia de prova que é construção de demonstrações.
	
	No que se segue, usaremos a sigla MTD com o significado de `metateorema da dedução, versão semântica'.
	
	Vamos partir do princípio que temos uma demonstração de $\Gamma, \alpha \vdash \beta$:
	\[(\varphi_1, j_1), \dots, (\varphi_n, j_n)\]
	e vamos, a partir desta, construir uma demonstração de $\Gamma \vdash \alpha \imply \beta$. Mais concretamente, construiremos uma demonstração (de hipóteses em $\Gamma$)
	\[(\psi_1, j'_1), \dots, (\psi_N, j'_N)\]
	em que alguns dos $\psi$, digamos $\psi_{i_1}, \dots, \psi_{i_n}$ (este último coincidindo com $\psi_N$) correspondem respetivamente a $\alpha \imply \varphi_1, \dots, \alpha \imply \varphi_n$. Esta prova terminará então com $\alpha \imply \beta$ (visto que $\varphi_n$ é $\beta$), pelo que teremos a demonstração desejada de $\Gamma \vdash \alpha \imply \beta$.
	
	Exemplificamos o processo com os primeiros três passos. Considere-se $(\varphi_1, j_1)$.
	
	\begin{itemize}
	\item Se $j_1$ é \texttt{Ax}, isso significa que $\varphi_1$ é uma tautologia. Assim sendo, (por transitividade de $\vDash$ e usando a versão semântica do MTD) temos que $\alpha \imply \varphi_1$ é também uma tautologia, pelo que a nossa prova modificada pode simplesmente começar com
	\[(\alpha \imply \varphi_1, \texttt{Ax}).\]
	
	\item Se $j_1$ é \texttt{Hip}, temos que $\varphi_1 \in \Gamma \cup \{\alpha\}$, pelo que há dois casos a considerar.
	\begin{itemize}
	\item Se $\varphi_1$ é $\alpha$, então basta reparar que a afirmação $\alpha \imply \alpha$ é uma tautologia, pelo que podemos começar a prova modificada com
	\[(\alpha \imply \varphi_1, \texttt{Ax}).\]
	
	\item Se $\varphi_1 \in \Gamma$, é preciso provar, com apenas hipóteses em $\Gamma$, que $\alpha \imply \varphi_1$. Para isto, usamos o facto que a seguinte afirmação é uma tautologia: (Como pode ser demonstrado através de dois usos do MTD)
	\[(\varphi_1 \imply (\alpha \imply \varphi_1), \texttt{Ax})\]
	e continuamos a demonsração modificada com
	\begin{gather*}
	(\varphi_1, \texttt{Hip})\\
	(\alpha \imply \varphi_1, \texttt{MP}_{12})
	\end{gather*}
	\end{itemize}
	
	\item Não consideramos aqui o caso de $j_1 = \texttt{MP}$ por razões óbvias.
	\end{itemize}
	
	O mesmo raciocínio funciona para o segundo passo, e aliás qualquer passo cuja justificação seja \texttt{Ax} ou \texttt{Hip}. Falta agora considerar o caso de \texttt{MP}.
	
	Para propósitos ilustrativos, suponha-se que $j_3 = \texttt{MP}_{12}$. A prova modificada construida até agora terá sido
	\[\dots, (\alpha \imply (\varphi_2 \imply \varphi_3), j_{i_1}), \dots, (\alpha \imply \varphi_2, j_{i_2}).\]
	
	Para completar a prova, precisamos de justificar que de $\alpha \imply (\varphi_2 \imply \varphi_3)$ e $\alpha \imply \varphi_2$ conseguimos concluir $\alpha \imply \varphi_3$.  Para tal, é necessário usar o facto que a seguinte afirmação é uma tautologia:
	
	\[[\alpha \imply (\varphi_2 \imply \varphi_3)] \imply [(\alpha \imply \varphi_2) \imply (\alpha \imply \varphi_3)]\]
	coisa esta que pode ser demonstrada semânticamente através de uso generoso do MTD e MP.
	
	Sabendo este facto, é fácil continuar a demonstração modificada, adicionando as linhas:
	\begin{gather*}
	([\alpha \imply (\varphi_2 \imply \varphi_3)] \imply [(\alpha \imply \varphi_2) \imply (\alpha \imply \varphi_3)], \texttt{Ax})\\
	((\alpha \imply \varphi_2) \imply (\alpha \imply \varphi_3), \texttt{MP}_{i_2 + 1, i_1})\\
	(\alpha \imply \varphi_3, \texttt{MP}_{i_2 + 2, i_2})
	\end{gather*}
	
	Note-se que neste raciocínio focámo-nos nos primeiro, segundo e terceiro passos, mas é evidente que este argumento poderá ser aplicado a todos os passos. Continuando o processo até o $n$-ésimo passo, obtem-se a demonstração modificada desejada, o que conclui a prova.
	\end{proof}
	
	Tal como a sua correspondente versão semântica, a versão sintática do metateorema da dedução é instrumental para simplificar imensas provas. Exemplificamos com o seguinte lema, que foi usado na demonstração de completude.
	
	\begin{lema}\label{lema:1}
	Seja $\Gamma \subseteq \F_p$ e $\alpha, \beta, \varphi \in \F_p$. Suponha-se que $\Gamma, \alpha \vdash \varphi$ e $\Gamma, \beta \vdash \varphi$. Então,
	\[\Gamma, \alpha \lor \beta \vdash \varphi.\]
	\end{lema}
	
	\begin{proof}
	Sabendo que $\Gamma, \alpha \vdash \varphi$, concluímos, pelo metateorema da dedução sintático, que $\Gamma \vdash \alpha \imply \varphi$. Idênticamente, temos que $\Gamma \vdash \beta \imply \varphi$.
	
	Sejam $(\varphi_1, j_1), \dots, (\varphi_n, j_n)$ e $(\psi_1, j'_1), \dots, (\psi_m, j'_m)$ as respetivas provas. Concatenando as duas (e ajustando índices de \texttt{MP}'s quando necessário) obtemos uma prova cuja $n$-ésima entrada é $\alpha \imply \varphi$ e cuja $(n+m)$-ésima entrada é $\beta \imply \varphi$.
	
	Adicionando a esta prova a linha
	\[((\alpha \imply \varphi) \imply [(\beta \imply \varphi) \imply ((\alpha \lor \beta) \imply \varphi)], \texttt{Ax})\]
	(ver lema \ref{lemaou} para justificar que esta é uma tautologia) seguida de duas aplicações de MP, obtemos uma demonstração, com hipóteses em $\Gamma$, de $(\alpha \lor \beta) \imply \varphi$, como desejado.
	\end{proof}
	
	Mostramos agora a versão sintática do metateorema de substituição de equivalentes. Visto que temos ao nosso dispor todas as tautologias como axiomas, juntamente com a versão semântica metateorema de substituição, esta demonstração acaba por ser algo trivial.
	
	\begin{prop}
	(Metateorema de substituição de equivalentes, versão sintática) Sejam $\varphi, \psi, \alpha, \beta \in \F_p$ e $\Gamma \subseteq \F_p$. Suponha-se que $\Gamma \vdash \alpha \eqv \beta$ e que $\psi$ é obtido de $\varphi$ por substituição de $\alpha$ por $\beta$. Então,
	\[\Gamma \vdash \varphi \eqv \psi.\]
	\end{prop}
	
	\begin{proof}
	A primeira observação é que o problema já está resolvido para $\Gamma$ finito. De facto, aplicando a completude do cálculo proposicional para conjuntos de hipóteses finitos, basta recorrer diretamente à versão semântica deste metateorema, visto que, neste caso, $\vdash$ e $\vDash$ são equivalentes.
	
	A segunda observação é que qualquer conjunto de hipóteses pode ser reduzido a um conjunto finito. De facto, sabendo que $\Gamma \vdash \alpha \eqv \beta$, visto que demonstrações são finitas, existe um subconjunto \emph{finito} $\Gamma' \subseteq \Gamma$ tal que $\Gamma' \vdash \alpha \eqv \beta$. Aplicando o metateorema de substituição de equivalentes, que já justificámos para o caso finito, obtemos que $\Gamma' \vdash \varphi \eqv \psi$, que obviamente implica que $\Gamma \vdash \varphi \eqv \psi$, como desejado.
	\end{proof}
	
	Estamos agora em posição de mostrar um lema que foi usado na demonstração da completude do cálculo proposicional, que nos permite fazer uma ponte entre valorações e demonstrações.
	
	\begin{lema}\label{lema:3}
	Seja $\bf x_1, \bf x_2, \dots$ uma enumeração das variáveis, $\rho$ uma valoração e $\varphi$ uma fórmula. Defina-se, para $i = 1, 2, \dots$, $r(\bf x_i)$ como sendo a fórmula $\bf x_i$ se $\rho(\bf x_i) = \lt$ e $\neg \bf x_i$ se $\rho(\bf x_i) = \lf$. Sob estas hipóteses,
	\[\rho \Vdash \varphi \text{ sse } r(\bf x_1), r(\bf x_2), \dots \vdash \varphi.\]
	\end{lema}
	
	\begin{proof}
	($\leftarrow$) Pela correção do cálculo proposicional, se
	\[r(\bf x_1), r(\bf x_2), \dots \vdash \varphi\]
	então
	\[r(\bf x_1), r(\bf x_2), \dots \vDash \varphi.\]
	
	É fácil verificar que $\rho \Vdash r(\bf x_i)$ para todo $i \in \N^+$, pelo que, por definição de consequência semântica, $\rho \Vdash \varphi$, como desejado.
	
	\medskip
	
	($\rightarrow$) Para provar esta implicação, começamos por reparar que o valor de $\overline\rho(\varphi)$ depende apenas do valor de $\rho(\bf x)$ para um número finito de variáveis $\bf x$. Isto pode ser provado diretamente por indução na estrutura da fórmula, ou pode ser feito usando o facto que $\overline\rho(\varphi)$ depende apenas de $\rho|_{\var \varphi}$ e que o conjunto $\var \varphi$ é finito (ambos estes factos justificados por indução na estrutura da fórmula). Assim sendo, existe algum $N$ tal que $\overline\rho(\varphi)$ depende apenas de $\rho(\bf x_1), \dots, \rho(\bf x_N)$. Como tal, partindo do princípio que $\rho \Vdash \varphi$, qualquer valoração $\rho'$ que concorde com $\rho$ nestas variáveis também satisfará $\rho' \Vdash \varphi$.
	
	Repare-se agora que qualquer valoração $\rho'$ que satisfaz
	\[\rho' \Vdash r(\bf x_1), \dots, r(\bf x_N)\]
	está precisamente nestas condições, pelo que $\rho' \Vdash \varphi$. Assim sendo, conclui-se que
	\[r(\bf x_1), \dots, r(\bf x_N) \vDash \varphi.\]
	
	Pela completude do cálculo proposicional no caso finito, obtem-se
	\[r(\bf x_1), \dots, r(\bf x_N) \vdash \varphi,\]
	e visto que não há problema em adicionar hipóteses, temos
	\[r(\bf x_1), r(\bf x_2), \dots \vdash \varphi\]
	como desejado.
	\end{proof}
	
	\chapter{Lógica de primeira ordem}
	
	Introdução à lógica de primeira ordem, culminando no teorema da completude de Gödel.
	
	\chapter{Introdução à computação}
	
	Introdução à teoria das funções computáveis, ligando-a à lógica de primeira ordem, culminando nos teoremas de incompletude de Gödel.
	

\end{document}