\documentclass{report}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{comment}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage{changepage}

%para desenhar árvores sintáticas
\usepackage{tikz}
\usepackage{tikz-qtree}
\tikzset{level distance=2em}

\usepackage{graphicx}


\title{Lógica}
\author{}
\date{}

\newtheorem{prop}{Proposição}	
\newtheorem*{prop*}{Proposição}

\theoremstyle{definition}
\newtheorem{definicao}{Definição}
\newtheorem*{definicao*}{Definição}

\theoremstyle{remark}
\newtheorem{obs}{Obs}

\addto\captionsportuguese{
	\renewcommand{\proofname}{Dem}
}


\newcommand{\N}{\mathbb{N}}

\renewcommand{\bf}[1]{\mathbf{#1}}

\newcommand{\F}{\mathrm{F}}

\newcommand{\lt}{\mathrm{T}}
\newcommand{\lf}{\mathrm{F}}

\DeclareMathOperator{\var}{Var}


\DeclareMathOperator{\pnot}{\texttt{not}}
\newcommand{\pand}{\mathbin{\texttt{and}}}
\newcommand{\por}{\mathbin{\texttt{or}}}
\newcommand{\imply}{\mathbin{\Rightarrow}}
\newcommand{\implied}{\mathbin{\Leftarrow}}
\newcommand{\eqv}{\mathbin{\Leftrightarrow}}

\begin{document}
	\maketitle
	\newpage
	
	\tableofcontents
	\newpage
	
	\chapter{Lógica Proposicional}
	
	A lógica proposicional é um sistema que nos permite expressar raciocínios sobre afirmações e relações entre elas. Mais concretamente, é um sistema no qual as variáveis representam afirmações, que tomam o valor `verdadeiro' e `falso', juntamente com um conjunto de operações lógicas com as quais o leitor já estará familiar, por exemplo o `ou' e o `não'.
	
	Não é preciso procurar muito para descobrir que este sistema tem interesse e aplicações práticas. Qualquer linguagem de programação em uso regular terá este sistema contido no seu funcionamento. Tome-se o exemplo da linguagem Python. Nesta linguagem, as variáveis podem ser do tipo \texttt{bool}. Uma variável deste tipo toma um de dois valores: \texttt{True} e \texttt{False}. Existem também os operadores \texttt{and}, \texttt{or} e \texttt{not}, que recebem valores booleanos e retornam valores booleanos. O uso de parênteses permite-nos agrupar expressões, de modo a formar expressões mais complexas. Por exemplo, \texttt{(a and b) or not (b or not c)} é uma expressão válida em Python (assumindo que as variáveis \texttt{a}, \texttt{b} e \texttt{c} estão definidas e são do tipo \texttt{bool}.)
	
	Formalizaremos e estudaremos este sistema, usando-o como `caixa de areia' para nos preparar para a lógica de primeira ordem, que apesar de semelhante, é significativamente mais complexa.
	
	\section{Noções básicas (Preliminar)}
	
	Esta subsecção tem o sufixo `Preliminar' porque não é final. Isto é, o propósito desta subsecção é apenas dar intuição para o significado das coisas, antes de avançar para as definições secas e rigorosas.
	
	\bigskip
	
	Começamos por introduzir a noção de fórmula. Para os nossos propósitos, uma fórmula é uma expressão composta por variáveis, operadores lógicos, e parênteses. Por exemplo, a expressão $(a \land b) \lor \neg (b \lor \neg c)$ é um exemplo de uma fórmula. Fórmulas são normalmente denotadas por letras gregas minúsculas, e.g. `A fórmula $\varphi$'.
	
	As variáveis (neste caso, $a$, $b$ e $c$) podem tomar os valores de verdade `verdadeiro' e `falso', que aqui denotamos por $\lt$ e $\lf$.
	
	Existem diversos operadores lógicos conhecidos, mas no que se segue usaremos os operadores existentes no Python: $\pnot$, $\pand$ e $\por$. O leitor já deverá estar familiar com o comportamento destes, mas para evitar qualquer confusão, apresentamos as respetivas tabelas de verdade.
	
	\[\label{tabela:operadores}
	\begin{array}{|c|c||c|c|c|}
	\hline
	a & b & \pnot a & a \pand b & a \por b\\
	\hline
	\lt & \lt & \lf & \lt & \lt\\
	\lf & \lt & \lt & \lf & \lt\\
	\lt & \lf &     & \lf & \lt\\
	\lf & \lf &     & \lf & \lf\\
	\hline
	\end{array}
	\]
	
	Dada uma fórmula $\varphi$, podemos tentar `interpretá-la'. Isto é, se atribuirmos valores de verdade às variáveis podemos `substituir esses valores na fórmula' e avaliá-la.
	
	A título de exemplo, consideremos a fórmula $\varphi$ descrita acima.
	\[\varphi : (a \land b) \lor \neg (b \lor \neg c).\]
	
	Suponha-se que estabelecemos $a = \lt$ e $b = c = \lf$. Então, substituindo na fórmula (e escrevendo os operadores \textit{a la} Python), ficamos com
	\begin{gather*}
	(\lt \pand \lf) \por \pnot (\lf \por \pnot \lf)\\
	\lf \por \pnot (\lf \por \lt)\\
	\lf \por \pnot \lt\\
	\lf \por \lf\\
	\lf.
	\end{gather*}
	
	Podemos tornar o processo mais rigoroso descrevendo-o da seguinte forma: definimos uma \emph{valoração} como sendo uma função $\rho : \{\text{Variáveis}\} \to \{\lt, \lf\}$. Afirmamos que qualquer valoração pode ser extendida de forma natural para uma função ${\overline\rho : \{\text{Fórmulas}\} \to \{\lt, \lf\}}$, da forma que descrevemos: substitui-se cada variável $x$ pelo valor de $\rho(x)$ e `faz-se as contas'.
	
	Existe uma classe de fórmulas que tem particular interesse, que são as chamadas tautologias.
	
	Uma fórmula $\varphi$ diz-se uma tautologia se para qualquer valoração $\rho$ temos $\rho(\varphi) = \lt$. Isto é, $\rho$ é sempre verdadeira.
	
	Parte do objetivo deste capítulo é caracterizar as tautologias, de modo a podermos indentificá-las em tempo finito. Claro que, no caso de lógica proposicional, isto já está feito: dada uma fórmula $\varphi$, para determinar se esta é uma tautologia, basta listar todas as valorações possíveis nas variáveis de $\varphi$ (há aqui um detalhe escondido, mas já voltamos a ele) e fazer as contas para todas elas. Se todas elas derem $\lt$, então $\varphi$ é uma tautologia. Caso contrário, não é!
	
	A razão pela qual procuramos outra forma de caracterizar estas fórmulas é porque eventualmente atacaremos o problema mais geral, onde as variáveis, em vez de serem só $\lt$ e $\lf$, podem ser elementos de um universo qualquer arbitrário: naturais, reais, grupos... Assim sendo, deixa de ser possível testar todos os casos possíveis. Como tal, passa a ser necessário um método `sintático', isto é, que manipule as afirmações sem as tentar interpretar. É daí que nasce a formalização de `demonstração', com fim a esclarecer a relação entre o que é verdade e o que é demonstrável.
	
	Voltando a lógica proposicional, consideremos o problema de `testar todos os casos possíveis' para valores das variáveis numa fórmula. Ao fazermos isto estamos a assumir implícitamente que existe um número finito de casos, mas repare-se que, da forma que o definímos, existe um número potencialmente infinito de valorações! De facto, existe um número infinito de variáveis (por exemplo, $x_1$, $x_2$, \dots) pelo que haverá também um número (não-contável!) infinito de valorações. Assim sendo, é impossível testá-las todas.
	
	Claro que, na prática, isto é uma parvoíce. Fixa uma fórmula $\varphi$, só existe um número finito de variáveis a considerar, visto que apenas um número finito de variáveis consta em $\varphi$, e o valor dado a variáveis que não estas é irrelevante. Estamos habituados a tomar estes princípios como garantidos, mas aproveitá-los-emos como veículo para introduzir a noção de indução na estrutura.
	
	A observação essencial é que podemos decompôr uma fórmula arbitrária em fórmulas mais pequenas. Por exemplo, a fórmula $\varphi : (a \land b) \lor \neg (b \lor \neg c)$ pode ser decomposta como $\varphi_1 \lor \varphi_2$, onde $\varphi_1$ e $\varphi_2$ são fórmulas mais pequenas do que a inicial. Isto permite-nos usar o princípio de indução (forte) no tamanho de uma fórmula, em que o passo de indução corresponde a separar uma fórmula como $\varphi_1 \lor \varphi_2$, $\varphi_1 \land \varphi_2$ ou $\neg \varphi_1$. Este processo para nas fórmulas que não podem ser simplificadas mais: chamamos a estas de fórmulas atómicas, e são aquelas compostas por apenas uma variável. Por exemplo, $x$, ou $a$.
	
	Exemplificaremos o princípio, começando por definir indutivamente a noção de `variáveis em fórmula', e demonstrando, com base nesta definição, que, se $\rho$ é uma valoração e $\varphi$ é uma fórmula, $\overline\rho(\varphi)$ depende apenas do valor de $\rho$ nas variáveis em $\varphi$.
	
	\begin{definicao*}
	Seja $\varphi$ uma fórmula. Definimos $\var \varphi$ indutivamente da seguinte forma:
	\begin{itemize}
	\item Se $\varphi$ é da forma `$x$', então $\var \varphi = \{x\}$.
	
	\item Se $\varphi$ é da forma $\neg \varphi_1$, então $\var \varphi = \var \varphi_1$.
	
	\item Se $\varphi$ é da forma $\varphi_1 \lor \varphi_2$ ou $\varphi_1 \land \varphi_2$, então $\var \varphi = \var \varphi_1 \cup \var \varphi_2$.
	\end{itemize}
	\end{definicao*}
	
	\begin{prop*}
	Seja $\varphi$ uma fórmula, $\rho$ uma valoração. Então, $\overline \rho(\varphi)$ depende apenas de $\rho|_{\var \varphi}$. Por outras palavras, se $\rho$ e $\rho'$ são duas valorações tal que para todo $x \in \var \varphi$ se tem $\rho(x) = \rho'(x)$, então $\overline \rho(\varphi) = \overline \rho'(\varphi)$.
	\end{prop*}
	
	\begin{proof}
	Como dito antes, usaremos esta demonstração para exemplificar o conceito de indução em estrutura.
	
	O caso base são as fórmulas atómicas, $\varphi : x$. Como $\overline\rho(\varphi) = \rho(x)$ neste caso, de facto $\overline\rho(\varphi)$ depende apenas de $\rho(x)$, isto é, o valor que $\rho$ toma nos elementos de $\var \varphi = \{x\}$. A demonstração do caso base está terminada.
	
	Fazemos agora o passo de indução. Seja $\varphi$ uma fórmula não-atómica, e suponha-se que o enunciado é verdadeiro para todas as fórmulas mais pequenas do que $\varphi$. Então, partimos do princípio que $\varphi$ é da forma $\neg \varphi_1$, $\varphi_1 \lor \varphi_2$ ou $\varphi_1 \land \varphi_2$. Em qualquer um destes casos, as fórmulas nas quais decompômos $\varphi$ são estritamente mais pequenas do que $\varphi$, pelo que podemos usar nelas a hipótese de indução.
	
	Usemos o caso $\varphi_1 \lor \varphi_2$ como exemplo, sabendo que os outros dois casos são idênticos.
	
	Por hipótese de indução, $\overline\rho(\varphi_1)$ depende apenas de $\rho$ aplicado a $\var \varphi_1$. Da mesma forma, $\overline\rho(\varphi_2)$ depende apenas de $\rho$ aplicado a $\var \varphi_2$. Logo, $\overline\rho(\varphi) = \overline\rho(\varphi_1) \por \overline\rho(\varphi_2)$ depende apenas de $\rho$ aplicado a $\var \varphi_1 \cup \var \varphi_2 = \var \varphi$, o que conclui a demonstração.
	\end{proof}
	
	Voltemos ao problema de identificar tautologias. Existe um conceito mais geral, que é o conceito de `consequência semântica'. A ideia é que às vezes é possível afirmar, \emph{sob certas condições}, que uma fórmula é sempre verdadeira.
	
	Por exemplo, considere-se $\varphi : (a \land c) \lor b \lor (a \land \neg c)$. Esta fórmula não é uma tautologia: por exemplo, a valoração que leva tudo em $\lf$ faz com que esta fórmula fique falsa. No entanto, se uma valoração $\rho$ satisfaz $\overline\rho(a \lor b) = \lt$, então é fácil verificar que de certeza que $\overline\rho(\varphi) = \lt$. Dito de outra forma: sabendo que $\rho$ dá o valor $\lt$ a $a \lor b$, concluímos que $\rho$ dá o valor $\lt$ a $\varphi$. Às vezes, por abuso de linguagem, omitimos as referências a valorações e dizemos apenas `se $a \lor b$ então $\varphi$'.
	
	Antes de generalizarmos este conceito, introduzimos alguma linguagem para nos ajudar a expressar.
	
	\begin{definicao*}
	Seja $\gamma$ uma fórmula, $\rho$ uma valoração. Dizemos que $\rho$ satisfaz $\gamma$, denotado $\rho \Vdash \gamma$, se $\overline\rho(\gamma) = \lt$.
	
	Se em vez de uma fórmula tivermos um conjunto de fórmulas $\Gamma$ (normalmente usamos letras gregas maiúsculas para conjuntos de fórmulas) dizemos que $\rho$ satisfaz $\Gamma$ se $\rho$ satisfizer todas as fórmulas de $\Gamma$. Isto é, simbolicamente,
	\[\rho \Vdash \Gamma \text{ se para todo $\gamma \in \Gamma$ temos } \rho \Vdash \gamma.\]
	\end{definicao*}
	
	\begin{definicao*}
	Seja $\varphi$ uma fórmula e $\Gamma$ um conjunto de fórmulas. Então, dizemos que \emph{$\varphi$ é consequência semântica de $\Gamma$}, representado simbolicamente como
	\[\Gamma \vDash \varphi\]
	se para todas as valorações $\rho$ tal que $\rho \Vdash \Gamma$ temos $\rho \Vdash \varphi$.
	
	Por outras palavras, `se todas as afirmações em $\Gamma$ são verdade, concluímos que $\varphi$ é verdade'.
	
	Normalmente, quando $\Gamma$ é um conjunto finito, abreviamos a notação, omitindo chavetas. Por exemplo, se $\Gamma = \{\gamma_1, \gamma_2, \gamma_3\}$, escreveríamos $\gamma_1, \gamma_2, \gamma_3 \vDash \varphi$.\label{convencao:consequencia}
	
	Isto sugere uma notação para tautologia. De facto, $\varphi$ é uma tautologia sse $\emptyset \vDash \varphi$ (verifique). Escrevendo $\emptyset = \{\}$ e usando a convenção de omitir chavetas, chegamos à notação para tautologias: $\vDash \varphi$.
	
	Outra convenção que seguiremos será abreviar uniões usando vírgulas. Por exemplo, escrever $\Gamma, \alpha, \beta \vDash \varphi$ em vez de $\Gamma \cup \{\alpha, \beta\} \vDash \varphi$.
	\end{definicao*}
	
	A noção de consequência semântica é útil porque, juntamente com uma regra básica que iremos discutir agora, nos permite deduzir verdades novas a partir de verdades conhecidas.
	
	Suponhamos que temos uma afirmação da forma $a \lor b$. Isto significa que pelo menos um dos termos é verdadeiro. Assim sendo, se nos for dito que uma destas duas afirmações é falsa, concluímos que a outra é necessariamente verdadeira, isto é, $a$ falso implica $b$ verdadeiro. Por outras palavras, $a \lor b, \neg a \vDash b$.
	
	Substituindo $a$ por $\neg a$ e partindo do princípio que $\neg \neg a$ é a mesma coisa que $a$, chegamos à conclusão
	\[\neg a \lor b, a \vDash b.\]
	
	Assim sendo, a afirmação $\neg a \lor b$ representa, de alguma forma, `$a$ implica $b$'. Como tal, definimos o símbolo `$a \imply b$' como sinónimo de $\neg a \lor b$, e concluímos a chamada regra de \textit{modus ponens}:
	\[a \imply b, a \vDash b.\]
	
	Esta regra será a fundação do nosso cálculo dedutivo. De facto, veremos que existe um conjunto razoavelmente pequeno de tautologias $T$ tal que qualquer outra tautologia pode ser obtida a partir de aplicação repetida de \textit{modus ponens} a tautologias em $T$. A implicação tem um papel tão central, de facto, que quando definirmos fórmulas rigorosamente usaremos como base os operadores `não' e `implica'.
	
	\smallskip
	
	Terminamos esta secção preliminar com uma introdução ao conceito de metateorema.
	
	A noção de implicação e consequência semântica estão intrinsicamente ligadas. De facto, mostraremos que, em certo sentido, `$a \imply b$ sse $a \vDash b$'. Isto diz-se um metateorema porque relaciona duas `camadas' de verdade: relaciona uma verdade `dentro do sistema' ($a \imply b$) com uma verdade `sobre o sistema' ($a \vDash b$).
	
	\begin{prop*}
	(Metateorema da dedução) Seja $\Gamma$ um conjunto de fórmulas, $a$ e $b$ proposições. Então,
	\[\Gamma, a \vDash b \text{ sse } \Gamma \vDash a \imply b.\]
	\end{prop*}
	
	\begin{proof}\label{dem:mtd}
	($\imply$) Suponha-se que $\Gamma, a \vDash b$. Desejamos mostrar $\Gamma \vDash a \imply b$, isto é, $\Gamma \vDash \neg a \lor b$. Assim sendo, vamos supor que $\rho$ é uma valoração tal que $\rho \Vdash \Gamma$ e mostraremos que $\rho \Vdash \neg a \lor b$.
	
	Existem dois casos: ou $\rho(a) = \lt$ ou $\rho(a) = \lf$.
	
	Se $\rho(a) = \lf$, então $\overline\rho(\neg a \lor b) = (\pnot \lf) \por \rho(b) = \lt \por \rho(b) = \lt$.
	
	Se $\rho(a) = \lt$, então temos que $\rho \Vdash \Gamma \cup \{a\}$, donde, como $\Gamma, a \vDash b$ por hipótese, concluímos que $\rho(b) = \lt$. Concluímos então que $\overline\rho(\neg a \lor b) = (\pnot \lt) \por \lt = \lt$, como desejado.
	
	($\leftarrow$) Suponha-se que $\Gamma \vDash a \imply b$. Seja $\rho$ uma valoração tal que $\rho \Vdash \Gamma \cup \{a\}$. Então, em particular, $\rho \Vdash \Gamma$, donde $\rho \Vdash a \imply b$. Sabemos também que $\rho \Vdash a$, pelo que concluímos $\rho \Vdash \{a \imply b, a\}$. Pela regra de \textit{modus ponens}, como $a \imply b, a \vDash b$, concluímos que $\rho \Vdash b$.
	
	Como partimos do princípio que $\rho$ era uma valoração arbitrária tal que $\rho \Vdash \Gamma \cup \{a\}$ e concluímos $\rho \Vdash b$, temos que $\Gamma \cup \{a\} \vDash b$.
	\end{proof}
	
	Este metateorema marca a primeira ocasião em que a nossa linguagem diz algo sobre si mesma. Frases autorreferenciais terão um papel central quando falarmos dos teoremas de incompletude de Gödel, mas isso terá que esperar até ao terceiro capítulo.
	
	\section{Semântica}
	
	O que se segue assume parcialmente que o leitor já leu a secção anterior. Apesar de não haver precedência explícita ou implícita, algumas das ideias essenciais já foram explicadas, e como tal não serão detalhadas novamente. Por outras palavras, o leitor poderá ler esta secção sem ter lido a anterior, mas se der por si perdido nas definições sem entender o seu significado poderá querer voltar atrás e ler a secção introdutória.
	
	\medskip
	
	Começamos por definir o conceito de fórmula proposicional.
	
	Fixe-se, primeiro, um conjunto, que usaremos em tudo o que se segue, chamado o conjunto das variáveis. Isto é apenas um conjunto infinito contável\footnote{Algo estranhamente, a cardinalidade exata deste conjunto é relevante. Bastantes argumentos que faremos de futuro necessitam explicitamente da contabilidade de $X$!} de símbolos $X$. Normalmente usamos variáveis como $x$, $y$, $p$, $q$, e permitimos a modificação de símbolos como a adição de apóstrofos ou asteriscos. Os símbolos $c$, $c'$, $c^*$ são considerados distintos. Usaremos a convenção que variáveis serão representadas por letras romanas minúsculas.
	
	\begin{obs}
	Há a necessidade de distinguir uma variável de uma `meta-variável'. Isto é: se falamos na variável $x$, poderá ser ambíguo se nos referimos ao elemento $x \in X$ ou se a letra $x$ é uma incógnita que pode significar uma variável arbitrária.
	
	Para evitar esta ambíguidade, representamos meta-variáveis a negrito: $\bf{x}$. Ou seja: $x$ é o elemento de $X$, enquanto que $\bf x$ é uma incógnita que pode ser substituída por qualquer variável: $x$, $y$, $z$, \dots
	\end{obs}
	
	Há quem defina, agora, fórmulas como sequências de símbolos. Isto parece ser uma definição intuitiva, visto que é assim que representamos fórmulas: sequências de caracteres. No entanto, visto que no futuro teremos que escrever programas que lêm e interpretam estas fórmulas, é mais conveniente definirmos fórmulas pelas respetivas árvores semânticas.
	
	Para esclarecer o que se entende por isto, considere-se a expressão $a \lor b$. Isto consiste de um operador (o operador `ou') aplicado a duas variáveis. Podemos representar isto como uma árvore na seguinte forma:
	
	\begin{center}
	\Tree [.\texttt{or} $a$ $b$ ]
	\end{center}
	
	Podemos, no entanto, considerar expressões mais complexas. Por exemplo, considere-se a expressão $(a \land b) \lor \neg (b \lor \neg c)$. Interpretada como uma árvore, esta expressão fica
	
	\begin{center}
	\Tree [.\texttt{or} [.\texttt{and} $a$ $b$ ] [.\texttt{not} [.\texttt{or} $b$ [.\texttt{not} $c$ ] ] ] ]
	\end{center}
	
	Para os nossos propósitos, é mais fácil manipular àrvores do que sequências de caracteres. Assim sendo, é com base nesta perspetiva que definimos o conjunto das fórmulas proposicionais.
	
	\begin{definicao}
	Definimos o conjunto das fórmulas proposicionais $\F_p$ (sobre o conjunto $X$, que deixamos implícito) indutivamente.
	
	Qualquer variável $\bf x$ é uma fórmula.
	
	Se $\alpha$ e $\beta$ são fórmulas, ambos os seguintes são fórmulas:
	
	\begin{center}
	\Tree [.\texttt{not} $\alpha$ ]
	\hspace{3em}
	\Tree [.\texttt{implies} $\alpha$ $\beta$ ]
	\end{center}
	
	Esta forma de representar fórmulas não é particularmente eficiente tipográficamente, pelo que, no que se segue, continuaremos a representá-las com a notação linear $\neg \alpha$ e $\alpha \imply \beta$.
	
	Ao darmos nomes a fórmulas, associaremos o nome ao conteúdo usando dois pontos. Por exemplo, para associar o nome $\varphi$ à fórmula $a \lor b$, escreveremos $\varphi : a \lor b$.
	\end{definicao}
	
	\begin{definicao}
	Definimos uma valoração $\rho$ como uma função $\rho : X \to \{\lt,\lf\}$.
	
	Dada uma valoração $\rho$, definimos uma função $\overline\rho : \F_p \to \{\lt, \lf\}$ indutivamente:
	
	\begin{itemize}
	\item Se $\varphi : \bf x$, definimos $\overline\rho(\varphi) = \rho(\bf x)$.
	
	\item Se $\varphi : \neg \alpha$, definimos $\overline\rho(\varphi) = \pnot \overline\rho(\alpha)$.\footnote{Se o leitor não perceber o uso dos operadores $\pnot$ e $\por$, ver página \pageref{tabela:operadores}.}
	
	\item Se $\varphi : \alpha \imply \beta$, definimos $\overline\rho(\varphi) = (\pnot \overline\rho(\alpha)) \por \overline\rho(\beta)$.
	\end{itemize}
	
	Dada uma valoração $\rho$, dizemos que $\rho \Vdash \varphi$ ($\rho$ satisfaz $\varphi$) se $\overline\rho(\varphi) = \lt$. Se em vez de uma fórmula $\varphi$ tivermos um conjunto de fórmulas $\Gamma$, dizemos que $\rho \Vdash \Gamma$ se $\rho \Vdash \gamma$ para todo $\gamma \in \Gamma$.
	\end{definicao}
	
	\begin{definicao}
	Seja $\varphi \in \F_p$, $\Gamma \subseteq \F_p$. Dizemos que $\Gamma \vDash \varphi$ (pronunciado `$\varphi$ é consequência semântica de $\Gamma$') se todas as valorações que satisfazem $\Gamma$ também satisfazem $\varphi$. Por outras palavras, se para todas as valorações $\rho$ tal que $\rho \Vdash \Gamma$ temos $\rho \Vdash \varphi$.
	
	Para abreviar a notação, seguimos algumas convenções, detalhadas na página \pageref{convencao:consequencia}, relacionadas com omissão de chavetas em expressões do género $\{a, b\} \vDash c$.
	
	Dizemos que $\varphi$ é uma tautologia se $\emptyset \vDash \varphi$. Isto pode ser representado como $\vDash \varphi$.
	\end{definicao}
	
	Começamos por apresentar algumas regras de decução que nos ajudarão a mostrar que certas coisas são consequência semântica de outras.
	
	\begin{prop}
	A relação $\vDash$ é transitiva. Isto é:
	
	Sejam $\Gamma, \Phi \subseteq \F_p$ e $\psi \in \F_p$. Suponha-se que $\Gamma \vDash \varphi$ para todo $\varphi \in \Phi$ (Podemos representar isto como $\Gamma \vDash \Phi$) e que $\Phi \vDash \psi$. Então $\Gamma \vDash \psi$.
	\end{prop}
	
	\begin{proof} Suponha-se $\Gamma \vDash \Phi$ e $\Phi \vDash \psi$. Então, para mostrar $\Gamma \vDash \psi$ começamos por supor que $\rho$ é uma valoração tal que $\rho \Vdash \Gamma$. Então, por definição de $\Gamma \vDash \Phi$, temos que $\Gamma \vDash \varphi$ para todo $\varphi \in \Phi$. Como $\rho \Vdash \Gamma$, obtemos que $\rho \Vdash \varphi$ para todo $\varphi \in \Phi$, ou seja, que $\rho \Vdash \Phi$. Finalmente, por definição de $\Phi \vDash \psi$, concluímos que $\rho \Vdash \psi$, terminando a demonstração.
	\end{proof}
	
	\begin{prop} (\textit{Modus ponens}) 
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então, $\alpha \imply \beta, \alpha \vDash \beta$.
	\end{prop}
	
	\begin{proof}
	Suponha-se que $\rho \Vdash \alpha \imply \beta$ e $\rho \Vdash \alpha$. Então, $(\pnot\overline\rho(\alpha))\por\overline\rho(\beta) = \lt$ e $\overline\rho(\alpha) = \lt$. Substituindo $\overline\rho(\alpha)$ por $\lt$ na primeira afirmação, ficamos com $(\pnot\lt)\por\overline\rho(\beta) = \lt$, isto é, $\lf \por \overline\rho(\beta) = \lt$. Para isto acontecer, é necessário que $\overline\rho(\beta) = \lt$, ou seja, $\rho \Vdash \beta$.
	\end{proof}
	
	\begin{prop}
	(Metateorema da dedução)
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então
	\[\Gamma, \alpha \vDash \beta \text{ sse } \Gamma \vDash \alpha \imply \beta.\]
	\end{prop}
	
	\begin{proof}
	Uma possível demonstração é semelhante à demonstração feita na página \pageref{dem:mtd}, com um pequeno detalhe. Essa demonstração foi feita para variáveis $a, b$ em vez de fórmulas $\alpha, \beta$. No entanto, substituindo $\rho(a)$ por $\overline\rho(\alpha)$ e $\rho(b)$ por $\overline\rho(\beta)$, a demonstração funciona sem modificações. Apresentamos, no entanto, uma demonstração ligeiramente diferente de ($\leftarrow$), que exemplifica as proposições acima.
	
	Suponha-se que $\Gamma \vDash \alpha \imply \beta$. É trivial reparar que $\Gamma, \alpha \vDash \Gamma$ (verifique). Por transitividade,
	\begin{equation}\label{eq:mtd:1}
	\Gamma, \alpha \vDash \alpha \imply \beta.
	\end{equation}
	
	Sabemos também que
	\begin{equation}\label{eq:mtd:2}
	\Gamma, \alpha \vDash \alpha.
	\end{equation}
	
	Juntando as afirmações \eqref{eq:mtd:1} e \eqref{eq:mtd:2}, obtemos que $\Gamma, \alpha \vDash \{\alpha \imply \beta, \alpha\}$. A regra de \textit{modus ponens} diz-nos que $\{\alpha \imply \beta, \alpha\} \vDash \beta$, pelo que, por transitividade, $\Gamma, \alpha \vDash \beta$, como desejado.
	\end{proof}
	
	O leitor poderá ter reparado que os símbolos $a \land b$ e $a \lor b$ não foram definidos, visto que na nossa definição de fórmula englobámos apenas as operações $\neg a$ e $a \imply b$. Visto que o uso dos operadores $\land$ e $\lor$ são convenientes, definimo-los por abreviatura. Ou seja, escrevemo-los em termos de `não's e `implica's, e sempre que escrevemos `ou' ou `e' substituimos mentalmente pela abreviatura establecida.
	
	Recordamos o leitor que $\overline\rho(\alpha \imply \beta) = (\pnot \overline\rho(\alpha)) \por \overline\rho(\beta)$, pelo que desejamos escrever os operadores $\por$ e $\pand$ como uma expressão semelhante a esta forma.
	
	Afirmamos que
	\begin{gather*}
	a \por b = (\pnot (\pnot a)) \por b\\
	a \pand b = \pnot ((\pnot a) \por (\pnot b)).
	\end{gather*}
	
	Pelo que estabelecemos as seguintes abreviaturas:
	
	\begin{itemize}
	\item Quando escrevemos $\alpha \lor \beta$, substituimos mentalmente por $\neg \alpha \imply \beta$.
	
	\item Quando escrevemos $\alpha \land \beta$, substituimos mentalmente por $\neg (\alpha \imply \neg \beta)$.
	
	\item Estabelecemos também a abreviatura $a \eqv b$ como $(a \imply b) \land (b \imply a)$ (que por sua vez é abreviatura de outra expressão, mas achamos por bem não expandir por completo).
	\end{itemize}
	
	Considere-se a noção de equivalência. Estamos habituados a que afirmações equivalentes sejam `a mesma coisa', na medida em que podemos substituir uma afirmação pela outra. Por exemplo, suponha-se que provamos que $\vDash \neg \neg \alpha \eqv \alpha$. (Faremos os detalhes mais tarde.) Agora, suponhamos que se deseja provar uma afirmação na qual aparece $\neg \neg \alpha$, por exemplo, $\beta \imply \neg \neg \alpha$. Seria agradável reduzir isto a mostrar que $\beta \imply \alpha$. Felizmente, verifica-se que este tipo de atalhos é admissível. É nisto que consiste o \emph{metateorema da substituição de equivalentes}.
	
	Antes de estudarmos a relação de equivalência, no entanto, vale a pena investigar o símbolo $\land$, visto que este consta na definição de $\eqv$.
	
	\begin{prop}\label{prop:conj:prop:sem}
	Sejam $\alpha, \beta \in \F_p$. Então, $\alpha, \beta \vDash \alpha \land \beta$ e $\alpha \land \beta \vDash \{\alpha, \beta\}$.
	\end{prop}
	
	\begin{proof}
	Para mostrar isto, basta mostrar que, se $\rho$ é uma valoração arbitrária, $\rho \Vdash \alpha \land \beta$ sse $\rho \Vdash \{\alpha, \beta\}$.
	
	De facto, $\rho \Vdash \alpha \land \beta$ sse $\overline\rho(\neg(\alpha \imply \neg \beta)) = \lt$ sse $\pnot ((\pnot \overline\rho(\alpha)) \por (\pnot \overline\rho(\beta))) = \lt$. É fácil verificar que isto acontece sse $\overline\rho(\alpha) = \overline\rho(\beta) = \lt$, ou seja, $\rho \Vdash \{\alpha, \beta\}$. Isto conclui a demonstração.
	\end{proof}
	
	Com a informação que já temos até agora, podemos começar a fazer demonstrações sem pensar tanto sobre valorações e casos possíveis. Exemplificamos demonstrando que $\alpha \eqv \neg \neg \alpha$.
	
	\begin{prop}
	Para qualquer $\alpha \in \F_p$, $\vDash \alpha \eqv \neg \neg \alpha$.
	\end{prop}
	
	\begin{proof}
	Primeiro que tudo, é preciso observar a `meta-equivalência' trivial: $\pnot \pnot x = x$. Usando isto, concluímos que $\alpha \vDash \neg \neg \alpha$ e $\neg \neg \alpha \vDash \alpha$. Aplicando o metateorema da dedução a cada um destes, obtemos $\vDash \{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\}$. Usando a proposição \ref{prop:conj:prop:sem}  temos que $\{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\} \vDash (\alpha \eqv \neg \neg \alpha)$ (recorde-se da definição de equivalência por abreviatura), e por transitividade, como $\emptyset \vDash \{\alpha \imply \neg \neg \alpha, \neg \neg \alpha \imply \alpha\} \vDash (\alpha \eqv \neg \neg \alpha)$, temos $\emptyset \vDash \alpha \eqv \neg \neg \alpha$.
	\end{proof}
	
	Repare-se que a maior parte da demonstração que acabámos de fazer consistiu em passar de `$\alpha \vDash \beta$ e $\beta \vDash \alpha$' para `$\vDash \alpha \eqv \beta$'. Agora que sabemos que este tipo de raciocínios é válido, abreviaremos as nossas demonstrações na medida em que deixamos esta passagem para o leitor. Por exemplo:
	
	\begin{prop}
	Para qualquer $\alpha \in \F_p$, $\vDash (\alpha \land \beta) \eqv (\beta \land \alpha)$.
	\end{prop}
	
	\begin{proof}
	Sabemos que $\alpha \land \beta \vDash \{\alpha, \beta\}$. Como $\{\alpha, \beta\} = \{\beta, \alpha\}$, obtemos que $\{\alpha, \beta\} \vDash \beta \land \alpha$. Por transitividade, conclui-se $(\alpha \land \beta) \vDash (\beta \land \alpha)$. Reproduzindo a demonstração com o papel de $\alpha$ e $\beta$ trocado, damos a prova por concluída.
	\end{proof}
	
	Visto que já temos ferramentas para mostrar equivalências, passamos agora à proposição que nos permite fazer uso de equivalências. Antes de o podermos fazer, no entanto, precisamos de formalizar o que significa `substituir'.
	
	A ideia essencial é que pretendemos, numa fórmula $\varphi$, substituir certas instâncias de uma expressão $\alpha$ por uma outra expressão (presumivelmente equivalente) $\beta$. Por exemplo, passar de $\varphi : a \land \neg \neg (b \imply c)$ para $\psi : a \land (b \imply c)$, e depois possívelmente para $\theta : (b \imply c) \land a$. Para podermos manipular o conceito de substituição e demonstrar coisas sobre ele, precisamos de o definir de forma rigorosa. Como o leitor poderá estar à espera, fá-lo-emos de forma indutiva.
	
	\begin{definicao}
	Sejam $\varphi, \psi, \alpha, \beta \in \F_p$. Dizemos que \emph{$\psi$ é obtido de $\varphi$ por substituição de $\alpha$ por $\beta$} se:
	
	\begin{itemize}
	\item Caso base: Se $\varphi$ e $\psi$ são a mesma fórmula.
	
	\item Substituição: Se $\varphi : \alpha$ e $\psi : \beta$.
	
	\item Passo de indução (negação): Se $\varphi : \neg \varphi_1$, $\psi : \neg \psi_1$ e $\psi_1$ é obtido de $\varphi_1$ por substituição de $\alpha$ por $\beta$.
	
	\item Passo de indução (implicação): Se $\varphi : \varphi_1 \imply \varphi_2$, $\psi : \psi_1 \imply \psi_2$, $\psi_1$ é obtido de $\varphi_1$ por substituição de $\alpha$ por $\beta$ e $\psi_2$ é obtido de $\varphi_2$ por substituição de $\alpha$ por $\beta$.
	\end{itemize}
	\end{definicao}
	
	Note-se que esta definição é particularmente complexa, e aplicá-la na prática é chato. Claro que isto corresponde simplesmente à noção intuitiva de `pegar nalguns $\alpha$, apagá-los, e escrever $\beta$ no seu lugar', pelo que, ao afirmar que duas fórmulas são obtidas uma da outra por substituição, não nos daremos ao trabalho de fazer uma inteira justificação com base nestes casos todos. No entanto, se o leitor estiver confuso com a definição é recomendado tentar aplicá-la a alguns exemplos de substituição de fórmulas.
	
	Podemos finalmente passar à demonstração de:
	
	\begin{prop}
	(Metateorema de substituição de equivalentes) Sejam $\varphi, \psi, \alpha, \beta \in \F_p$ e $\Gamma \subseteq \F_p$. Suponha-se que $\Gamma \vDash \alpha \eqv \beta$ e que $\psi$ é obtido de $\varphi$ por substituição de $\alpha$ por $\beta$. Então,
	\[\Gamma \vDash \varphi \eqv \psi.\]
	\end{prop}
	
	\begin{proof}
	Como esperado, usamos a definição indutiva de $\psi$ ser obtido de $\varphi$ por substituição.
	
	Se $\varphi$ e $\psi$ são a mesma fórmula, então basta reparar que $\varphi \eqv \varphi$ é uma tautologia (deixamos a demonstração disto para o leitor).
	
	Se $\varphi : \alpha$ e $\psi : \beta$, a afirmação $\Gamma \vDash \varphi \eqv \psi$ é dada como hipótese.
	
	Se $\varphi : \neg \varphi_1$ e $\psi : \neg \psi_1$, onde $\psi_1$ é obtido de $\varphi_1$ por substituição, usamos a hipótese de indução para afirmar que $\Gamma : \varphi_1 \eqv \psi_1$. Basta agora mostrar que $\varphi_1 \eqv \psi_1 \vDash (\neg \varphi_1) \eqv (\neg \psi_1)$, e a conclusão decorre por transitividade. Deixamos a demonstração deste facto auxiliar como exercício para o leitor, de modo a não quebrar o raciocínio.
	
	Se $\varphi : \varphi_1 \imply \varphi_2$ e $\psi : \psi_1 \imply \psi_2$, onde $\psi_1$ e $\psi_2$ são obtidos por substituição a partir de $\varphi_1$ e $\varphi_2$, respetivamente, podemos aplicar a hipótese de indução para afirmar que $\Gamma \vDash \varphi_1 \eqv \psi_1$ e $\Gamma \vDash \varphi_2 \eqv \psi_2$. Por transitividade, é suficiente mostrar que $\{\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2\} \vDash (\varphi_1 \imply \varphi_2) \eqv (\psi_1 \imply \psi_2)$.
	
	Faremos a demonstração deste último facto aplicando repetidamente o metateorema da dedução. Mostraremos que
	\begin{equation}\label{eq:mse:1}
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2, \varphi_1 \imply \varphi_2, \psi_1 \vDash \psi_2.
	\end{equation}
	
	Ora, repare-se que $\varphi_1 \eqv \psi_1 \vDash \psi_1 \imply \varphi_1$, como se pode mostrar recorrendo à definição por abreviatura de $\eqv$ e a proposição \ref{prop:conj:prop:sem}. De igual modo, $\varphi_2 \eqv \psi_2 \vDash \varphi_2 \imply \psi_1$. Assim sendo,
	\[\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2, \varphi_1 \imply \varphi_2, \psi_1 \vDash \psi_1, \psi_1 \imply \varphi_1, \varphi_1 \imply \varphi_2, \varphi_2 \imply \psi_2.\]
	
	Aplicando repetidamente modus ponens, chegamos à conclusão que desta última sequência de termos se conclui $\psi_2$, pelo que, por transitividade, a equação \eqref{eq:mse:1}. Aplicando agora o metateorema da dedução duas vezes, conclui-se
	\[
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2  \vDash (\varphi_1 \imply \varphi_2) \imply (\psi_1 \imply \psi_2).
	\]
	
	Repetindo o argumento com o papel de $\varphi$ e $\psi$ trocados, obtemos a implicação inversa, pelo que aplicando a proposição \ref{prop:conj:prop:sem} concluímos, finalmente,
	\[
	\varphi_1 \eqv \psi_1, \varphi_2 \eqv \psi_2  \vDash (\varphi_1 \imply \varphi_2) \eqv (\psi_1 \imply \psi_2).
	\]
	\end{proof}
	
	\section{Sintática}
	
	Como explicado na secção preliminar, o nosso objetivo final será arranjar uma forma sistemática de descobrir que afirmações são tautologias. Um pouco mais geralmente, dado um conjunto de afirmações $\Gamma$ (`hipóteses'), queremos arranjar um método para decidir, dada uma fórmula $\varphi$, se $\Gamma \vDash \varphi$. Para mais, queremos fazer isto sem recorrer a valorações, visto que, quando estivermos a trabalhar num contexto mais geral do que o cálculo proposicional, não teremos a vantagem de universos finitos.
	
	Para o fazer, formalizaremos a noção de demonstração. Para o fazer, baseamo-nos na nossa experiência a escrever provas.
	
	Ao redigirmos provas geralmente escrevemos coisas linearmente (uma sequência de afirmações), em que novas afirmações são justificadas com base em conhecimento prévio. Algumas afirmações são hipóteses (1) do teorema que estamos a tentar provar, algumas delas são afirmações que são simplesmente logicamente válidas (2), e algumas são consequências de afirmações anteriores (3). Para exemplificar, considere-se a seguinte demonstração em linguagem natural. Os passos estão anotados consoante a qual destes tipos de afirmação correspondem.
	
	\medskip
	
	\textbf{Proposição:} Sejam $a$ e $b$ valores de verdade tal que $a \por b = \lt$ e $b = \lf$. Então, $a = \lt$.
	
	\begin{adjustwidth}{1cm}{}
	1: Hipótese: $a \por b = \lt$ (1)\\
	2: Axioma: Se $a \por b = \lt$ então $a = \lt$ ou $b = \lt$ (2)\\
	3: Como consequência das linhas 1 e 2: $a = \lt$ ou $b = \lt$. (3)\\
	4: Hipótese: $b = \lf$ (1)\\
	5: Axioma: Se sabemos $a = \lt$ ou $b = \lt$, mas $b \neq \lt$, então $a = \lt$ (2)\\
	6: Como consequência das linhas 3 e 4: $a = \lt$. (3)
	\end{adjustwidth}
	
	\medskip
	
	Claro que isto pressupõe uma noção de `axiomas', ou pelo menos, afirmações tomadas como verdadeiras sem justificação. Uma escolha óbvia para o nosso caso seria tomar como axiomas todas as tautologias, mas é precisamente o problema de encontrar as tautologias que estamos a tentar resolver! Assim sendo, deixamos por agora, como incógnita, um conjunto $A \subseteq \F_p$ de \emph{axiomas do cálculo proposicional}. Mais tarde preocupar-nos-emos com o seu conteúdo, mas a intuição necessária é que este conjunto será razoávelmente pequeno e poderá conter afirmações óbvias como $\neg \neg \alpha \imply \alpha$ ou $(\alpha \land \beta) \imply \alpha$.
	
	\textbf{A partir deste ponto}, consideramos sempre implícito o conjunto $A$, de conteúdo de momento desconhecido. 
	
	\textbf{Se o leitor deseja ver os axiomas finais,} poderá avançar para a página \pageref{def:prop:ax}. Não há perda de continuidade em ler esta secção mesmo sabendo os axiomas. No entanto, esta está escrita como se os axiomas não fossem conhecidos. Ao longo do texto, haverá diversos parágrafos, como o parágrafo anterior, que descrevem hipóteses tomadas por necessidade sobre o conjunto $A$, com o intuito de, no final, `descobrir' o que o conjunto tem que ser. Da perspetiva do leitor que já os sabe, poderá interpretar estas hipóteses, em vez disso, como lembretes quanto ao seu conteúdo.
	
	\begin{definicao}
	Seja $\Gamma \subseteq \F_p$. Este conjunto representa o conjunto de hipóteses da nossa demonstração.
	
	Uma demonstração com base em $\Gamma$, ou demonstração que tem $\Gamma$ como hipóteses, é uma sequência finita
	\[(\varphi_1, j_1), (\varphi_2, j_2), \dots, (\varphi_n, j_n)\]
	onde cada $\varphi_i$ é uma fórmula proposicional, e o respetivo $j_i$ (que simboliza a justificação de $\varphi_i$) satisfaz as seguintes regras:
	
	\begin{itemize}
	\item Cada $j_i$ é um símbolo da forma \texttt{Ax}, \texttt{Hip} ou $\texttt{MP}_{ab}$, com $a,b \in \N$
	
	\item Se $j_i = \texttt{Ax}$ é necessário que $\varphi_i \in A$
	
	\item Se $j_i = \texttt{Hip}$ é necessário que $\varphi_i \in \Gamma$
	
	\item Se $j_i = \texttt{MP}_{ab}$, então $a, b < i$ e $\varphi_a$ é a fórmula $\varphi_b \imply \varphi_i$.
	
	Por outras palavras, se $\varphi_a$ é da forma $\alpha \imply \beta$ e $\varphi_b$ é a fórmula $\alpha$, então podemos concluír a fórmula $\beta$, com a justificação $\texttt{MP}_{ab}$ (\textit{Modus ponens}, com hipóteses $a$ e $b$).
	\end{itemize}
	\end{definicao}
	
	\begin{definicao}
	Dizemos que $\varphi \in \F_p$ é um teorema de $\Gamma \subseteq \F_p$, denotado
	\[\Gamma \vdash \varphi\]
	se existe uma demonstração com base em $\Gamma$ cuja última afirmação seja $\varphi$.
	\end{definicao}
	
	Como mencionado anteriormente, ainda não fixámos o conjunto de axiomas. No entanto, é certo que todos os axiomas serão logicamente válidos, na medida em que serão todos tautologias. Com base nisto, podemos afirmar (sob esta hipótese) que o nosso cálculo será certamente \emph{correto}, isto é, só mostra afirmações verdadeiras.
	
	\textbf{A partir deste ponto}, assumiremos sempre que todas as fórmulas $\alpha \in A$ são tautologias.
	
	\begin{prop}
	Seja $\Gamma \subseteq \F_p$, $\varphi \in \F_p$. Suponha-se que $\Gamma \vdash \varphi$. Então, $\Gamma \vDash \varphi$.
	\end{prop}
	
	\begin{proof}
	Se $\Gamma \vdash \varphi$, existe uma demonstração de $\varphi$ com base em $\Gamma$. Seja $(\varphi_1, j_1), \dots, (\varphi_n, j_n)$ esta demonstração. Mostraremos por indução que todos os $\varphi_i$ são consequência semântica de $\Gamma$, e portanto, em particular, $\Gamma \vDash \varphi_n = \varphi$.
	
	Faremos esta prova usando o princípio de indução forte:
	
	\begin{center}
	Seja $S$ um subconjunto dos naturais. Suponha-se que para todo $n \in \N$ o conjunto $\N \cap \left[0,n\right[$ está contido em $S$. Então, o princípio de indução forte diz que $S = \N$.\footnote{Para justificar este princípio: suponha-se que $S \neq \N$. Então, $\N \setminus S$ é não-vazio. Qualquer subconjunto não-vazio dos naturais tem mínimo; seja, então, $n$ o mínimo de $\N \setminus S$. Por definição de mínimo, temos que $\N \cap \left[0, n\right[ \subseteq S$, e, por hipótese, isto implica que $n \in S$. Contradição, pelo que $\N \setminus S$ tem que ser vazio e portanto $S = \N$.} Note-se que não é necessário provar caso base.
	\end{center}
	
	Seja $i$ um índice tal que para todo $i' < i$ se tem $\Gamma \vDash \varphi_{i'}$. Então, mostramos que $\Gamma \vDash \varphi_i$. A prova consiste em examinar a justificação de $\varphi_i$, isto é, $j_i$.
	
	\begin{itemize}
	\item Se $j_i = \texttt{Hip}$, então $\varphi_i \in \Gamma$, donde $\Gamma \vDash \varphi_i$ trivialmente.
	
	\item Se $j_i = \texttt{Ax}$, então $\varphi_i \in A$, donde $\varphi_i$ é uma tautologia. Isto claramente implica $\Gamma\vDash\varphi_i$.
	
	\item Se $j_i = \texttt{MP}_{ab}$, basta usar a transitividade da consequência semântica. Por hipótese, $\Gamma \vDash \{\varphi_a, \varphi_b\}$. Por definição de demonstração, $\varphi_a$ é a fórmula $\varphi_b \imply \varphi_i$. Pela regra de \textit{modus ponens}, $\{\varphi_b \imply \varphi_i, \varphi_b\} \vDash \varphi_i$, pelo que, por transitividade, $\Gamma \vDash \varphi_i$, como desejado.
	\end{itemize}
	\end{proof}
	
	A proposição anterior mostra que, sob as hipóteses já acumuladas, qualquer afirmação demonstrada é verdadeira. Desejamos algo mais forte, no entanto: queremos que qualquer afirmação verdadeira seja demonstrável. A esta última propriedade chamamos \emph{completude} do cálculo. Para a assegurarmos, é necessário termos uma quantidade suficientemente grande de axiomas. Para descobrir que axiomas precisamos, podemos olhar para os metateoremas demonstrados na secção anterior. Para o nosso cálculo ser completo, é necessário que todos os metateoremas se verifiquem quando substituimos $\vDash$ por $\vdash$ no seu enunciado.
	
	Exemplificamos o raciocínio com o metateorema da dedução:
	
	\begin{prop}
	(Metateorema da dedução, versão sintática)
	
	Sejam $\alpha, \beta \in \F_p$, $\Gamma \subseteq \F_p$. Então
	\[\Gamma, \alpha \vdash \beta \text{ sse } \Gamma \vdash \alpha \imply \beta.\]
	\end{prop}
	
	\begin{proof}
	Um dos lados não requer hipóteses. ($\leftarrow$) Suponha-se que $\Gamma \vdash \alpha \imply \beta$. Então, isso implica a existência de uma prova com base em $\Gamma$:
	\[
	(\varphi_1, j_i), \dots, (\varphi_n, j_n)
	\]
	com $\varphi_n$ sendo a fórmula $\alpha \imply \beta$. Basta agora considerar a demonstração
	\[
	(\varphi_1, j_i), \dots, (\varphi_n, j_n), (\alpha, \texttt{Hip}), (\beta, \texttt{MP}_{n,(n+1)}).
	\]
	É fácil ver que isto é uma demonstração com base em $\Gamma \cup \{\alpha\}$: todas as justificações $j_1, \dots, j_n$ continuam válidas (um axioma continua a ser um axioma, qualquer hipótese $\varphi \in \Gamma$ é também uma hipótese em $\Gamma \cup \{\alpha\}$, e visto que a estrutura não foi modificada quaisquer aplicações de \textit{modus ponens} continuam a ser válidas) e é fácil verificar que as duas linhas adicionadas à demonstração estão também devidamente justificadas. Temos, então, uma demonstração com base em $\Gamma \cup \{\alpha\}$ cuja última afirmação é $\beta$, pelo que, como desejado, $\Gamma, \alpha \vdash \beta$.
	
	A demonstração da implicação oposta ($\rightarrow$) é ligeiramente mais elaborada, mas a ideia principal é a mesma: pegar numa demonstração de $\Gamma, \alpha \vdash \beta$ e transformá-la numa demonstração de $\Gamma \vdash \alpha \imply \beta$. Assim sendo, seja
	\[
	(\varphi_1, j_i), \dots, (\varphi_n, j_n)
	\]
	uma demonstração de $\beta$ com base em $\Gamma \cup \{\alpha\}$. Construiremos indutivamente uma demonstração com base em $\Gamma$, digamos
	\[
	(\psi_1, j'_1), (\psi_2, j'_2), \dots, (\psi_N, j'_N)
	\]
	em que algum $\psi_{m_1}$ é $\alpha \imply \varphi_1$, algum $\psi_{m_2}$ é $\alpha \imply \varphi_2$, \dots, e algum $\psi_{m_n}$ ($m_n = N$) é $\alpha \imply \varphi_n$. A ideia por trás disto é que estamos a modificar a demonstração que já tinhamos, transformando todas as conclusões da forma $\varphi$ em $\alpha \imply \varphi$. Isto reflete-se na nossa conclusão na medida em que acabamos por demonstrar $\alpha \imply \varphi_n$, isto é, $\alpha \imply \beta$, como desejado.
	
	Assim sendo, suponha-se, pelo princípio de indução, que já temos a demonstração construída até $(\psi_1, j'_1), \dots, (\psi_{m_k}, j'_{m_k})$, com $k < n$. Construiremos mais uma secção da prova, $(\psi_{m_k + 1}, j'_{m_k + 1}), \dots, (\psi_{m_{k+1}}, j'_{m_{k+1}})$. Faremos isto por casos, dependendo de $(\varphi_{k+1}, j_{k+1})$.
	
	\begin{itemize}
	\item Se $j_{k+1} = \texttt{Ax}$, então $\varphi_{k+1}$ é um axioma. Precisamos de mostrar $\alpha \imply \varphi_{k+1}$. Ora, não é necessário que $\alpha \imply \varphi_{k+1}$ seja um axioma, e ainda não temos hipóteses suficientes para construir uma prova desta fórmula, mas guardaremos a sua necessidade para futura consideração.
	
	\textbf{O conjunto $A$ terá que satisfazer} a propriedade que, se $\varphi \in A$, então para qualquer $\alpha \in \F_p$ temos $\vdash \alpha \imply \varphi$.
	
	\item Se $j_{k+1} = \texttt{Hip}$, então
	\end{itemize}
	\end{proof}
	
	\chapter{Lógica de primeira ordem}
	
	Introdução à lógica de primeira ordem, culminando no teorema da completude de Gödel.
	
	\chapter{Introdução à computação}
	
	Introdução à teoria das funções computáveis, ligando-a à lógica de primeira ordem, culminando nos teoremas de incompletude de Gödel.
	

\end{document}