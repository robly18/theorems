\documentclass{article}

\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}

\usepackage[standard]{ntheorem}

\usepackage{diffcoeff}

\title{The Hartman-Grobman Theorem (Unfinished)}
\author{Duarte Maia}
\date{Late 2021}

\newcommand{\R}{\mathbb{R}}

\newcommand{\e}{\mathrm{e}}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

\theoremnumbering{arabic}
\theoremseparator{:}
\newtheorem*{Assumption}{Assumption}

\begin{document}
\maketitle

\section{Introduction}

The Hartman-Grobman theorem is shockingly recent for mathematical standards: Grobman's original paper is from 1959, and Hartman's is from 1960. With this in mind, it's perhaps not too shocking that there don't seem to be that many complete proofs out there. In my research, I found only Hartman's original paper, Grobman's original paper (in Russian...) and one in a book by Chicone. Furthermore, all of the proofs I found (that I could read...) use a `discrete-time approach', which feels artificial and unnecessary to me. %Consequently, I present a proof in continuous time, which is hopefully marginally simpler than the ones currently out there. Furthermore, as well as the proof, I present the steps I took to reach it, in hopes that it makes the proof more easily understood. However, for the reader who only wants to see the proof and not the steps that led up to it, the terse version of the proof is at the end of this document.
Consequently, I attempted to find a proof in continuous time which does not resort to some of the weird tricks the standard proof uses. In the process, I found out why the standard proof uses these tricks. This document was intended to provide a complete proof, but I never intended to finish it, but it remains as an attempted proof of a particular case with what I would see as the obvious approach (iteration), and displays why this attempted proof fails and an idea of how to fix it, which (I believe) recovers the original proof. But then I ran out of steam and didn't know/have time to do the remainder of the proof. But I hope this can still be useful to someone.

Prerequisites for reading this document are basic propositions in the theory of ODEs: existence of solutions, continuity in initial conditions, and Grunbaum's lemma.

\section{Motivation}

What the Hartman-Grobman theorem guarantees is, in a sense, that near a hyperbolic rest point of the ODE $\dot x = f(x)$ (i.e. a point where $f(z) = 0$ and $f'(z)$ has no null-real-part eigenvalues) the phase portrait of the equation looks a lot like the phase portrait of $\dot x = f'(z) x$. More concretely, we will show that there exists a topological homeomorphism $H$ between a neighbourhood of $z$ and a neighbourhood of the origin such that
\begin{equation}\label{goaleq}
\phi_t = H^{-1} \e^{f'(z) t} H,
\end{equation}
where $\phi_t$ is the (time $t$) flow of $f$.

To find such a $H$, a tempting approach is to use the tried-and-tested method of iteration. A possible way to do it, and perhaps the most obvious, is to write \eqref{goaleq} as
\begin{equation}
H = \e^{f'(z) t} H \phi_{-t},
\end{equation}
and therefore iterating the transformation $H \mapsto \e^{f'(z) t} H \phi_{-t}$ starting with $H$ equal to, say, the identity, might give us good results. Note that we have not yet fixed $t$.

Now, it is easy to see that iterating the above map starting with the identity is the same as taking the limit $t \to \pm\infty$ (depending on the sign of $t$) of $H_t(x) = \e^{f'(z) t} \phi_{-t} x$. As such, this will be the preliminary definition we shall work with, and most of what follows is based on making this definition work.

\section{A first example}

To start, note that this is a local theorem. As such, `getting away from the rest point' implies, in principle, losing control of the flow. Therefore, we want to make sure $\phi_{-t} x \to z$, and for this to happen for $t \to \pm \infty$ then $z$ must be either a source or a sink. Of course, if the proof works for one of these then it'll work for the other (just reverse time), so for the sake of definiteness we will work with a source. We will then lay out the basic assumptions for this section and the others.

\begin{Assumption}
From now on, we will always be working with an ODE of the form
\[\dot x = f(x),\]
where $f$ is Lipschitz in a neighborhood of the rest point $z$, and differentiable at $z$. By translation, we may assume without loss of generality that $z = 0$. Under these assumptions, we may write the ODE as
\[\dot x = A x + g(x),\]
where $g(x) = o(x)$. Finally, we assume 0 is a source, in the sense that all eigenvalues of $A$ have positive real part.
\end{Assumption}

We will test our definition of $H(x) = \lim_{t \to \infty} \e^{-A t} \phi_t x$ in the following simple equation:
\[
\begin{cases}
\dot x = -x,\\
\dot y = -\alpha y + x^2.
\end{cases}
\]

This equation was picked because it is among the simplest nonlinear ODEs I know how to solve. Indeed, the solution can easily be found by the method of variation of parameters:
\[
\begin{cases}
x = x_0 \e^{-t},\\
y = y_0 \e^{-\alpha t} - \frac1{2-\alpha} x_0^2 \e^{-\alpha t} (1 - \e^{(2 - \alpha)t}).
\end{cases}
\]

Note that this is only the solution for $\alpha \neq 2$. For $\alpha = 2$, the solution is slightly simpler:
\[y = y_0 \e^{-2 t} + x_0^2 \e^{- 2 t} t.\]

We can now write the expression for $\e^{-At} \phi_t (x,y)$ explicitly, and then we may take the limit as $t \to \infty$. For $\alpha \neq 2$,
\begin{equation}\label{flowsimple}
\e^{-At} \phi_t (x,y) =
\begin{bmatrix}
x\\
y - \frac1{2-\alpha} x^2 (1 - \e^{(2-\alpha)t})
\end{bmatrix}.
\end{equation}

We are now faced with an unfortunate situation. For $\alpha < 2$ this method works fine, converging to a function $H(x,y) = (x, y-\frac1{2-\alpha} x^2)$, but for $\alpha > 2$ it diverges. However, this expression for $H$ still works, and it is easy to check that, for $\alpha \neq 2$, $H$ is a homeomorphism that behaves as intended with regard to the flow, i.e.
\[\phi_t = H^{-1} \e^{A t} H.\]
However, for $\alpha = 2$, the situation seems to be not easily repaired. In any case, it has become clear that this method, while promising, does not work for all ODEs. It then becomes obvious that a different approach is needed.

I have tried a few things. I couldn't get most of them to work.
\begin{itemize}
\item Exponential ($\e^{\delta/\abs{x}}$) dampening near the origin, followed by taking the limit $\delta \to 0$. The method works for the dampened ODEs, but it might diverge as $\delta \to 0$.

\item Adding a correction term to prevent $H$ from exploding. This occurred to because of the following argument. Consider the previous expression for $H$:
\[H(x,y) = (x,y - \frac1{2-\alpha} x^2).\]

We cannot, from it, recover an expression for $\alpha = 2$, even taking limits, because it diverges. However, adding the term $\frac1{2-\alpha} x^\alpha$ to the second coordinate gives us a modified function
\[\tilde H(x,y) = (x,y + \frac{x^2 - x^\alpha}{2-\alpha}),\]
and in this case it does make sense to take $\alpha \to 2$. This seems to suggest that $\tilde H$ is a `more natural homeomorphism', and so it might be fortuitous to find a correction error we could add to make $\tilde H$ appear naturally.

\item Starting the iteration with a function that isn't the identity. In other words, taking the limit of $\e^{-A t} T \phi_t$, where $T$ is a suitable function. This might be a possible way to add the correction term mentioned in the previous bullet point.
\end{itemize}

However, the approach that seems to work best is the one taken by Hartman himself (and maybe Grobman too, but I couldn't tell), which we will now describe.

\section{Hartman's approach}

Earlier, we mentioned that, since it is a local theorem we are trying to prove, it is best not to stray too far from the origin, because the origin is where we have control. On the other hand, the previous example shows us that the origin can be tricky to work with. This leads us to a very clever insight in Hartman's part: we can turn the tables and dampen the area far from the origin, and then build $H$ by going `outside' and then `inside'.

In other words, let us multiply $g$ by a bump function $\varphi(x)$, which is a smooth function equal to 1 near the origin and equal to 0 far from the origin. This has the added bonus of allowing us to extend $f = A + g$ to the whole plane, and furthermore making $f$ a linear function outside of a bounded set. Consequently, the ODE $\dot x = f(x)$ can be guaranteed to have solutions for all starting positions, and for all time, freeing us from worrying about domains of definition. Furthermore, the flows are the same as those of the original equation in a small enough neighborhood of the origin, which means that this transformation can be done without loss of generality.

\begin{Assumption}
Still working with the ODE $\dot x = f(x) = A x + g(x)$, suppose without loss of generality that $g$ is null outside of a neighborhood of radius $R$. By continuity, this implies that $g$ is bounded by some $M_g$, which can be assumed to be as small as necessary by decreasing $R$. Furthermore, the same can be said for $g'$: it is bounded (in the operator norm, say) by some constant $M_{g'}$, which can also be made as small as needed. In particular, $g$ is $M_{g'}$-Lipschitz.
\end{Assumption}

Note that $R$ has been left undefined. As we go on, we will require that $M_g$ or $M_{g'}$ are small enough for some things to happen. As such, we will demand that $R$ is small enough for these constants to be as small as necessary.

Now, let us define our next version of $H$. Recall that we're working with a source, which implies that $A$ has all eigenvalues positive.

Define $H(x) = \lim_{t \to \infty} \e^{-A t} \phi_t x$. It remains to check that this is, in fact, well-defined.

First of all, note that for $x$ big enough (i.e. such that $\phi_t(x)$ is never smaller than $R$) this expression is constant as a function of $t$, and then obviously the limit exists. The crux of the proof of convergence is simple: because the origin is a source, every $x$ (other than zero) is eventually pushed away enough from the origin that this expression becomes a constant.

First, we find out how far away we need to be from the origin to be sure that we never have norm less than $R$. Recall the elementary bounds for the growth of matrix exponentials acting on a vector.

\begin{Assumption}
By assumption, all eigenvalues of $A$ have positive real part. Let $\lambda_m$ be the minimum real part among all eigenvalues, and $\lambda_M$ the largest. Let $\varepsilon$ be a small number. We will make this number as small as necessary in what follows. Then, elementary bounds tell us that there exist constants $m$ and $M$ (as a function of $\varepsilon$) such that, for all vectors $v$,
\begin{gather*}
m \e^{(\lambda_m - \varepsilon)t} \abs{v} \leq \abs{\e^{A t} v} \leq M \e^{(\lambda_M + \varepsilon)t} \abs{v}, \text{for $t \geq 0$};\\
m \e^{(-\lambda_M - \varepsilon) t} \abs{v} \leq \abs{\e^{-A t} v} \leq M \e^{(-\lambda_m + \varepsilon) t} \abs{v}, \text{for $t \geq 0$}.
\end{gather*}
\end{Assumption}

With this in mind, recall that
\begin{gather*}
\phi_t x = \e^{A t} x + \int_0^t \e^{A (t-s)} g(\phi_s(x)) \dl s, \text{and therefore}\\
\abs{\phi_t x} \geq m \e^{(\lambda_m - \varepsilon) t} \abs{x} - \abs*{\int_0^t \dots \dl s}.
\end{gather*}

Now, it is easy to show that, if $\abs{x}$ is greater than $R/m$ (and $\varepsilon$ is less than $\lambda_m$), $\phi_t x$ will never enter the ball of radius $R$ around the origin and thus the integral will have null contribution. Therefore, from the moment $\phi_t(y)$ becomes greater than $R/m$, the function $\e^{-A t} \phi_t(y)$ becomes constant. Thus, to show the pointwise convergence of $H$, we need only show that $\phi_t(y)$ becomes arbitrarily big as $t \to \infty$. To do so, we will ensure that the nonlinear term cannot significantly affect the linear term's growth.

Indeed, recall that the linear term grows at least like $m \e^{(\lambda_m - \varepsilon) t} \abs{x}$. We will ensure that $M_{g'}$ is small enough that after some fixed time $T$ the vector $\phi_T x$ is bigger than $x$ by a factor of at least $\rho = \frac12 m \e^{(\lambda_m - \varepsilon) T}$. Of course, we want to make sure that $\rho > 1$, so fix arbitrary $T$ such that this is the case.

In truth, what we will show is not that $\abs{\phi_T x} \geq \rho \abs x$, but rather that there exists $t \leq T$ such that this is the case. Of course, even though this is slightly weaker, it is sufficient to show that $\abs{\phi_t x}$ grows \emph{at least} like $\rho^{t/T}$, which goes to infinity.

Onward with the proof. Suppose, for the sake of argument, that at no point in the interval $[0, T]$ is $\abs{\phi_t x}$ ever greater than or equal to $\rho \abs x$. Then, by the formula of variation of parameters,
\begin{align*}
\abs{\phi_T x} &\geq m \e^{(\lambda_m - \varepsilon) T} \abs{x} - \int_0^T M \e^{(\lambda_M + \varepsilon)(T-s)} \abs{g(\phi_s(x))} \dl s\\
&\geq 2\rho \abs{x} - \int_0^T M \e^{(\lambda_M + \varepsilon)T} M_{g'} \abs{\phi_s(x)} \dl s\\
&\geq 2\rho \abs{x} - \int_0^T M \e^{(\lambda_M + \varepsilon)(t-s)} M_{g'} \rho \abs{x} \dl s\\
&\geq \left( 2\rho - \e^{(\lambda_M + \varepsilon)T} \frac1{\lambda_M + \varepsilon} M_{g'} \rho \right) \abs{x}.
\end{align*}

Now, recall that we have control over $M_{g'}$. In particular, we can still make it as small as necessary. In this case, let
\[M_{g'} \leq (\lambda_M + \varepsilon) \e^{-(\lambda_M + \varepsilon) T}.\]

Note that neither $T$ nor $\rho$ depends on the choice of $R$, so this retroactive change does not break any step of the proof. In any case, we conclude that $\abs{\phi_T x} \geq \rho \abs{x}$, which contradicts the hypothesis we started with, and so we conclude:

\begin{Lemma}
Under the assumptions we have henceforth accumulated, for all $x$ there exists $t \in [0,T]$ such that $\abs{\phi_t x} \geq \rho \abs{x}$.
\end{Lemma}

\begin{Corollary}
For all $x$ and for all $n$ there exists $t_n \leq n T$ such that $\abs{\phi_{t_n} x} \geq \rho^n \abs x$.
\end{Corollary}

\begin{Proposition}
The definition we have given for $H$ is well-defined at every point.
\end{Proposition}

\begin{Proof}
We just need to show that, for every $x \neq 0$, there exists $t$ such that $\abs{\phi_t x} \geq R/m$. But this is a trivial consequence of the previous remark.
\end{Proof}

\begin{Remark}
While we defined $H$ as a limit, note that it is a very particular kind of limit: one where the function in question stabilizes for big enough $t$.
\end{Remark}

This shows that $H$ exists, but we have not yet shown that it has any reasonable properties.

(And this is where I stopped)

\end{document}
