\documentclass{article}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{mathtools}

\title{Establishing with rigour and certainty the existance of Turing Machines that compute certain functions}
\author{Duarte Maia}
\date{}

\newtheorem{theorem}{Theorem}

\newcommand{\B}{\mathbf{B}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Ha}{\mathbf{H}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\Nc}{\mathcal{N}}
\newcommand{\Q}{\mathcal{Q}}
\newcommand{\prarrow}[1]{\overset{#1}{\rightarrow}}
\newcommand{\plarrow}[1]{\overset{#1}{\leftarrow}}
\DeclareMathOperator{\suc}{\mathbf{succ}}
\DeclareMathOperator{\run}{\mathbf{run}}
\DeclareMathOperator{\dom}{\mathrm{dom}}
\DeclareMathOperator{\runtime}{\mathbf{runtime}}
\DeclareMathOperator{\out}{\mathbf{out}}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclareMathOperator{\Nifat}{\mathbf{if\,at}}
\DeclareMathOperator{\Nthen}{\mathbf{then}}
\DeclareMathOperator{\Nelse}{\mathbf{else}}
\DeclareMathOperator{\Nendif}{\mathbf{endif}}
\DeclareMathOperator{\Nwhileon}{\mathbf{while\,on}}
\DeclareMathOperator{\Ndo}{\mathbf{do}}
\DeclareMathOperator{\Nendwhile}{\mathbf{endwhile}}


\begin{document}
	\maketitle

	\section{Introduction}

	It is to my dismay that books on computability, even those that boast of care and rigour, often skimp on showing the computability of functions. That is, to show that a certain function is computable, a Turing Machine is given (or the sketch of how such would be written) and an appeal to intuition is made so that the reader will `clearly see' that the given machine will halt in finite time and output the desired result.
	
	In this document, we will establish with rigour the computability of a certain class of functions (namely, $\mu$-recursive functions), and we will show that any $\mu$-recursive function can be computed by a Turing Machine.
	
	\section{Roadmap}
	
	Before we begin, a note on what lies ahead of us.
	
	Turing Machines are hard to tame beasts. The rules they obey are seemingly simple, but a lot of complexity is hidden by them. They are, in general, wild and unpredictable, given that branching can and will occur at almost any moment. We will not try to tame these wild beasts, but will instead make tools to allow us to build structured programs whose termination and correction are more reasonably provable. Of course, the Halting Problem guarantees us that we won't be able to find a recipe for proving these things, but that doesn't stop us from doing it on a case-per-case basis.
	
	We will, on top of Turing Machines, build two languages, one on top of the other. %give them names?
	The reason for this indirection is to make it easier to compile these languages to a Turing Machine, and to show that they have the semantics we wish them to have.
	
	Our goal is to make proving things easier, and so our final language will have as few `moving parts' as possible. For example, we will abolish the pointer position, giving us less state to keep track of.
	
	%how structured will this be?

	\section{Turing Machines}

	We start by giving a formal definition of Turing Machine. Ours will be a definition of a Turing Machine with a tape infinite only to the right. These definitions are an adaptation of the definition found in \cite{bridges}.
	
	We will consider fixed an alphabet $Y$, the \emph{tape alphabet}, containing at least one symbol, the `blank symbol', which we will denote by $\B$. We will consider another alphabet, $X \subseteq Y$, which is called the \emph{input alphabet}, that does not contain $\B$. These definitions will be as general as possible, but we will always assume in the following $X$ has at least two symbols: 0 and 1. That is, $\{0,1\} \subseteq X$.
	
	Given an alphabet $A$, the set of finite strings in $A$ (including the empty one, which we will denote by $\Lambda$) is denoted $A^*$. Given a string $s$, we will denote its length by $\lvert s \rvert$. The set of (countably infinite) sequences in $A$ will be denoted $A^\infty$:  these are, formally, functions from $\N^+$ to $A$.
	
	We will allow concatenation of finite strings $u, v$ by juxtaposition: $uv$. We will allow the usual abbreviations for building languages (sets of strings): if $L$ and $M$ are two languages, $LM$ represents the language containing strings of the form $\ell m$ where $\ell \in L, m \in M$. Union, in this context, is denoted by a +. When convenient, we will omit curly braces, for example using $1^*$ to represent all strings containing only 1, or $01^*0 + 0$ to represent all strings that start and end in zeros, with only ones in the middle.
	
	Given a string $s$ or language $A$, it will be useful to denote by $s \B^\infty$ or $A \B^\infty$ the sequence (or set of sequences) obtained by concatenating the string $s$ or language $A$ to the beginning of the sequence $\B\B\B\cdots$. A sequence of the form $s \B^\infty$ is said to be \emph{finitary}.
	
	Given a string or sequence $s$, we will use $s[i]$ to refer to the $i$-th character in $s$, and notations such as $s[i,j]$ or $s]i,j[$ or anything inbetween to refer to particular intervals. The question of whether the edges are included or not should be obvious by analogy with the notation for intervals. In the particular case of sequences, we also allow the notation $s[i, \infty[$.
	
	A \emph{Turing Machine} is a 4-uple $\M = (\Q, \delta, q_0, q_f)$, where:
	
	\begin{itemize}
	\item $\Q$ is a set, the so-called \emph{set of states}
	
	\item $\delta$ is a partial function $\Q \times Y \rightharpoonup \Q \times Y \times \{L, \Lambda, R\}$
	
	\item $q_0, q_f \in \Q$ are the so-called start and end states, respectively.
	
	\item $\delta(q_f, y)$ is undefined for all $y \in Y$
	\end{itemize}
	
	A \emph{tape state on $\M = (\Q, \delta, q_0, q_f)$} is a triple $T = (q, t, p)$ such that $q \in \Q$, $t \in Y^\infty$, $p \in \N^+$.
	
	Given a Turing Machine $\M = (\Q, \delta, q_0, q_f)$ and a tape state $T = (q, t, p)$, we will say $T' = (q', t', p')$ is the \emph{successor state of $T$} if:
	
	Let $\delta(q, t[p]) = (q', c, d)$ in
	
	\begin{itemize}
	\item $t' = t[1, p[ \, c \, t]p, \infty[$
	
	\item If $d$ is $L, \Lambda, R$, then $p = p' + 1, p = p', p + 1 = p'$, respectively.
	\end{itemize}
	
	The reader should have no trouble seeing that this state is unique (justifying calling it `the' successor rather than `a' successor), and it is not hard to see that it is not always defined. For example, if $p$ is $1$ and $d$ is $L$, the equation $p = p' + 1$ has no solution $p'$ in $\N^+$. Furthermore, this is obviously not defined if $\delta(q, t[p])$ is undefined, which it might very well be.
	
	We define the partial \emph{successor} function $\suc T = T'$.
	
	We say that the Turing Machine $\M = (\Q, \delta, q_0, q_f)$ \emph{halts on input $s$ with output $t$}, where $s, t \in X^*$, if there exists $n$ such that
	
	\[\suc^n (q_0, s \B^\infty, 1) = (q_f, t \B^\infty, 1)\]
	
	It is clear that given some input, the output on which $\M$ halts, if it exists, is unique, as this last state has no successor as $\delta(q_f, (t \B^\infty)[1])$ is undefined by definition.
	
	This allows us to define, for any Turing Machine $\M$, the partial function $\out_\M : X^* \rightharpoonup X^*$ that, given $s$, if $\M$ halts on input $s$ with some output $t$, returns $t$. It is otherwise undefined.
	
	In what follows, we will be interested in a more general meaning of `run' and `halt'. Namely, we will be interested in the behavior of machines that stop execution, even if they don't park on the left end of the tape, or with a tape of the form $X^* \B^\infty$, or if they don't necessarily start in these conditions.
	
	Suppose given a sequence $s$ and a position $p$, as well as a Turing Machine $\M$ with starting state $q_0$ and final state $q_f$. On the occasion that there exists $n$ such that $\suc^n (q_0, s, p) = (q_f, s', p')$ -- It is clear that this $n$ is unique due to the restriction enforced on the state change function -- we define the partial function $\runtime_\M (s,p) := n$, as well as $\run_\M (s, p) = (s', p')$. If these exist, we say $\M$ \emph{halts on the tape $(s,p)$ with the tape $(s', p')$ after $n$ steps}. Otherwise, we say $\M$ does not halt. Notice that this includes the case of undefined behavior, such as an undefined result for $\delta$, or trying to move $\L$ on position 0.
	
	\section{Computability}
	
	We have laid out the basic groundwork for defining what it means for a function to be Turing Computable:
	
	Given a partial function $f : X^* \supseteq A \rightharpoonup B \subseteq X^*$, we say $\M$ \emph{represents $f$ on $A$} if:
	
	\begin{itemize}
	
	\item For all $s \in \dom f$, $\out_\M s$ is defined and equals $f(s)$
	
	\item For all $s \in A \setminus \dom f$ either $\out_\M s$ is undefined, or it is not in $B$.
	
	\end{itemize}
	
	We wish to establish the computability or noncomputability of some functions. For example, we would like to show that the sum of natural numbers is computable. Of course, the sum is a function from $\N_0 \times \N_0$ to $\N_0$, neither of which are (unless you have a very odd notion of natural number and cartesian product) subsets of $X^*$, so we will have to adjust our definitions accordingly.
	
	As such, we will encode $n$-uples of natural numbers in a standard form: any natural number $n$ will be encoded in unary. The symbol $\ceil{n}$ will be used to denote the string composed of $n$ ones. That is:
	
	\[\ceil{n} = \underbrace{111\cdots1}_{n \text{ times}}\]
	
	Defining this inductively: $\ceil{0} = \Lambda$; $\ceil{n+1} = \ceil{n}1$.
	
	It is easy to see by induction that $\ceil{n+m} = \ceil{n}\ceil{m}$.
	
	We now move on to encoding $n$-uples of natural numbers. For our purposes, zero will serve as a comma. As such, the $n$-uple $(x_1, x_2, \cdots, x_n)$ is encoded as

	\[ \ceil{(x_1, x_2, \cdots, x_n)} = \ceil{x_1}0\ceil{x_2}0\cdots0\ceil{x_n} \]
	
	For our purposes, when convenient, we will identify $\N_0$ with the set of strings of ones, i.e. we will pretend $\N_0 = 1^*$, and likewise, we will identify $\N_0^n$ with the strings of the above form. That is, we identify:
	
	\[\N_0^n = \underbrace{1^*\,0\,1^*\,0\,1^*\,0 \cdots 0\,1^*}_{n \text{ zeroes}}\]
	
	This leaves us with only one caveat: the zero-uple. I have yet to find a satisfying way to define these things in a satisfactory way.
	
	Our definition of computable function will stay the same, but our focus will be mostly on functions from $\N_0^n$ to $\N_0$, where $n$ is greater than zero.\footnote{We could focus on functions from $\N_0^n$ to $\N_0^m$, but any such function can just be represented by $m$ functions from $\N_0^n$ to $\N_0$, and so, we can restrict our study to this slightly easier class of functions without loss of generality.} It is a shame to be excluding the zeroary functions, but fortunately, these are just constants, and thus of little interest, as a function to compute these would simply erase the tape and write its own output, making all such functions trivially computable.
	
	So, we wish to investigate the set of Turing computable functions. Examples of functions we would love to show computable would be, for example, the function $+ : \N_0^2 \rightarrow \N_0$, or $\times$, or $- : \N_0^2 \rightharpoonup \N_0$. However, while writing out a program for each of these is not of extreme difficulty, showing formally that they terminate and that the output is what we expect it to be is tedious. So much so, in fact, that most books on the subject simply forego this verification for the most part.
	
	The main reason for this is that, on Turing Machines, there is a lot of global state to keep track of, and relatively few tools to keep track of it. Not only do we have both the tape and pointer position to keep track of, it is also very hard in general to modify arbitrary data, as, unless we are modifying something at the rightmost end of the written data, we will have to shuffle things over to make room, which, without being very careful about how we organize the data, might very well be an enormous headache. Add to it the fact that there are no limitations on control flow (you can jump from any state to any other state without restrictions) and it is extremely hard to show the correctness of a given program.
	
	As such, in this study, we will develop a sort of `compiled language', which will sit on Turing machines and which we will show can be compiled to one, with the semantics we will later establish, and about which it will be much easier to reason about, using techniques such as (a modified version of) Hoare calculus.
	
	The first step in this path is to develop a set of instructions (composed of possibly more than one state) whose behavior we can reason about in abstract. But before we do that, we will need a way to compose them.
	
	\section{Composition}
	Our first special program is going to be composition.
	
	Given two Turing Machines, $\M_1$ and $\M_2$, their \emph{composition}, denoted $\M_1;\M_2$, is the machine $\M$ described as follows:
	
	Let 
	
	\[\M_1 = (\Q_1, \delta_1, q_{10}, q_{1f})\]
	\[\M_2 = (\Q_2, \delta_2, q_{20}, q_{2f})\]
	
	Define
	
	\[ \M = \M_1 ; \M_2 \]
	
	As $\M = (\Q, \delta, (q_{10}, 1), (q_{2f}, 2))$ such that:
	
	\begin{itemize}
	\item $\Q = \{\, (q, i) \mid q \in \Q_i, i = 1,2 \,\}$
	
	\item $\delta((q, i), y) = ((q', i), c, d)$ where $\delta_i(q,y) = (q', c, d)$ and $q \neq q_{if}$
	
	\item $\delta((q_{1f}, 1), y) = ((q_{20}, 2), y, \Lambda)$
	\end{itemize}
	
	Predictably, we prove that this machine has the expected behavior: it's as though we ran $\M_1$ until it halts, followed by running $\M_2$ on the result.
	
	\begin{theorem}
	Fix the Turing Machines:
	
	\[\M_1 = (\Q_1, \delta_1, q_{10}, q_{1f})\]
	\[\M_2 = (\Q_2, \delta_2, q_{20}, q_{2f})\]
	
	And some sequence $s$ and position $p$. Let $\M = (\Q, \delta, q_0, q_f) = \M_1 ; \M_2$. Then, we have
	
	\[\run_\M (s,p) = \run_{\M_2} \run_{\M_1} (s,p)\]
	\[\runtime_\M (s,p) = \runtime_{\M_1} (s,p) + 1 + \runtime_{\M_2} \run_{\M_1} (s,p)\]
	
	(This includes the case of non-halting, as, in that case, both sides will be undefined).
	\end{theorem}
	
	\begin{proof}
	To simplify the exposition, we introduce the following notation:
	
	Given two triples $(q, c, d)$ and $(q', c', d')$, we say $(q, c, d) \prarrow{i} (q', c', d')$ if $c = c', d = d'$ and $q' = (q, i)$.
	
	Let $n_1 = \runtime_{\M_1} (s,p)$ and $n_2 = \runtime_{\M_2} \run_{\M_1} (s,p)$. We suppose for now that both of these exist.
	
	Now, we show by induction that for $i = 0, \cdots, n_1$ we have that
	
	\[\suc^{i}_{\M_1} (q_{10}, s, p) \prarrow{1} \suc^{i}_{\M} ((q_{10}, 1), s, p)\]
	
	
	For $i = 0$ this is obvious. Suppose this is true for some $i < n_1$.
	
	That is, suppose 
	
	\[\suc^{i}_{\M_1} (q_{10}, s, p) = (q', s', p')\]
	\[\suc^{i}_{\M} ((q_{10}, 1), s, p) = ((q', 1), s', p')\]
	
	Thus,
	
	\[\suc^{i+1}_{\M_1} (q_{10}, s, p) = \suc_{\M_1} (q', s', p')\]
	\[\suc^{i+1}_{\M} (q_{10}, s, p) = \suc_{\M} ((q',1), s', p')\]
	
	Supposing $\delta_1(q', s'[p']) = (q'', c, d)$, we have that $\delta((q', 1), s'[p']) = ((q'', 1), c, d)$. The reader can now easily examine the three cases of the definition of successor to see that, indeed, if the former is $(q'', s'', p'')$, the latter will be $((q'', 1), s'', p'')$.
	
	(If $n_1$ does not exist, either you can continue this process indefinitely, thus showing that $\M$ never reaches the final state, or at some point the successor will be undefined, thus showing $\M$ does not halt because of undefined behavior.)
	
	Now, notice that if
	
	\[\suc^{n_1}_{\M_1} (q_{10}, s, p) = (q_{1f}, t, p_1)\]
	
	Then, by what we just showed,
	
	\[\suc^{n_1}_{\M} ((q_{10}, 1), s, p) = ((q_{1f}, 1), t, p_1)\]
	
	Taking the successor of the latter, we know that, for $i = 0$,
	
	\[\suc^{i}_{\M_2} (q_{20}, t, p_1) = (q_{20}, t, p_1)\]
	\[\suc^{n_1+1+i}_{\M} ((q_{10}, 1), s, p) = ((q_{20}, 2), t, p_1)\]
	
	We will show that for $i = 0, \cdots, n_2$ we have that, if
	
	\[\suc^{i}_{\M_2} (q_{20}, t, p_1) \prarrow{2} \suc^{n_1+1+i}_{\M} ((q_{10}, 1), s, p)\]
	
	We already saw it true for $i=0$, so we show it true for the rest by induction.
	
	Suppose $i < n_2$. Then assuming it true for $i$, we have,
	
	\[\suc^{i+1}_{\M_2} (q_{20}, t, p_1) = \suc_{\M_2} (q', t', p')\]
	
	\[\suc^{n_1+1+(i+1)}_{\M} ((q_{10}, 1), s, p) = \suc_{\M} ((q', 2), t', p')\]
	
	Repeating the same argument as before, we see that if $\delta_2(q', t'[p']) = (q'', c, d)$, then $\delta((q',2), t'[p']) = ((q'', 2), c, d)$ as $q' \neq q_{2f}$, and so, checking against the definition of successor, if the former is $(q'', t'', p'')$ then the latter will be $((q'', 2), t'', p'')$.
	
	(As with last time: if $n_12$ does not exist, either you can continue this process indefinitely, thus showing that $\M$ never reaches the final state, or at some point the successor will be undefined, thus showing $\M$ does not halt because of undefined behavior.)
	
	This culminates in $i = n_2$, where we have
	
	\[\suc^{n_2}_{\M_2} (q_{20}, t, p_1) = (q_{2f}, r, p_2)\]
	
	And so,
	
	\[\suc^{n_1 + 1 + n_2}_{\M} ((q_{10},1), s, p) = ((q_{2f},2), r, p_2)\]
	
	As we wished.
	
	We mostly dealt with the case where both machines halt, but the parenthical comments are enough to justify that the proposition is still true in the event of non-halting.
	\end{proof}
	
	This last proposition tells us something very important, that will form the basis of most of what we will do from now on.
	
	Let $\phi, \psi, \omega$ be propositions of two free variables: a sequence $s$ and a positive integer $p$. Given a machine $\M$, the symbol $\phi\M\psi$ represents the proposition `if $\phi(s,p)$ is true and $\run_\M(s, p) = (s', p')$, then $\psi(s', p')$ is true.'
	
	Sometimes the juxtaposition notation will be inadequate. If this is the case, we also allow using curly braces to group propositions, as such: $\{\phi\}\M\{\psi\}$.
	
	
	\begin{theorem}
	If $\phi \M_1 \psi$ and $\psi \M_2 \omega$, then $\phi \M_1;\M_2 \omega$
	\end{theorem}
	
	\begin{proof}
	
	We have already shown $\run_{\M_1;\M_2} (s,p) = \run_{\M_2} \run_{\M_1} (s,p)$. If any of this is undefined, the theorem is true by definition. Otherwise, we know that if $\phi$ is true applied to $(s,p)$, then $\psi$ is true applied to $\run_{\M_1} (s,p)$ and thus $\omega$ is true applied to $\run_{\M_1;\M_2} (s,p) = \run_{\M_2} \run_{\M_1} (s,p)$, as we wished to show.
	\end{proof}
	
	We move on to our second special program: conditional branching.
	
	Fix two Turing Machines, $\M_1$ and $\M_2$ such that
	
	\[\M_1 = (\Q_1, \delta_1, q_{10}, q_{1f})\]
	\[\M_2 = (\Q_2, \delta_2, q_{20}, q_{2f})\]
	
	And fixed some element $y_0$ of $Y$, we define the following Turing Machine:
	
	\[ \M = \Nifat y_0 \Nthen \M_1 \Nelse \M_2 \Nendif \]
	
	As $\M = (\Q, \delta, q_0, q_f)$ such that:
	
	\begin{itemize}
	\item $\Q = \{\,(q, i) \mid q \in \Q_i, i = 1,2\,\} \cup \{q_0, q_f\}$
	
	\item $q_0$ and $q_f$ are distinct symbols
	
	\item $\delta(q_0, y_0) = ((q_{10}, 1), y_0, \Lambda)$
	
	\item $\delta(q_0, y) = ((q_{20}, 2), y, \Lambda)$ for all $y \neq y_0$
	
	\item $\delta((q, i), y) = ((q', i), c, d)$ if $\delta_i(q, y) = (q', c, d)$
	
	\item $\delta((q_{if}, i), y) = (q_f, y, \Lambda)$
	\end{itemize}
	
	This machine's behavior is what it says on the tin, as the next proposition shows.
	
	\begin{theorem}
	Let $s$ be a sequence, $p$ a position, $y_0 \in Y$, and the following Turing Machines:
	
	
	\[\M_1 = (\Q_1, \delta_1, q_{10}, q_{1f})\]
	\[\M_2 = (\Q_2, \delta_2, q_{20}, q_{2f})\]
	\[\M = (\Q, \delta, q_0, q_f) = \Nifat y_0 \Nthen \M_1 \Nelse \M_2 \Nendif \]
	
	If $s[p] = y_0$ then $\run_{\M_1} (s, p) = \run_\M(s,p)$ and $\runtime_{\M_1}(s,p) + 2 = \runtime_\M(s,p)$.
	
	If $s[p] \neq y_0$ then $\run_{\M_2} (s, p) = \run_\M(s,p)$ and $\runtime_{\M_2}(s,p) + 2 = \runtime_\M(s,p)$.
	\end{theorem}
	
	\begin{proof}
	We will only do the proof for the first case, as the proof of the second is completely analogous.
	
	Suppose, then $s[p] = y_0$. We have $\suc_\M (q_0, s, p) = ((q_{10}, 1), s, p)$, as the reader may easily verify.
	
	From now on, we show by induction that, for $i = 0, \cdots, n$, if
	
	\[\suc^i_{\M_1} (q_{10}, s, p) = (q, s', p')\]
	
	Then
	
	\[\suc^{1+i}_\M (q_0, s, p) = ((q, 1), s', p')\]
	
	For $i = 0$ this has already been shown. Suppose, now, this is true for some $i < n$.
	
	Applying the definition of $\delta$ vs $\delta_1$, knowing that $q \neq q_{1f}$, one can easily see that if the state change for the former is given by $(q', c, d)$, the state change for the latter is given by $((q', 1), c, d)$, and so the successors will also obey this relation.
	
	Finally, now that we know that if $\suc^n_{\M_1} (q_{10}, s, p) = (q_{1f}, s', p')$ then $\suc^{1+n}_\M (q_0, s, p) = ((q_{1f}, 1), s', p')$, applying the successor function to the latter once more, we get $\suc^{n+2}_\M (q_0, s, p) = (q_f, s', p')$, as we wished to show.
	
	This finishes the proof of the first case. As said before, the proof of the second case is completely analogous.
	\end{proof}
	
	This gives us the following corollary:
	
	\begin{theorem}
	Suppose that $\{\phi \land s[p] = y_0\} \M_1 \{\psi\}$ and $\{\phi \land s[p] \neq y_0\} \M_1 \{\psi\}$. Then,
	
	\[\{\phi\} \Nifat y_0 \Nthen \M_1 \Nelse \M_2 \Nendif \{\psi\}\]
	\end{theorem}
	
	\begin{proof}
	Let $\M = \Nifat y_0 \Nthen \M_1 \Nelse \M_2 \Nendif$. We wish to show $\{\phi\}\M\{\psi\}$.
	
	Suppose $\phi$ is true of $(s,p)$. Then, one of two cases happens:
	
	Either $s[p] = y_0$, in which case $\run_\M(s,p) = \run_{\M_1}(s,p)$. Since $\phi(s,p)$ and $s[p] = y_0$ we have, by hypothesis on $\M_1$, that $\psi$ is true applied to $\run_{\M_1}(s,p) = \run_\M(s,p)$.
	
	On the other hand, it could happen that $s[p] \neq y_0$, in which case $\run_\M(s,p) = \run_{\M_2}(s,p)$. Applying the same argument, we get that in this case $\psi$ is also true applied to $\run_\M(s,p)$.
	
	In both cases, we reach the conclusion that, if $\phi$ is true of $(s,p)$, then $\psi$ is true of $\run_\M(s,p)$, as we intended.
	\end{proof}
	
	We finish this section with the last kind of composition we will need for sanely making Turing Machines.

	Fixed some subset $S$ of $Y$ and a Turing Machine $\M_1 = (\Q_1, \delta_1, q_{10}, q_{1f})$, we define the following Turing Machine:
	
	\[ \M = \Nwhileon S \Ndo \M_1 \Nendwhile \]
	
	As $\M = (\Q, \delta, q_0, q_f)$ such that:
	
	\begin{itemize}
	\item $\Q = \Q_1 \cup \{q_0, q_f\}$
	
	\item $q_0$ and $q_f$ are symbols not in $\Q$
	
	\item $\delta(q_0, y) = (q_{10}, y, \Lambda)$ for all $y \in S$
	
	\item $\delta(q_0, y) = (q_f, y, \Lambda)$ for all $y \not\in S$
	
	\item $\delta(q, y) = \delta_1(q, y)$ for all $q \in \Q_1$ if $q \neq q_{1f}$
	
	\item $\delta(q_{1f}, y) = (q_0, y, \Lambda)$
	\end{itemize}
	
	The semantics of this machine are slightly harder to pinpoint than the rest, but it is doable.
	
	\begin{theorem}
	Let $\M_1$ be a Turing Machine, $S \subseteq Y$, and $\M = \Nwhileon S \Ndo \M_1 \Nendwhile$. Fix a tape $(s,p)$.

	Suppose that, for some $k$, $\run_{\M_1}^k (s,p) = (s', p')$ is such that $s'[p'] \not \in S$. Consider the smallest such $k$. Then, $\run_\M (s,p) = \run_{\M_1}^k (s,p)$ and 
	
	\[\runtime_\M (s,p) = k + 1 + \sum_{i=1}^k \runtime_{\M_1} \run_{\M_1}^{k-1}(s,p)\]
	
	If such a $k$ does not exist, $\run_\M(s,p)$ is undefined.
	\end{theorem}
	
	\begin{proof}
	First, suppose such a $k$ exists. We will show that, for $i = 0, \cdots, k$, there exists $n$ such that
	
	\[\suc_\M^n (s,p) = (q_0,  \run_{\M_1}^i (s,p))\]
	
	For $i = 0$ this is obvious, with $n = 0$. Suppose now that this is true for some $i < k$, with some $n$, and we will show it true for $i+1$.
	
	Let $(s', p') = \run_{\M_1}^i (s,p)$, and so, by hypothesis, $\suc_\M^n (s,p) = (q_0, s', p')$.
	
	Suppose $(s'', p'') = \run_{\M_1}(s',p')$. Let $n_1$ be the runtime of this.
	
	We will show that $\suc_\M^{j+1} (q_0, s',p') = \suc_{\M_1}^j (q_{10}, s', p')$ for $j = 0, \cdots, n_1$.
	
	This is clearly true for $j = 0$, as the latter will be simply $(q_{10}, s', p')$ and the former, since $i < k$ and thus $s'[p'] \not \in S$, will be $(q_{10}, s', p')$, as $\delta(q_0, s'[p']) = (q_{10}, s'[p'], \Lambda)$. One can easily check that, if true for $j < n_1$, it is true for $j+1$, which shows what we desired.
	
	Finally, we get that $\suc_\M^{n_1+1} (q_0, s',p') = \suc_{\M_1}^{n_1} (q_{10}, s', p') = (q_{1f}, s'', p'')$ and so, taking the successor again, $\suc_\M^{n_1 + 2}(q_0, s', p') = (q_0, s'', p'')$.
	
	In other words, $\suc_\M^{n + n_1 + 2}(q_0, s, p) = (q_0, \run_{\M_1}^{i+1} (s, p))$, as we wished to show.
	
	Put $i = k$ to get that there exists $n$ such that $\suc_\M^n(q_0, s, p) = (q_0, \run_{\M_1}^k(s, p))$. Now, take the successor of the left hand side. Since, by definition of $k$, we have, if $(s', p') = \run_{\M_1}^k(s, p)$ then $y = s'[p'] \not \in S$. As such, $\delta(q_0, y) = (q_f, y, \Lambda)$, and thus $\suc_\M^{n+1}(q_0, s, p) = (q_f, \run_{\M_1}^k(s, p))$ and so $\run_\M(s, p) = \run_{\M_1}^k (s, p)$ as we wished to show.
	
	This deals with the case where such a $k$ exists. If it does not, then the induction step can be done \textit{ad infinum}. If there is undefined behavior at any point, then $\run_\M(s, p)$ is undefined as desired. On the other hand, if there is no undefined behavior but $(s', p') = \run_{\M_1}^i (s,p)$ is never such that $s'[p'] \not \in S$, $\M$ will never reach the final state (as the induction above shows) and so $\run_\M(s, p)$ is undefined. This concludes our demonstration.
	\end{proof}
	
	\begin{theorem}
	Fix $\M_1$, $S$, and suppose $\M = \Nwhileon S \Ndo \M_1 \Nendwhile$. Then, if
	
	\[\{\phi \land s[p] \in S\}\M_1\{\phi\}\]
	
	We have
	
	\[\{\phi\}\M\{\phi \land s[p] \not \in S\}\]
	\end{theorem}
	
	\begin{proof}
	In the case that these machines do not halt, the result is trivial, so let's suppose they do. Let $k$ be as described in the previous theorem, and let $(s,p)$ obey $\phi$.
	
	We will show by induction that for $i = 0, \cdots, k$ we have $(s', p') = \run_{\M_1}^i (s, p)$ obeys $\phi$.
	
	For $i = 0$ this is trivial. Suppose, then, it is true for $i < k$.
	
	Since $i < k$, by definition of $k$ we have that $(s', p') = \run_{\M_1}^i (s, p)$ obeys $s'[p'] \in S$. Furthermore, by the induction hypothesis, it also obeys $\phi$. As such, $\run_{\M_1}(s', p') = \run_{\M_1}^{i+1}(s,p)$ obeys $\phi$, as we wished to show.
	
	Plug in $i = k$. We know $(s', p') = \run_{\M_1}^k (s, p) = \run_\M(s,p)$ obeys $\phi$, and also, by definition of $k$, $s'[p'] \not \in S$. As such, it obeys $\phi \land s'[p'] \not \in S$ as we wished to show.
	\end{proof}
	
	\section{Total Correction}
	
	The previous results give us ways to manufacture programs and show their correction. That is, if they halt given correct input, they halt with correct output.
	
	This is not enough to show they actually compute a function, however. Indeed, we still need to show that they halt. For composition and branching, this is easy. As we showed in the respective propositions:
	
	If $\M_1$ halts on correct input, and $\M_2$ halts on $\M_1$'s correct output, then $\M_1;\M_2$ halts on correct input.
	
	If $\M_1$ halts on input that obeys $\phi$ and $s[p] = y_0$, and $\M_2$ halts on input that obeys $\phi$ and $s[p] \neq y_0$, then $\Nifat y_0 \Nthen \M_1 \Nelse \M_2 \Nendif$ halts on input that obeys $\phi$.
	
	In fact, for these two cases we even gave a formula for the amount of time taken for halting.
	
	The case for While, however, is trickier. There is a direct condition for termination, but it turns out to be unwieldy at times. Regardless, we present it here.
	
	\begin{theorem}
	Let $r = \run_\M_1$, $(s,p)$ be a tape, and suppose that if $r^i(s,p) = (s', p')$ is defined and $s'[p'] \in S$ then $r^{i+1}(s,p)$ is also defined. Suppose, also, that there exists $k$ such that $r^k(s,p) = (s', p')$ is defined and $s'[p'] \not \in S$. Suppose $k$ is minimal without loss of generality.
	
	Then, if $\M = \Nwhileon S \Ndo \M_1 \Nendwhile$, we have $\M$ halts on input $(s,p)$, with output $r^k(s,p)$.
	\end{theorem}
	
	This is clearly not a wieldy condition to use to show termination! As such, we present a slightly more amenable condition, making use of the concept of \emph{monovariant}.
	
	
	
\begin{thebibliography}{9}
\bibitem{bridges} 
Bridges, Douglas S.
\textit{Computability - A Mathematical Sketchbook}. 
Springer, 1994. %i don't know how to do this right
\end{thebibliography}	

\end{document}