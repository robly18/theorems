\documentclass{article}

\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}

\title{On nice enough ODEs and dependency on initial conditions}
\author{Duarte Maia}
\date{}

\newcommand{\R}{\mathbb{R}}

\newcommand{\dd}{\mathrm{d}}

\begin{document}
\maketitle

\section{Introduction}

This document is a repository for me to write down the sequence of results necessary to prove, from scratch, that the flow of a vector field exists and is smooth, in some sense. The flow is obtained by solving an ODE, which means that I want to show that, under some niceness assumptions, the solutions of an ODE exist locally and vary smoothly when the initial conditions change. In this document, I will only solve the case for $\R^n$, as translating that to the original goal (proving vector field flows exist) is beyond the scope of this.

\section{Picard-Lindelöf}

The Picard-Lindelöf theorem states that, fixed initial conditions, the solution of an ODE exists locally and is unique globally.

To be more precise: suppose $f : D \to \R^n$, $D$ open subset of $\R \times \R^n$, is a \emph{continuous} function satisfying the following property: for any compact $K \subseteq D$, $f|_K$ is (uniformly) Lipschitz in $x$. That is, there exists a constant $L$ such that for all $(t,x) \in K$ and $(t, y) \in K$ we have $\lvert f(x) - f(y) \rvert \leq L \lvert x - y \rvert$. We will later give general enough conditions for this to happen (for example, $f$ $C^1$ is enough).

Fix $(t_0, x_0) \in D$. We will show that the ODE given by
\begin{equation}\label{ode}
\begin{cases}
x'(t) = f(t, x)\\
x(t_0) = x_0
\end{cases}
\end{equation}
has a unique solution.

We begin by showing existence. Fix $(t_0, x_0) \in D$. Let $I \times R$ be a compact neighborhood of this point. Let $M$ be the maximum of $\lvert f \rvert$ over this set and $L$ the Lipschitz constant of $f$. Pick $\alpha > 0$ small enough such that
\[B_\alpha(t_0) \times \overline B_{M \alpha}(x_0) \subseteq I \times R \text{ and } \alpha L < 1.\]
Now put
\[X = \{\, \varphi \in C(B_\alpha(t_0), \R^n) \mid d(\varphi(t), x_0) \leq M d(t, t_0)\,\}.\]
We may define $T : X \to X$ given by
\[T(\varphi)(t) = x_0 + \int_{t_0}^t f(s, \varphi(s)) \dd s.\]

The conditions imposed by $\varphi \in X$ guarantee that this is well-defined for all $t \in B_\alpha(t_0)$ and remains in $X$. Now, given two functions $\varphi, \psi \in X$ we conclude
\begin{align*}
\lvert T \varphi - T\psi \rvert &= \lvert \int_{t_0}^t f(s, \varphi) - f(s, \psi) \dd s \rvert\\
&\leq \int_{t_0}^t L \lvert \varphi - \psi \rvert\\
&\leq \alpha L \lVert \varphi - \psi \rVert_\infty,
\end{align*}
which shows that $T$ is contracting in the sup norm. Standard arguments (Cauchy sequences) show that this implies $T^n x_0$ converges to some function $\varphi$, and note that $\varphi$ must be a fixed point of $T$, for
\[\lVert T T^n x_0 - T \varphi \rVert \leq \alpha L \lVert T^n x_0 - \varphi \rVert \to 0,\]
and so $T^{n+1} x_0$ converges to $T \varphi$, but since it is a subsequence of $T^n x_0$ it also converges to $\varphi$, which shows equality.

We conclude that $\varphi$ is a continuous function satisfying $\varphi(t) = x_0 + \int_{t_0}^t f(s, \varphi(s)) \dd s$, and differentiating both sides we obtain it is a local solution of the original ODE.

Now for uniqueness. Let $x$ and $y$ be two solutions defined in a common interval $[t_0, t_1]$ without loss of generality. Then,
\begin{align*}
\lvert x(t) - y(t) \rvert \leq \lvert \int_{t_0}^t f(s,x) - f(s,y) \dd s \rvert\\
\leq \int_{t_0}^t L \lvert x - y \rvert,
\end{align*}
where $L$ is the Lipschitz constant that exists on the compact set given by the union of the curves given by $x$ and $y$. By Gronwall's lemma, this implies $x = y$ on the interval.

\section{Maximality of solutions}

Consider the ODE \eqref{ode}. We will show that there is a maximal solution, where we take solutions to be defined in an open interval containing $t_0$.

Define $I_M$ as the union of the intervals of definition of all possible (contiguous) solutions of the ODE. By the uniqueness part of Picard-Lindelöf, all solutions agree where mutually defined, so there is an unambiguous $x$ defined on $I_M$, which is a solution of the ODE, and clearly the maximal possible.

It is possible to show that if $I_M$ is bounded, say, from above, then in some sense $x$ is `exploding' or leaving $D$. Indeed, in this case, call the supremum of $I_M$ by the name $t_f$. We assert that either $f(t, x)$ is unbounded as $t \to t_f$ or, in the negative case, $(t, x(t))$ converges to a limit $(t_f, x_f)$ as $t \to t_f$, and this limit lies outside $D$.

Suppose, then, $f(t,x)$ is bounded as $t \to t_f$. Then $x'$ is bounded and so it converges as $t \to t_f$, because $x$ is also bounded and so has a converging subsequence, but boundedness of the derivative implies that any two sublimits coincide. As such, let $x_f$ be the limit.

If $(t_f, x_f) \in D$ then it would be possible to find $\varphi : \left[t_f, t_f + \varepsilon\right[ \to \R^n$ that is also a solution of the ODE. It is easy to see (calculating the left-derivative) that gluing $\varphi$ to the end of $x$ gives us another (bigger) solution of the ODE, contradicting $x$'s maximality.

\section{Continuity of initial conditions}

Define $x(t_0, x_0)(t)$ to be the solution of the ODE \eqref{ode} with the given initial conditions. Given $t_0, x_0$ fixed, suppose $x(t_0, x_0)$ is defined on an interval $[a,b]$. We will show that for $t_1, x_1$ close enough to $t_0, x_0$ the solution is also defined in $[a,b]$, and $x$ is continuous as a function from this neighbourhood to $C[a,b]$ with the sup norm.

\end{document}
