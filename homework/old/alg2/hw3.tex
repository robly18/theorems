\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts,stmaryrd}
\usepackage{mathtools}

\usepackage[thmmarks, amsmath]{ntheorem}
\usepackage{fullpage}

\usepackage{graphicx}

\usepackage{diffcoeff}
\diffdef{}{op-symbol=\mathrm{d},op-order-sep=0mu}

\usepackage{cancel}
\usepackage{interval}

\usepackage{enumitem}

\setlist[enumerate,1]{label=(\alph*)}

\title{Algebra Homework 2}
\author{Duarte Maia}
%\date{}

\theorembodyfont{\upshape}
\theoremseparator{.}
\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Prop}
\renewtheorem*{prop*}{Prop}
\newtheorem{lemma}{Lemma}

\newtheorem{ex}{Exercise}

\theoremstyle{nonumberplain}
\theoremheaderfont{\itshape}
\theorembodyfont{\upshape}
\theoremseparator{:}
\theoremsymbol{\ensuremath{\blacksquare}}
\newtheorem{proof}{Proof}
\newtheorem{sol}{Solution}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\K}{\mathbb{K}}

\newcommand{\kk}{\Bbbk}

\newcommand{\PP}{\mathbb{P}}
\newcommand{\Gr}{\mathrm{Gr}}

\newcommand{\I}{\mathrm{i}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\id}{\mathrm{id}}

\newcommand{\conj}[1]{\overline{#1}}

\newcommand{\grad}{\nabla}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\image}{im}
\DeclareMathOperator{\ord}{ord}
\let\radical\relax
\DeclareMathOperator{\radical}{rad}

\newcommand{\Aff}{\mathbb{A}}

\newcommand{\HH}{\mathcal{H}}
\newcommand{\bbH}{\mathbb{H}}

\let\Im\relax
\DeclareMathOperator{\Im}{Im}
\let\Re\relax
\DeclareMathOperator{\Re}{Re}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lvert}{\rvert}
\DeclarePairedDelimiter{\Norm}{\lVert}{\rVert}
\DeclarePairedDelimiter{\braket}{\langle}{\rangle}


\begin{document}
\maketitle

\begin{ex}
\leavevmode
\begin{enumerate}
\item Let $I$ be nilpotent. Assuming that $M/IM$ is finitely generated, show that $M$ is as well, with the same number of generators.
\item Let $I$ be the ideal of combinations positively graded elements. Assuming that $M/IM$ is finitely generated, show that $M$ is as well.
\end{enumerate}
\end{ex}

\begin{sol}
\leavevmode
\begin{enumerate}
\item Let $[g_1], \dots, [g_n]$ be the generators of $M/IM$. We show that $g_1, \dots, g_n$ are generators of $M$.

To see this, pick $m \in M$. Then, since the $[g_k]$ generate $M/IM$, we may write $m$ in the form
\begin{equation}
m = \left( \sum r_k g_k \right) + \sum i_k m'_k,
\end{equation}
with $r_k \in R$, $i_k \in I$, $m'_k \in M$. Then, we repeat the same process with the $m'_k$, and simplifying we obtain an expression of the form
\begin{equation}
m = \left( \sum r'_k g_k \right) + \sum i_k j_\ell m''_{k\ell},
\end{equation}
and so on. Once this process has been repeated $N$ times, the right-hand side will evidently be in $I^N M$, so for $N$ big enough this ensures that it does not exist, and so we may write $m$ as a linear combination of the $g_k$, as desired.

\item A similar argument to the above works. However, first, we assume withotu loss of generality that the $g_k$ are homogeneous elements of $M$. (If they are not, divide them into their homogeneous parts.)

Now, by the same argument, we write
\begin{equation}\label{eq:m}
m = \left( \sum r_k g_k \right) + \sum i_k m'_k,
\end{equation}
with the $r_k \in R$, $i_k \in I$, and $m'_k$ in $M$, and repeat the process iteratively. Now, without loss of generality, we may assume that all variables in \eqref{eq:m} are homogeneous and that all members of the right-hand side have degree equal to the degree of $m$. Thus, since the degree of $i_k$ is strictly positive, the degree of the $m'_k$ is strictly less than the degree of $m$. This hypothesis takes the role that `$I$ is nilpotent' did in the previous item, as it guarantees that the process will eventually terminate, given that the degree is decreasing at every step.
\end{enumerate}
\end{sol}

\begin{ex}
Show that $R^G$ is a finitely generated $\kk$-algebra.
\end{ex}

\begin{sol}
First, we note that $I R$ is finitely generated as an ideal of $R$, because $R$ is Noetherian. Now, let $g_1, \dots, g_m$ be a finite collection of homogeneous generators of $I R$ as an ideal of $R$. Each of these may be written in the form $\sum i_k r_k$, for $i_k \in I$. If $p_1, \dots, p_n$ is an enumeration of the $i_k$ that show up, we conclude that these $p_i \in I$ form a collection of generators of $I R$ as an $R$-ideal. We now show that they generate $R^G$ as a $\kk$-algebra.

Let $q$ be a polynomial in $R^G$. Since the action of $G$ preserves polynomial degree and homogeneity, $R^G$ is a graded subring of $R$, so we may without loss of generality assume that $q$ is homogeneous of degree $d$ by considering its homogeneous components. If $d = 0$ then $q$ is in the algebra generated by the $p_i$ because such an algebra includes scalars by definition. Otherwise, $q \in I \subseteq I R$, so we may write $q = \sum q_i p_i$ for some homogeneous polynomials $q_i$. By applying the Reynolds operator to both sides, we may without loss of generality assume that the $q_i$ are $G$-invariant (because everything else already is). Moreover, their degree is strictly less than $d$, because each $p_i$ has positive degree, so we may recursively apply this process on the $q_i$ until we reach scalars. In the end, we will have written $q$ as a sum of terms of the form: scalar $\times p_{i_1} \times \dots p_{i_k}$, thus showing that it is in the algebra generated by the $p_i$.
\end{sol}

\begin{ex}
Check that the map $\PP^1 \to C$ is an isomorphism. Show that $C$ is contained within a smooth quadric $Q \subseteq \PP^3$ which is isomorphic to $\PP^1 \times \PP^1$, and that $C$ can be realized inside $Q$ as the zero locus of a bihomogeneous polynomial.
\end{ex}

\begin{sol}
Recall from a previous homework that $C$ is given by the vanishing locus of the equations (on variable $[X:Y:Z:W]$)
\begin{equation}\label{eq:1}
\begin{cases}
XW = YZ,\\
XZ = Y^2,\\
YW = Z^2.
\end{cases}
\end{equation}

Now, the quadric $Q$ is question is given by the vanishing locus of the polynomial $XW - YZ$. Evidently, $C$ is contained in $Q$. Moreover, we built in the first pset a bijection between $Q$ and $\PP^1 \times \PP^1$, in the form
\begin{equation}
\begin{aligned}
g \colon \PP^1 \times \PP^1 &\to Q\\
[A:B],[C:D] &\mapsto [AC:AD:BC:BD],
\end{aligned}
\end{equation}
and we also showed that its inverse was locally given by $[X:Y:Z:1] \mapsto [Y:1],[Z:1]$ (and similar expressions on other copies of affine space). There is an unproven fact here, which is that a function $X \times Y \to Z$ which is locally written in terms of rational expressions is a regular map, but this is plausible enough. Using this fact, we see that $g$ is an isomorphism of quasiprojective algebraic sets.

To conclude, we note that the copy of $C$ sitting inside $\PP^1 \times \PP^1$ has the equations (obtained by pulling back \eqref{eq:1})
\begin{equation}\label{eq:2}
\begin{cases}
AC \, BC = A^2 D^2,\\
AD \, BD = B^2 C^2.
\end{cases}
\end{equation}

We claim that this system of equations is equivalent to the sole equation $BC^2 = AD^2$. Indeed, the latter evidently implies \eqref{eq:2}. On the other hand, suppose that \eqref{eq:2} holds. Then, either $A$ or $B$ is nonzero. If $A \neq 0$, look at the first equation and divide out by $A$ to obtain $BC^2 = AD^2$. If $B \neq 0$, divide the second equation out by $B$ instead.
\end{sol}

\begin{ex}
\leavevmode
\begin{enumerate}
\item Check that if $\omega_0 \in Q$ represents a given line $\ell_0 \subset \PP^3$, then the locus of lines in $\PP^3$ which meet $\ell_0$ is given by the zero locus of the equations $\omega \wedge \omega = 0$ and $\omega \wedge \omega_0 = 0$. Check in coordinates that this is a hyperplane section of $Q$.

\item Pick four general skew lines $\ell_0, \dots, \ell_3$. Assume that $\ell_0 = \braket{e_1, e_2}$ and $\ell_1 = \braket{e_3, e_4}$. If $\ell_2$ and $\ell_3$ are in general position, we may write them as
\begin{equation}\label{eq:gp}
\begin{gathered}
\ell_2 = \braket{e_1 + \alpha_3 e_3 + \alpha_4 e_4, e_2 + \beta_3 e_3 + \beta_4 e_4},\\
\ell_3 = \braket{e_1 + \gamma_3 e_3 + \gamma_4 e_4, e_2 + \delta_3 e_3 + \delta_4 e_4},
\end{gathered}
\end{equation}
for a unique choice of variables. Then check directly that under these conditions, in general position, there exist exactly two lines in $\PP^3$ that meet all of them.
\end{enumerate}
\end{ex}

\begin{sol}
\leavevmode
\begin{enumerate}
\item Suppose that $\ell_0 = \braket{v_0,v_1}$, so that $\omega_0$ may be chosen, for example, as $v_0 \wedge v_1$. Let $\omega = v \wedge w$ represent the line passing through $\braket{v}$ and $\braket{w}$. Then, we claim that $\omega \wedge \omega_0 = 0$ iff $\braket{v,w} \cap \braket{v_0, v_1} \neq 0$.

The implication $\leftarrow$ is obvious; in this scenario, we may replace either $v$ or $w$ with a linear combination of $v_0$ and $v_1$, so the wedge is obviously zero.

Now, we turn to proving $\rightarrow$. Indeed, if $\braket{v,w} \cap \braket{v_0,v_1} = 0$ then the vectors $v,w,v_0,v_1$ are linearly independent. Thus, the wedge of the four of them is nonzero, which is precisely saying that $\omega \wedge \omega_0 \neq 0$.

\smallskip

In coordinates, this condition looks as follows. Extend $v_0,v_1$ to a basis $v_0, \dots, v_3$ of $\kk^4$. Then, write $\omega = \sum_{0 \leq i < j \leq 3} a_{ij} \, v_i \wedge v_j$, with $a_{12} a_{34} - a_{13} a_{24} + a_{14} a_{23} = 0$. Then, the condition that $\omega \wedge \omega_0 = 0$ is written in coordinates as saying that $a_{34} = 0$, which determines a hyperplane section.
	
\item As in the statement, we assume that $\ell_0$ and $\ell_1$ are as given. This happens in general position, as it may be done whenever $\ell_0$ and $\ell_1$ do not intersect, which as per the previous item is an algebraic condition, hence a Zariski closed subset, which is proper (because, well, there are nonintersecting lines. Such as the ones given.)

Now, we show that any line $\ell$ in general position may be written as in \eqref{eq:gp}. A little more precisely, we show that the condition that it may \emph{not} be written in such a way is algebraic in $\omega_0$ and $\omega_1$ (the representatives of $\ell_0$ and $\ell_1$).

We claim that a line $\ell$ represented by $\omega = v \wedge w$ may be written in this manner iff it does not intersect $\ell_1$, and thus whenever $\omega \wedge \omega_1 \neq 0$. The implication $\leftarrow$ is as follows: if $\ell$ intersects $\ell_1$, its projection on $\ell_0$ via $\ell_1$ is a one-dimensional subspace of $\ell_0$ and thus cannot contain $e_1$ and $e_2$ at once. The implication $\rightarrow$ is similar: if $\ell$ may be written in this way, its projection onto $\ell_0$ via $\ell_1$ is the whole space, which by a dimensional argument implies that $\ell \cap \ell_1 = 0$.

Thus, in general, $\ell_2$ and $\ell_3$ may be written as in \eqref{eq:gp}. Under these conditions, there exist exactly two lines in $\PP^3$ that meet all four of them, and here is why.

Consider a line $\ell$ which does meet all of them. Then, its intersection with $\ell_0$ and $\ell_1$ must have exactly one point, as if $\ell$ met either at two or more points, it would coincide with it, and not intersect the other. Thus, we may chracterize $\ell$ uniquely as a line of the form
\begin{equation}
\ell = \braket{t e_0 + t' e_1, s e_2 + s' e_3}.
\end{equation}

Now, this line intersects $\ell_2$ if and only if (using (a))
\begin{equation}
\begin{gathered}
t e_0 + t' e_1 \wedge s e_2 + s' e_3 \wedge e_1 + \alpha_3 e_3 + \alpha_4 e_4 \wedge e_2 + \beta_3 e_3 + \beta_4 e_4 = 0,\\
\text{that is, iff }
\left|
\begin{matrix}
t  & 0 & 1 & 0 \\
t' & 0 & 0 & 1 \\
0 & s  & \alpha_0 & \beta_0 \\
0 & s' & \alpha_1 & \beta_1
\end{matrix}
\right| = 0,\\
\text{iff } t s \alpha_1 - t s' \alpha_0 + t' s \beta_1 - t' s' \beta_0 = 0.
\end{gathered}
\end{equation}

Likewise, the condition of intersecting $\ell_3$ yields a similar equation, with $\gamma$ and $\delta$ for $\alpha$ and $\beta$. Thus, it suffices to show that in general there exist exactly two solutions $([t:t'],[s:s'])$ to the resulting equations.

First, we remark that, in general, no solutions exist with $t' = 0$ or $s' = 0$. For example, if there was a solution with $t' = 0$, then (since $t \neq 0$ we would have
\begin{equation}
\begin{cases}
s \alpha_1 - s' \alpha_0,\\
s \gamma_1 - s' \gamma_0.
\end{cases}
\end{equation}

Thus, the nonzero vector $(s,-s')$ is at once orthogonal to $(\alpha_1, \alpha_0)$ and $(\gamma_1,\gamma_0)$, which can only happen if the latter two are linearly dependent. This is an algebraic condition (use the determinant), so does not happen in general. Thus, in general position, all our solutions are of the form $([t:1],[s,1])$.

We may also suppose, in general position, that $\alpha_1 \neq 0$, and moreover that any solution satisfies $s \alpha_1 - \alpha_0 \neq 0$. Indeed, if there is a solution satisfying this, we have that
\begin{equation}
s \beta_1 - \beta_0 = t(s \alpha_1 - \alpha_0) = 0,
\end{equation}
hence $\beta_1 \alpha_0 - \alpha_1 \beta_0 = 0$, which is an algebraic condition and thus false in general. Thus, in general position, we may find the solution by writing
\begin{equation}\label{eq:ts}
t = \frac{s \beta_1 - \beta_0}{s \alpha_1 - \alpha_0}
\end{equation}
and then plugging in this value of $t$ into $t s \gamma_1 - t \gamma_0 + s \delta_1 - \delta_0 = 0$, which yields upon simplification a second-degree equation on $s$. If this equation has exactly two solutions, then this means that there exactly two lines crossing all our four lines, as \eqref{eq:ts} determines $t$ from $s$. Now, in general, a quadratic will indeed have exactly two solutions, as the requirements for the equation $a s^2 + b s + c = 0$ to have two solutions are: i) $a \neq 0$ (an algebraic condition, hence general), and ii) the discriminant is nonzero (also algebraic).

This basically completes the proof. There is just one minor detail that I've been glossing over: I've proven that there exists an open set in the variety of ``four lines in $\PP^3$'' on which the given proposition holds. I still need to show that this open set is nonempty. To do so, I would find a collection of four lines such that there exist exactly two lines going through all of them. I'm not actually going to bother doing that, but it would boil down to showing that there exist values of $\alpha_0, \dots, \delta_1$ such that all the algebraic conditions posed above hold. This would then complete the solution.
\end{enumerate}
\end{sol}

\begin{ex}
Show that any irreducible quadric hypersurface in $\PP^n$ has an open subset which is isomorphic to $\PP^{n-1}$.
\end{ex}

\begin{sol}
As in the e-mail sent on Canvas, we assume without loss of generality that our quadric hypersurface is given by $X_0^2 + \dots + X_n^2 = 0$. Now, also by a change of basis, setting $Y_0 = X_0 + \I X_1$ and $Y_1 = X_0 - \I X_1$, we may instead assume that it is given by
\begin{equation}
Y_0 Y_1 + X_2^2 + \dots + X_n^2 = 0.
\end{equation}

(This is assuming $n \geq 1$.)

Now, under these coordinates, we consider the subset of $Q$ where $Y_0 \neq 0$. We claim that this set, say $Q'$, is isomorphic to a copy of $\PP^{n-1}$.

We build the isomorphism in coordinates by
\begin{equation}
\begin{aligned}
Q' &\to \PP^{n-1}\\
[Y_0:Y_1:X_2:\dots:X_n] &\mapsto [Y_1:X_2:\dots:X_n]\\
[- {\textstyle \sum} X_k^2 : Y_1^2 : X_2 Y_1 : \dots : X_n Y_1] &\mapsfrom
\end{aligned}
\end{equation}

It is evident that these two maps are inverses and both are regular, so we have the desired isomorphism.
\end{sol}

\end{document}