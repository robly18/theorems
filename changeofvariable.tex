\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsthm}

\title{\textbf{Change of variable in Lebesgue integrals}}
\author{}
\date{}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\theoremstyle{plain}
\newtheorem{prop}{Proposition}
\newtheorem*{conj}{Conjecture}

\newcommand{\R}{\mathbf{R}}
\newcommand{\mo}{^{-1}}

\makeatletter \renewcommand\d[1]{\ensuremath{%
  \;\mathrm{d}#1\@ifnextchar\d{\!}{}}}
\makeatother

\begin{document}

\maketitle

\section{Preliminary definitions}

\begin{definition}
If $g$ is differenciable at $x$, $J_g(x)$ denotes $\det g'(x)$.
\end{definition}

\section{Preliminary results}

Before this result, some preliminary results, which I will no doubt prove someday, but for now just take it without evidence, yeah?

\begin{prop}\label{measurezeroc1}
The image under a $C^1$ function of a set of measure zero has measure zero.
\end{prop}

\begin{prop}\label{compactunion}
Any open set can be written as a countable union of almost-disjoint compact intervals.
\end{prop}

\begin{proof}
Enumerate rationals etc etc.
\end{proof}

\begin{prop}
If $X$ is a measurable set, there exists a sequence of characteristic functions (stair functions that only take the values 1 and 0) converging to $\chi_X$ almost everywhere.
\end{prop}

\begin{prop}
If $X$ is a measurable set contained in open $T$, there exists a sequence of characteristic functions converging to $\chi_X$ almost everywhere, whose support is contained in $T$.
\end{prop}

\begin{proof}
Consider $\chi_n \rightarrow \chi_X$, $T_1, T_2, \ldots$ a succession of limited open intervals whose union is almost $T$ (Consider the sequence of prop \ref{compactunion}, and take the interior of these), $\chi'_n$ the characteristic function of $T_1 \cup \ldots \cup T_n$. The function we want is $\min\{\chi_n, \chi'_n\}$.
\end{proof}

\begin{prop}
Given an open cover of a set, there exists a countable subcover.
\end{prop}

\section{The main proof}

\begin{definition}
Let $T$ be an open subset of $\R^n$. We say \emph{$g$ is a coordinate change on $T$} if $g \in C^1(T \rightarrow \R^n)$, $g$ is injective, and $J_g(x)$ is never zero.
\end{definition}

Here is our main result, which we intend to prove.

\begin{conj}
Let $X$ be a subset of $g(T)$, which is an open subset of $R^n$. Suppose $g$ is a coordinate change on $T$, and let $f \in L(X)$. Then, ${f \circ g \cdot \lvert J_g \rvert \in L(g\mo(X))}$ and

\[ \int_{X} f =  \int_{g\mo(X)} f \circ g \cdot \lvert J_g \rvert \]
\end{conj}

The proof will be done inductively on $n$. However, to make it a bit more tractable, it will be done in two different steps:

First, it is proven that, if it is true (for a given $n$) for the constant function 1 on compact intervals, then it is true in general. This makes sense, as, this also proves it for any constant function, and from there one can show the result for stair functions ($S$) and then pass to the limit to get $U$ and $L$.

Then, done that, it is shown that if the (general) result is true for $n-1$, it is true for $n$. The base case can be done by applying the previous proposition to the constant 1 function in intervals in $\R$. It is true for these functions as shown in Calculus 1.

\subsection{Constant to general}

\begin{prop}
If the change of variable formula is true for the constant function 1 in compact intervals in $g(T)$, it is true for any Lebesgue-integrable function on any compact interval.
\end{prop}

\begin{proof}
Let $X$ be the compact interval in question.

First, suppose $s \in S(X)$. Since $s$ is a stair function, there exists a partition $P$ of $X$ such that, in all compact $R$ in $P$, $s$ is a constant function almost everywhere. We denote this constant by $s_R$.

Now, notice that, by definition,

\[\int_X s = \sum_{R \in P} \int_R s = \sum_{R \in P} s_R \int_R 1 \]

On the other hand, by hypothesis, since the $R$ are compact, this equals

\[\sum_{R \in P} s_R \int_{g\mo(R)} \lvert J_g \rvert \]

Which is, in turn, equal to

\[\sum_{R \in P} \int_{g\mo(R)} s \circ g \cdot \lvert J_g \rvert \]

Finally, note the following: If two sets' intersection has null measure, the sum of the integrals over them is the same as the integral over their union.

Furthermore, any two $R$ intersect at a set of measure zero, and the intersection  $g\mo(R_1) \cap g\mo(R_2)$ is the same as $g\mo(R_1 \cap R_2)$. Finally, by proposition \ref{measurezeroc1}, this thing has measure zero.

What this shows is that summing the integrals over the preimages of the rectangles is the same as integrating over the preimage of their union, which in turn is the preimage of $X$. Thus, what we have shown is that

\[\int_X s = \int_{g\mo(X)} s \circ g \cdot \lvert J_g \rvert\]

for $s \in S(X)$.

\noindent\rule{\textwidth}{1pt}

Now, let $u \in U(X)$. Then, there exists $s_k \in S$ such that $s_k \nearrow u$ almost everywhere.

Notice that $\int_X s_k = \int_{g\mo(X)} s_k \circ g \cdot \lvert J_g \rvert$, and since the succession on the left hand side is bounded, the one on the right hand side is as well. Furthermore, the succession $s_k \circ g \cdot \lvert J_g \rvert$ is also crescent, and so, by the theorem of monotonous convergence, it converges almost everywhere (to $u \circ g \cdot \lvert J_g \rvert$) and the integral of this last function equals precisely $\int_X u$.

Finally, notice that any lebesgue integrable function is the difference of two functions in $U(X)$, and apply the formula to both of these, as well as the additivity of the integral.

\end{proof}

We have just proven this formula for compact intervals. We now make the extension to open sets, and finally, for any subset of $T$.

\begin{prop}
If the change of variable formula is true for the constant function 1 in compact intervals in $g(T)$, it is true for any Lebesgue-integrable function on any measurable subset of $g(T)$.
\end{prop}

\begin{proof}
We have already shown it, under this hypothesis, to be true for any lebesgue-integrable function over any compact subinterval of $g(T)$.

Now, let $X$ be an open subset of $g(T)$, and $f$ an integrable function defined on $X$.

Let $X_1, X_2, \ldots$ be a succession of almost-disjoint compact intervals whose union is $X$. (See proposition \ref{compactunion})

\[\int_{X} f = \sum_i \int_{X_i} f = \sum_i \int_{g\mo(X_i)} f \circ g \cdot \lvert J_g \rvert\]

Since $g\mo$ is injective and the $X_i$ are almost-disjoint, this equals

\[\int_{g\mo(X)} f \circ g \cdot \lvert J_g \rvert\]

as desired.

\noindent\rule{\textwidth}{1pt}

We are now ready to extend the result to all sets.

Let $X \subseteq g(T)$, and $f \in L(X)$. Extend $f$ to 0 outside of $X$.

Then, by definition, $\int_X f = \int \chi_X \cdot f$. In particular, since $X$ is contained in $g(T)$, this equals $\int_{g(T)} \chi_X \cdot f$. Since $g(T)$ is an open subset of $g(T)$, the change of variable formula applies, and we get this equals $\int_{T} \chi_X(g(t)) f(g(t)) \lvert J_g(t) \rvert \d{t}$.

Finally, notice the condition that $t \in T$ and $g(t) \in X$ is the same as $t \in g\mo(X)$, which shows precisely what we wanted:

\[ \int_X f = \int_{g\mo(X)} f \circ g \cdot \lvert J_g(t) \rvert \]
\end{proof}

\subsection{Induction step}

We are almost ready to prove the induction step, but there is a minor hurdle to overcome.

Here's the idea: we will split the change of variables into two separate variable changes, each with the following property: only $n-1$ variables are changed, in a sense. %todo word this better

More specifically, we will say a change of variables $g$ is \emph{inductible} if there exist $i$, $j$ such that $g_i(x) = x_j$.

\begin{prop}
If $g$ is inductible and the change of variables formula is valid for $n-1$ dimensions, then it's valid for $g$ on the constant 1 function over open sets.
\end{prop}

\begin{proof}
Suppose $g$ is an inductible coordinate transformation on $T$, $X$ an open subset of $g(T)$.

Let $i, j$ be such that $g_i(x) = x_j$.

Define $\gamma_{x_j}(x_{\hat\jmath}) = g_{\hat\imath}(x)$, with $x_j$ still fixed.

TO SHOW: $\gamma_{x_j}$ is a coordinate transformation.

We can now apply the following trickery:

By Fubini:

\[\int_X \d x = \int_{g(T)} \chi_X(x) \d x = \int \int_{g(T)_{x_j}} \chi_{X_{x_j}}(x_{\hat\jmath}) \d{x_{\hat\jmath}} \d{x_j}\]

Where, given a set $S$, $S_{x_j}$ is the set of $x_{\hat\jmath}$ such that $x \in S$.

By the induction hypothesis on the inner integral, this equals

\[ \int \int_{\gamma_{x_j}\mo(g(T)_{x_j})} \chi_{X_{x_j}}(\gamma_{x_j}(x_{\hat\jmath})) \cdot \lvert J_{\gamma_{x_j}}(x_{\hat\jmath}) \rvert \d{x_{\hat\jmath}} \d{x_j} \]

The reader may, with a little work, verify that this is the same as

\[ \int \int \chi_{\gamma_{x_j}\mo(X_{x_j})}(x_{\hat\jmath}) \cdot \lvert J_g(x) \rvert \d{x_{\hat\jmath}} \d{x_j}  \]

At this point, the reader may notice, we have an iterated integral. The iterated integral of the modulus exists (since everything is nonnegative, the things inside the integral are their own modulus) and the function inside the integral is mensurable (the product of two mensurables is mensurable; characteristic functions of open sets are mensurable; continuous functions are mensurable). As such, we are in the conditions of Tonelli's theorem, and as such, we may pronounce this equal to

\[ \int \chi_{\gamma_{x_j}\mo(X_{x_j})}(x_{\hat\jmath}) \lvert J_g(x) \rvert \d{x} \]

Finally, one can easily notice that $x_{\hat\jmath} \in \gamma_{x_j}\mo(X_{x_j})$ if and only if ${x \in g\mo(X)}$. This concludes our demonstration, as our integral now equals

\[ \int_{g\mo(X)} \lvert J_g(x) \rvert \d{x} \]
\end{proof}

Finally, the proof is within reach.

\begin{prop}
Suppose the variable change formula works for $n-1$. Then, it also works for $n$.
\end{prop}

\begin{proof}
We will show this works for $n$ solely for the constant function equal to 1 on a compact interval $I$ contained in $g\mo(T)$. The previous subsection shows this is enough to guarantee full generality in $\R^n$.

This demonstration will work by splitting $g$ into a composition of two coordinate transformations, both inductible. Unfortunately, the existance of this decomposition is only guaranteed locally, so we will have to do this on a local basis and later on stitch it all together.

Fix some $t_0$ in $T$. By hypothesis, $J_g(t_0) \neq 0$, and as such, there exists $i$ such that $\partial_i g_n(t_0) \neq 0$.

Define $\phi(t) = (t_1, \ldots, t_{n-1}, g_i(t))$. The jacobian of $\phi$ is clearly not zero at $t_0$, and by continuity, is also not 0 in a neighbourhood of it. By the inverse function theorem, $\phi$ is locally invertible at $t_0$.

With this in mind, define $X$ to be an open subset $T$ satisfying these two conditions. We have $\phi$ is a coordinate transformation bijecting $X \rightarrow \phi(X)$.

Now, in $\phi(X)$, define $\theta = g \circ \phi\mo$. This is clearly a coordinate transformation bijecting $\phi(X) \rightarrow g(X)$, and it is not too hard to see that $\theta_i(t) = t_n$. %todo justify

Both $\theta$ and $\phi$ are inductible, and none of the following is ever negative, and so, as such, we can apply the previous lemma twice here to get that, for any open set $S$ contained in $X$,

\begin{align*}
\int_S \d x =& \int_{\theta\mo(S)} \rvert J_{\theta} \lvert x \d x \\
=& \int_{\phi\mo(\theta\mo(S))} \rvert J_{\theta}(\phi(x)) \lvert \cdot \rvert J_\phi(x) \lvert \d x \\
=& \int_{g\mo(S)} \rvert J_g(x) \lvert \d x
\end{align*}

We will use this local version of the theorem to begin stitching.

Consider that for all $x \in I$, by what we have just shown, there exists a neighbourhood $X$ of $x$ where, for any open $S$,

\[ \int_X \chi_S(x) \d x = \int_{g\mo(X)} \chi_S(g(x)) \rvert J_g(x) \lvert \d x \]
%todo ponder over this

What we wish to show is that $\int_I \d x = \int_{g\mo(I)} \rvert J_g(x) \lvert \d x$. It would be convenient that our $I$ were to be an open set, so that we could apply what we already have to $\chi_I$. It is also useful that it is compact, however, to allow us to stitch it in finitely many pieces. This is less than a problem than it would seem, as the border of $I$ has null measure. As such, let $J = \textrm{int} I$. We will show $\int_J \d x = \int_{g\mo(J)} \rvert J_g(x) \lvert \d x$.

All the $X$s we were talking about earlier make an open cover of $I$. As such, there is a finite subcover, $X_1, \ldots, X_N$, of $I$ (and thus, $J$) of sets where our hypothesis applies. Let $L_i = X_1 \cup \ldots X_i$ for $i = 1, \ldots, N$.

What we will show by induction is that for any open set $S$, the variable change formula works on $L_i \cap S$.

The case $i = 1$ is already shown. Suppose we have shown the case $i$ and wish to show $i+1$.

Notice that

\[\int_{L_{i+1} \cap S} \d x = \int_{L_i \cap S} \d x + \int_{X_{i+1} \cap S} \d x  - \int_{L_i \cap (X_{i+1} \cap S)} \d x\]

All of these integrals exist. The first and last by the induction hypothesis, and the second by the hypothesis on the $X_i$.

One can now apply the variable change formula on all the integrals on the right hand side, and join them together to get

\[ \int \chi_{g\mo(L_i \cap S)}(x) + \chi_{g\mo(X_{i+1} \cap S)}(x) - \chi_{g\mo(L_i \cap X_{i+1}\cap S)}(x) \d x \]

With a little work, one can verify that
\[\chi_{g\mo(L_i \cap S)} + \chi_{g\mo(X_{i+1} \cap S)} - \chi_{g\mo(L_i \cap X_{i+1}\cap S)} = \chi_{g\mo(L_{i+1})} \cdot \chi_{g\mo(S)}\]

So, $\int_{L_i} \chi_S = \int_{g\mo(L_i)} \chi_{g\mo(S)} \cdot \lvert J_g \rvert$ for all $i$, and in particular, for $i = N$ and letting $S = J$,

\[ \int_{L_N} \chi_J = \int_{g\mo(L_N)} \chi_{g\mo(J)} \cdot \lvert J_g \rvert \]

Since $J$ is wholly contained in $L_N$, this is equivalent to

\[ \int_J \d x = \int_{g\mo(J)} \lvert J_g(x) \rvert \d x \]

Which concludes our proof.

\end{proof}

\end{document}
