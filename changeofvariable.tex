\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsthm}

\title{\textbf{Change of variable in Lebesgue integrals}}
\author{}
\date{}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\theoremstyle{plain}
\newtheorem{prop}{Proposition}
\newtheorem*{conj}{Conjecture}

\newcommand{\R}{\mathbf{R}}
\newcommand{\mo}{^{-1}}

\makeatletter \renewcommand\d[1]{\ensuremath{%
  \;\mathrm{d}#1\@ifnextchar\d{\!}{}}}
\makeatother

\begin{document}

\maketitle

\section{Preliminary definitions}

\begin{definition}
If $g$ is differenciable at $x$, $J_g(x)$ denotes $\det g'(x)$.
\end{definition}

\section{Preliminary results}

Before this result, some preliminary results, which I will no doubt prove someday, but for now just take it without evidence, yeah?

\begin{prop}\label{measurezeroc1}
The image under a $C^1$ function of a set of measure zero has measure zero.
\end{prop}

\begin{prop}\label{compactunion}
Any open set can be written as a countable union of almost-disjoint compact intervals.
\end{prop}

\begin{proof}
Enumerate rationals etc etc.
\end{proof}

\begin{prop}
If $X$ is a measurable set, there exists a sequence of characteristic functions (stair functions that only take the values 1 and 0) converging to $\chi_X$ almost everywhere.
\end{prop}

\begin{prop}
If $X$ is a measurable set contained in open $T$, there exists a sequence of characteristic functions converging to $\chi_X$ almost everywhere, whose support is contained in $T$.
\end{prop}

\begin{proof}
Consider $\chi_n \rightarrow \chi_X$, $T_1, T_2, \ldots$ a succession of limited open intervals whose union is almost $T$ (Consider the sequence of prop \ref{compactunion}, and take the interior of these), $\chi'_n$ the characteristic function of $T_1 \cup \ldots \cup T_n$. The function we want is $\min\{\chi_n, \chi'_n\}$.
\end{proof}

\begin{prop}
Given an open cover of a set, there exists a countable subcover.
\end{prop}

\section{The main proof}

\begin{definition}
Let $T$ be an open subset of $\R^n$. We say \emph{$g$ is a coordinate change on $T$} if $g \in C^1(T \rightarrow \R^n)$, $g$ is injective, and $J_g(x)$ is never zero.
\end{definition}

Here is our main result, which we intend to prove.

\begin{conj}
Let $X$ be a subset of $g(T)$, which is an open subset of $R^n$. Suppose $g$ is a coordinate change on $T$, and let $f \in L(X)$. Then, ${f \circ g \cdot \lvert J_g \rvert \in L(g\mo(X))}$ and

\[ \int_{X} f =  \int_{g\mo(X)} f \circ g \cdot \lvert J_g \rvert \]
\end{conj}

The proof will be done inductively on $n$. However, to make it a bit more tractable, it will be done in two different steps:

First, it is proven that, if it is true (for a given $n$) for the constant function 1 on compact intervals, then it is true in general. This makes sense, as, this also proves it for any constant function, and from there one can show the result for stair functions ($S$) and then pass to the limit to get $U$ and $L$.

Then, done that, it is shown that if the (general) result is true for $n-1$, it is true for $n$. The base case can be done by applying the previous proposition to the constant 1 function in intervals in $\R$. It is true for these functions as shown in Calculus 1.

\subsection{Constant to general}

\begin{prop}
If the change of variable formula is true for the constant function 1 in compact intervals in $g(T)$, it is true for any Lebesgue-integrable function on any compact interval.
\end{prop}

\begin{proof}
Let $X$ be the compact interval in question.

First, suppose $s \in S(X)$. Since $s$ is a stair function, there exists a partition $P$ of $X$ such that, in all compact $R$ in $P$, $s$ is a constant function almost everywhere. We denote this constant by $s_R$.

Now, notice that, by definition,

\[\int_X s = \sum_{R \in P} \int_R s = \sum_{R \in P} s_R \int_R 1 \]

On the other hand, by hypothesis, since the $R$ are compact, this equals

\[\sum_{R \in P} s_R \int_{g\mo(R)} \lvert J_g \rvert \]

Which is, in turn, equal to

\[\sum_{R \in P} \int_{g\mo(R)} s \circ g \cdot \lvert J_g \rvert \]

Finally, note the following: If two sets' intersection has null measure, the sum of the integrals over them is the same as the integral over their union.

Furthermore, any two $R$ intersect at a set of measure zero, and the intersection  $g\mo(R_1) \cap g\mo(R_2)$ is the same as $g\mo(R_1 \cap R_2)$. Finally, by proposition \ref{measurezeroc1}, this thing has measure zero.

What this shows is that summing the integrals over the preimages of the rectangles is the same as integrating over the preimage of their union, which in turn is the preimage of $X$. Thus, what we have shown is that

\[\int_X s = \int_{g\mo(X)} s \circ g \cdot \lvert J_g \rvert\]

for $s \in S(X)$.

\noindent\rule{\textwidth}{1pt}

Now, let $u \in U(X)$. Then, there exists $s_k \in S$ such that $s_k \nearrow u$ almost everywhere.

Notice that $\int_X s_k = \int_{g\mo(X)} s_k \circ g \cdot \lvert J_g \rvert$, and since the succession on the left hand side is bounded, the one on the right hand side is as well. Furthermore, the succession $s_k \circ g \cdot \lvert J_g \rvert$ is also crescent, and so, by the theorem of monotonous convergence, it converges almost everywhere (to $u \circ g \cdot \lvert J_g \rvert$) and the integral of this last function equals precisely $\int_X u$.

Finally, notice that any lebesgue integrable function is the difference of two functions in $U(X)$, and apply the formula to both of these, as well as the additivity of the integral.

\end{proof}

We have just proven this formula for compact intervals. We now make the extension to open sets, and finally, for any subset of $T$.

\begin{prop}
If the change of variable formula is true for the constant function 1 in compact intervals in $g(T)$, it is true for any Lebesgue-integrable function on any measurable subset of $g(T)$.
\end{prop}

\begin{proof}
We have already shown it, under this hypothesis, to be true on any compact subinterval of $g(T)$.

Now, let $X$ be an open subset of $g(T)$, and $f$ an integrable function defined on $X$.

Let $X_1, X_2, \ldots$ be a succession of almost-disjoint compact intervals whose union is $X$. (See proposition \ref{compactunion})

\[\int_{X} f = \sum_i \int_{X_i} f = \sum_i \int_{g\mo(X_i)} f \circ g \cdot \lvert J_g \rvert\]

Since $g\mo$ is injective and the $X_i$ are almost-disjoint, this equals

\[\int_{g\mo(X)} f \circ g \cdot \lvert J_g \rvert\]

as desired.

\noindent\rule{\textwidth}{1pt}

We are now ready to extend the result to all sets.

Let $X \subseteq g(T)$, and $f \in L(X)$. Extend $f$ to 0 outside of $X$.

Then, by definition, $\int_X f = \int \chi_X \cdot f$. In particular, since $X$ is contained in $g(T)$, this equals $\int_{g(T)} \chi_X \cdot f$. Since $g(T)$ is an open subset of $g(T)$, the change of variable formula applies, and we get this equals $\int_{T} \chi_X(g(t)) f(g(t)) \lvert J_g(t) \rvert \d{t}$.

Finally, notice the condition that $t \in T$ and $g(t) \in X$ is the same as $t \in g\mo(X)$, which shows precisely what we wanted:

\[ \int_X f = \int_{g\mo(X)} f \circ g \cdot \lvert J_g(t) \rvert \]
\end{proof}

\subsection{Induction step}

We are almost ready to prove the induction step, but there is a minor hurdle to overcome.

Here's the idea: we will split the change of variables into two separate variable changes, each with the following property: only $n-1$ variables are changed, in a sense. %todo word this better

More specifically, we will say a change of variables $g$ is \emph{inductible} if there exist $i$, $j$ such that $g_i(x) = x_j$.

\begin{prop}
If $g$ is inductible and the change of variables formula is valid for $n-1$ dimensions, then it's valid for $g$ on functions that never take negative values.
\end{prop}

\begin{proof}
Suppose $g$ is an inductible coordinate transformation on $T$, $X \subseteq T$, $f \in L(X)$.

Let $i, j$ be such that $g_i(x) = x_j$.

By Fubini's theorem, since $f \in L(X)$, we have that, for almost all $x_j$, the function $\varphi_{x_j}$ defined as $\varphi_{x_j}(x_{\hat\jmath}) = f(x)$ is Lebesgue-integrable (if extended to zero to outside of its domain). Since this is a function of $n-1$ variables, we can apply the induction hypothesis on it.

Define $\gamma_{x_j}(x_{\hat\jmath}) = g_{\hat\imath}(x)$, with $x_j$ still fixed.

TO SHOW: $\gamma_{x_j}$ is a coordinate transformation.

We can now apply the following trickery:

By Fubini:

\[\int_X f = \int \int_{X_{x_j}} \varphi_{x_j}(x_{\hat\jmath}) \d{x_{\hat\jmath}} \d{x_j}\]

By the induction hypothesis on the inner integral, this equals

\[ \int \int_{\gamma_{x_j}\mo(X_{x_j})} \varphi_{x_j}(\gamma_{x_j}(x_{\hat\jmath})) \lvert J_{\gamma_{x_j}}(x_{\hat\jmath}) \rvert \d{x_{\hat\jmath}} \d{x_j} \]

Clearing up notation, and making use of our abbreviations:

\[ \int \int_{\gamma_{x_j}\mo(X_{x_j})} \varphi_{g_i(x)}(g_{\hat\imath}(x)) \lvert J_{\gamma_{x_j}}(x_{\hat\jmath}) \rvert \d{x_{\hat\jmath}} \d{x_j} \]

Also, doing trickery on the jacobian of $\gamma_{x_j}$

\[ \int \int_{\gamma_{x_j}\mo(X_{x_j})} f(g(x)) \lvert J_g(x) \rvert \d{x_{\hat\jmath}} \d{x_j} \]

We wish to apply Tonelli, but the domain of the inner integral depends on the outer one. As such, we write this using the characteristic function.

\[ \int \int \chi_{\gamma_{x_j}\mo(X_{x_j})}(x_{\hat\jmath}) f(g(x)) \lvert J_g(x) \rvert \d{x_{\hat\jmath}} \d{x_j} \]

It is at this point that we consider the hypothesis that $f$ is never negative. Since the things inside the integral are never negative, we can apply Tonelli's theorem to get that, since the iterated integral exists, so does the full one, to get

\[ \int \chi_{\gamma_{x_j}\mo(X_{x_j})}(x_{\hat\jmath}) f(g(x)) \lvert J_g(x) \rvert \d{x} \]

Finally, notice that $x_{\hat\jmath} \in \gamma_{x_j}\mo(X_{x_j})$ if and only if $\gamma_{x_j}(x_{\hat\jmath}) \in X_{g_i(x)}$ if and only if $g_{\hat\imath}(x) \in X_{g_i(x)}$ if and only if $g(x) \in X$ if and only if $x \in g\mo(X)$. This concludes our demonstration, as our integral now equals

\[ \int_{g\mo(X)} f(g(x)) \lvert J_g(x) \rvert \d{x} \]
\end{proof}

Finally, the proof is within reach.

\begin{prop}
Suppose the variable change formula works for $n-1$. Then, it also works for $n$.
\end{prop}

\begin{proof}
We will show this works for $n$ solely for the constant function equal to 1 on a compact interval $I$ contained in $g\mo(T)$. The previous subsection shows this is enough to guarantee full generality in $\R^n$.

This demonstration will work by splitting $g$ into a composition of two coordinate transformations, both inductible. Unfortunately, the existance of this decomposition is only guaranteed locally, so we will have to do this on a local basis and later on stitch it all together.

Fix some $t_0$ in $T$. By hypothesis, $J_g(t_0) \neq 0$, and as such, there exists $i$ such that $\partial_i g_n(t_0) \neq 0$.

Define $\phi(t) = (t_1, \ldots, t_{n-1}, g_i(t))$. The jacobian of $\phi$ is clearly not zero at $t_0$, and by continuity, is also not 0 in a neighbourhood of it. By the inverse function theorem, $\phi$ is locally invertible at $t_0$.

With this in mind, define $X$ to be an open subset $T$ satisfying these two conditions. We have $\phi$ is a coordinate transformation bijecting $X \rightarrow \phi(X)$.

Now, in $\phi(X)$, define $\theta = g \circ \phi\mo$. This is clearly a coordinate transformation bijecting $\phi(X) \rightarrow g(X)$, and it is not too hard to see that $\theta_i(t) = t_n$. %todo justify

Both $\theta$ and $\phi$ are inductible, and none of the following is ever negative, and so, as such, we can apply the previous lemma twice here to get

\begin{align*}
\int_X \chi_I(x) \d x =& \int_{\theta\mo(X)} \chi_I(\theta(x)) \rvert J_{\theta} \lvert x \d x \\
=& \int_{\phi\mo(\theta\mo(X))} \chi_I(\theta(\phi(x))) \rvert J_{\theta}(\phi(x)) \lvert \cdot \rvert J_\phi(x) \lvert \d x \\
=& \int_{g\mo(X)} \chi_I(g(x)) \rvert J_g(x) \lvert \d x
\end{align*}

As we wished. The local version is now proven. We can begin stitching.

Consider that for all $x \in I$, as we have just shown, there exists a neighbourhood $X$ of $x$ where

\[ \int_X \chi_I(x) \d x = \int_{g\mo(X)} \chi_I(g(x)) \rvert J_g(x) \lvert \d x \]

Notice that the only thing we have assumed so far about $\chi_I$ was that it was never negative. As such, if we take any other characteristic function, the formula will still apply. This allows us to stitch things the following way:

All our $X$s make an open cover of $I$. As such, there is a countable subcover, $X_1, X_2, \ldots$. Let $L_i = X_1 \cup \ldots X_i$.

What we will show by induction is that for any nonnegative function $\chi : T \rightarrow \R^n$ the variable change formula works on $L_i$.

The case $i = 1$ is already shown. Suppose we have shown the case $i$ and wish to show $i+1$.

Notice that if $f$ is a nonnegative function in $L(T)$, we have $\int_{L_{i+1}} f = \int_{L_i} f + \int_{X_{i+1}} f  - \int_{L_i \cap X_{i+1}} f$. All of these integrals exist. The first by the induction hypothesis, the second by what we have previously shown, and the last because it is equivalent to doing the integral over $L_i$ of $\chi_{X_{i+1}} \cdot f$.

As such, the integral over $L_{i+1}$ of $f$ exists, and it can easily be shown that it equals the integral over $g\mo(L_{i+1})$ of $f \circ g \cdot \lvert J_g \rvert$, which concludes our induction step.

So, $\int_{L_i} f = \int_{g\mo(L_i)} f \circ g \cdot \lvert J_g \rvert$ for all $i$, and taking the limit, since these are all positive functions and the sequence $L_i$ is increasing, we have, by monotonous convergence, where $L = \bigcup L_i$,

\[ \int_L f = \int_{g\mo(L)} f \circ g \cdot \lvert J_g \rvert \]

As we wished to show. Now, apply this result to $f = \chi_I$ and our demonstration is finally complete.

\end{proof}

\end{document}
