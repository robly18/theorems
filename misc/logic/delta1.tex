\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathtools}

\usepackage[thmmarks, amsmath]{ntheorem}

\usepackage{fullpage}
\usepackage{showlabels}

\usepackage{enumitem}

\setlist[enumerate,1]{label=\alph*)}

\title{The Characterization of Computation via Predicates\\
And Some Consequences}
\author{Duarte Maia}
%\date{}

\theorembodyfont{\upshape}
\theoremseparator{.}
\newtheorem{theorem}{Theorem}[subsection]
\newtheorem{prop}[theorem]{Proposition}
\renewtheorem*{prop*}{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\theoremsymbol{\ensuremath{\square}}
\newtheorem{prelimdef}[theorem]{Preliminary Definition}
\newtheorem{definition}[theorem]{Definition}

\theoremstyle{nonumberplain}
\theoremsymbol{}
\newtheorem{convention}{Convention}

\theoremheaderfont{\itshape}
\theorembodyfont{\upshape}
\theoremseparator{:}
\theoremsymbol{\ensuremath{\blacksquare}}
\newtheorem{proof}{Proof}

\theoremsymbol{\ensuremath{\square}}
\newtheorem{sketch}{Proof Sketch}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}

\newcommand{\CF}{\mathrm{CF}}
\newcommand{\Seq}{\mathrm{Seq}}

\newcommand{\LA}{L_A}
\newcommand{\PA}{\mathrm{PA}}
\newcommand{\WPA}{\PA^-}


\DeclareMathOperator{\step}{step}
\DeclareMathOperator{\tapefrominput}{tapefrominput}
\DeclareMathOperator{\tapetooutput}{tapetooutput}
\DeclareMathOperator{\halted}{halted}

\DeclareMathOperator{\Proves}{\mspace{-2mu}Proves}
\DeclareMathOperator{\ProofOf}{\mspace{-2mu}ProofOf}
\DeclareMathOperator{\Sat}{Sat}
\DeclareMathOperator{\eval}{eval}

\DeclareMathOperator{\Th}{Th}


\DeclareMathOperator{\len}{len}

\DeclarePairedDelimiter{\braket}{\langle}{\rangle}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

\newcommand{\gn}[1]{\setbox0=\hbox{$\mathclap{\phantom{t}}#1$} \dimen0=\ht0 \advance\dimen0 by -1.25ex \,\raise\dimen0\hbox{$\ulcorner$} \! \box0 \! \raise\dimen0\hbox{$\urcorner$}\,}
\newcommand{\gf}[1]{\raise-0.25ex\hbox{$\llcorner$}\! #1 \!\raise-0.25ex\hbox{$\lrcorner$}}

\newcommand{\ssgn}[1]{\ulcorner\!#1\!\urcorner}



\begin{document}
\maketitle

\tableofcontents

\section{Introduction}

In this document, I seek to write down the main results I have been looking into in the summer of 2023, and sketches of their proofs. This may or may not be suitable for readers other than myself.

\section{The Basic Systems}

In the remainder of this document, we will be working over the language denoted $\LA$, which consists of the symbols $0$, $1$, $+$, $\times$, and $\leq$. In this language, we introduce two axiomatic systems.

\subsection{Weak Peano Arithmetic}

\begin{definition}
The axiomatic system $\WPA$ is given by (the translation to FOL of) the following statements:
\begin{gather}
\begin{gathered}
\text{The operations $+$ and $\times$ are associative, commutative, and satisfy the distributive law,}\\
\text{for which $0$ and $1$ are the identities,}\\
\text{and moreover $(x+z = y+z) \rightarrow (x=y)$, and $(xz = yz \land z \neq 0) \rightarrow (x=y)$.}
\end{gathered} \tag{SRing}\label{ax:sring} \\
\begin{gathered}
\text{The binary relation $\leq$ is a total order, which is respected by the operations}\\
\text{(i.e. if $x \leq y$ then $x+z \leq y+z$ and $xz \leq yz$)}
\end{gathered} \tag{Ord}\label{ax:ord}\\
\text{$x \leq y$ iff $\exists_z (x+z = y)$,} \tag{Def$\leq$}\label{ax:defleq}\\
\forall_x x \geq 0 \tag{ZMin}\label{ax:zmin}\\
\forall_x (x \neq 0 \leftrightarrow x \geq 1). \tag{Disc}\label{ax:disc}
\end{gather}
\end{definition}

The main power of this definition is that it allows us to carry out concrete computations, in a sense that will be made precise in propositions \ref{prop:wpadelta0} and \ref{prop:wpasigma1}. Before then, however, we need some preliminary results.

\begin{remark}
The axioms above may or may not contain some redundancy. Moreover, we will scarcely need the full power of $\WPA$, and many authors work with far, far weaker systems. However, since we will mostly be interested in $\PA$ itself, and $\WPA$ will be mostly used to identify where induction may be foregone or weakened, we do not care too much about ensuring that it is as weak as possible.
\end{remark}

\begin{convention}
If the letter $n$ denotes a natural number, its presence in a formula should be replaced by a term in $\LA$ which evaluates to $n$. Note that, by \eqref{ax:sring}, $\WPA$ proves that any two such terms are equal.
\end{convention}

\begin{convention}
The symbol $x < y$ means the obvious: `$x \leq y$, but $x \neq y$'.
\end{convention}

\begin{prop}\label{prop:leq}
$\WPA$ proves that $x < y$ iff $x+1 \leq y$.
\end{prop}

\begin{proof}
We reason in $\WPA$. Suppose that $x < y$, i.e. $x \leq y$ but $x \neq y$. Then, by \eqref{ax:defleq} we have $y = x+z$ for some $z$. Moreover, since $x \neq y$, $z$ cannot be zero. Thus, by \eqref{ax:disc}, $z \geq 1$. Finally, applying the fact that (by \eqref{ax:ord}) the order is respected by addition, we have (in $\WPA$) $x+1 \leq x+z = y$.

Conversely, given that $x+1 \leq y$, and moreover $x \leq x+1$, it suffices to show that $x \neq y$. But indeed, suppose that $x = y$. Since $x+1 \leq y$, we have $y = x+1+z$ for some $z$. Thus, by \eqref{ax:sring} we have $z+1 = 0$. However, this is impossible: whenever $a+b = 0$, we have $0 \leq a \leq a+b = 0$, whence $a = 0$ by \eqref{ax:ord}, and so in particular from $z+1 = 0$ we get $1=0$. Yet, by \eqref{ax:disc}, $1 \neq 0$, a contradiction.
\end{proof}

\begin{prop}\label{prop:leqrep}
If $n$ is a natural number, we have
\begin{equation}
\WPA \vdash \forall_x (x \leq n \leftrightarrow [x = 0 \lor \dots \lor x = n]).
\end{equation}
\end{prop}

\begin{proof}
We reason by (meta-)induction on $n$. For $n = 0$, the statement is obvious. On the other hand, if the statement is true for a given $n \in \N$, we have, in $\WPA$,
\begin{equation}
x \leq n+1 \text{ iff } (x = n+1 \lor x < n+1),
\end{equation}
and by \eqref{prop:leq} $x < n+1$ iff $x+1 \leq n+1$. By \eqref{ax:defleq} and \eqref{ax:sring}, this is equivalent to $x \leq n$, and by the induction hypothesis this is equivalent to $[x=0 \lor \dots \lor x=n]$, which completes the proof.
\end{proof}

\begin{prop}\label{prop:wpadelta0}
$\WPA$ is complete for (closed) $\Delta_0$ sentences. In particular, if $\varphi$ is a closed $\Delta_0$ formula, $\WPA \vdash \varphi$ iff $\N \vDash \varphi$.
\end{prop}

\begin{proof}
First, we remark that, by proposition \ref{prop:leqrep}, $\WPA$ has `closed bounded quantifier elimination', in the following sense. If $\varphi$ is of the form $\forall_{x \leq t} \varphi_0(x)$, then $\WPA$ proves that $\varphi$ is equivalent to $\varphi_0(0) \lor \dots \lor \varphi_0(n)$, where $n$ is whatever natural number $t$ evaluates to. Thus, we may recursively eliminate all bounded quantifiers from a $\Delta_0$ sentence, obtaining at the end an equivalent quantifier-free sentence. Hence, it suffices to show that $\WPA$ is complete for atomic sentences. But indeed, an atomic sentence is either of the form $t_1 = t_2$ or $t_1 \leq t_2$, and these can be decided in $\WPA$ by evaluating the numerical value of $t_1$ and $t_2$.

(Details are being swept under the rug here, but the bottom line is that cancellation properties may be used to reduce to sentences of the form $t = 0$, $t \leq 0$, or $t \geq 0$, and $\WPA$ is able to prove that the first two hold iff $t$ evaluates numerically to zero, and the latter holds always.)

The second part of the proposition is a direct consequence of completeness for closed $\Delta_0$ formulas, together with the fact that $\N \vDash \WPA$.
\end{proof}

\begin{prop}\label{prop:wpasigma1}
$\WPA$ proves all true $\Sigma_1$ sentences. More specifically, if $\varphi \equiv \exists_x \varphi_0(x)$ is a closed $\Sigma_1$ formula, $\WPA \vdash \varphi$ iff $\N \vDash \varphi$.
\end{prop}

\begin{proof}
Evidently, if $\WPA \vdash \varphi$, we have $\N \vDash \varphi$, so we prove the opposite implication.

Suppose that $\N \vDash \varphi$. Then, there is some natural number $n$ such that $\N \vDash \varphi_0(n)$. Since $\varphi_0(n)$ is a $\Delta_0$ closed sentence, we conclude by proposition \ref{prop:wpadelta0} that $\WPA \vdash \varphi_0(n)$ and so $\WPA \vdash \exists_x \varphi_0(x)$.
\end{proof}

\subsection{Peano Arithmetic}

The system of axioms of $\PA$ is obtained by adding the axiom schema of induction to $\WPA$.

\subsection{Adding Function Symbols}

For the time being, I will keep this section short and free of proofs, because they are quite technical and not that interesting to write out. Perhaps someday I will do it, because there is one or another thing that is kind of interesting.

The bottom line is the following: Suppose that $T$ is a set of axioms in the language $L$ and $\varphi(\vec x,y)$ is a formula such that $T$ proves $\forall_{\vec x} \exists^1_y \varphi(\vec x, y)$. Then, this formula may be said to represent a function, and we consider adding a function symbol $f(\vec x)$ to the language (call the new language $L'$), together with the axiom $\forall_{\vec x} \varphi(\vec x, f(\vec x))$ (call the new set of axioms $T'$). The first main result is that this adds no power to the language.

\begin{prop}\label{prop:cons1}
With $L$, $T$, $L'$, and $T'$ as above, there is a way to transform formulas $\varphi$ in $L'$ into formulas $\hat\varphi$ in $L$, such that:
\begin{itemize}
\item From the perspective of $T'$, $\varphi \leftrightarrow \hat\varphi$,
\item If $\varphi$ is already in $L$, then $T \vdash \varphi \leftrightarrow \hat\varphi$,
\item $T'$ proves $\varphi$ iff $T$ proves $\hat\varphi$.
\end{itemize}

As a consequence of the above properties, if $\varphi$ is a formula in $L$ and $T' \vdash \varphi$, then $T \vdash \hat\varphi$, hence $T \vdash \varphi$ as well.
\end{prop}

The operator $\hat\cdot$ described above operates recursively on a formula, being interesting only when it reaches atomic formulas, e.g. $t_1 = t_2$. In this scenario, it will recursively replace any instance of application of $f$ by an instance of $\varphi$, for example:
\begin{equation}
\begin{aligned}
g(f(x),y) = f(h(0)) \quad\rightsquigarrow\quad& \forall_{\nu_1 \mid \varphi(x, \nu_1)} \; \forall_{\nu_2 \mid \varphi(h(0), \nu_2)} \; g(\nu_1, y) = \nu_2,\\
\text{or }& \exists_{\nu_1 \mid \varphi(x, \nu_1)} \; \exists_{\nu_2 \mid \varphi(h(0), \nu_2)} \; g(\nu_1, y) = \nu_2.
\end{aligned}
\end{equation}

Note: The choice to use a $\forall$ or an $\exists$ is indifferent. This is useful because it means that if $\varphi$ is $\Sigma_n$ or $\Pi_n$, for $n \geq 1$, we may choose $\hat\varphi$ in the same class.

A useful property is that axiom schema of induction is preserved.
\begin{prop}\label{prop:cons2}
Suppose that $T$ contains the axiom schema of induction in $L$. Then $T'$ proves the axiom schema of induction in $L'$.

Moreover, this conclusion holds if we restrict ourselves to $\Sigma_n$ or $\Pi_n$ induction, for $n \geq 1$.
\end{prop}

\begin{proof}
If $\psi(x, \vec y)$ is a formula, then by proposition \ref{prop:cons1}, from the perspective of $T'$ the axiom of induction for $\psi$ is equivalent to the axiom of induction for $\hat\psi$. Since $T$ proves the latter, $T'$ does as well, and so it proves induction for $\psi$.
\end{proof}

\begin{remark}\label{rmk:delta0}
The second part of proposition \ref{prop:cons2} does not necessarily hold for $\Delta_0$ formulas, because the hat operator adds a quantifier which is not necessarily bounded. However, if one can find a term $t(\vec x)$ such that $T \vdash \forall_{\vec x} \forall_y (\varphi(\vec x, y) \rightarrow y \leq t(\vec x))$, then the hat operator may be made to add only bounded quantifiers. To me, this motivates the definition of $\Delta_0$ function, as one which is defined by a bounded quantifier formula and is itself bounded by a term in the input.
\end{remark}

\section{Computing in Arithmetic}

\subsection{Encoding Sequences}\label{sec:seqenc}

\begin{definition}\label{def:seqenc}
A \emph{sequence encoding} is a pair of formulas, say $\lambda(x,w)$ and $\theta(x,y,z)$, satisfying the following conditions (in the axiomatic system under consideration).
\begin{gather}
\forall_x \exists^1_w \lambda(x,w) \quad\text{(We say $w$ is the length of $x$, and denote it $\len(x)$)} \tag{Len}\\
\exists_x \len(x) = 0 \quad\text{(We call $x$ an empty sequence)} \tag{Eps} \label{ax:eps}\\
\parbox{0.8\linewidth}{\centering Given $x$ and $y$, there is a unique $z$ such that $\theta(x,y,z)$. \\ This $z$ is denoted by $(x)_y$, and moreover if $y \geq \len(x)$ we have $(x)_y = 0$.} \tag{Eval}\\
\parbox{0.8\linewidth}{\centering Given $x$ and $a$, there exists $x'$ such that: \\ $\len(x') = \len(x) + 1$, $(x')_{\len(x)} = a$, and for $y < \len(x)$, $(x')_y = (x)_y$.} \tag{Ext}\label{ax:ext}
\end{gather}
\end{definition}

An extremely important fact is the following.

\begin{prop}[Gödel's lemma]\label{prop:godellemma}
There exists a $\Delta_0$ sequence encoding in $\PA$. (Also in the sense of remark \ref{rmk:delta0}.)
\end{prop}

As it happens, as long as we have sufficient induction, the actual encoding chosen is irrelevant for our purposes, as we will never use anything about the encoding other than definition \ref{def:seqenc} (and possibly the fact that $\lambda$ and $\theta$ are $\Delta_0$). Indeed, one could imagine replacing our language by a two-sorted language, of which one sort is natural numbers and the other is sequences, and adjoining the axioms in definition \ref{def:seqenc}. Then, proposition \ref{prop:godellemma} would translate to a conservativity result: This new system proves nothing about the natural numbers that PA did not already.

This process of adding a second sort to our language could lead to some issues, namely when it comes to the notion of bounded quantification. However, I believe that it is already not feasible to bound the representatives of sequences, and indeed I think that quantifiers over (numbers that are intended to represent) sequences are basically never bounded. In any case, the main use for sequences is to represent the execution process of a Turing machine (see proposition \ref{prop:sigma1} below), in which event the quantifier for the sequence is unbounded, and thus we need not worry about what it means for a quantifier over a sequence to be bounded.

\begin{remark}
If I'm not mistaken, proposition \ref{prop:godellemma} does not require the full power of $\PA$, but only $\Sigma_1$ induction.
\end{remark} 

\subsection{Recursion in PA}

Now that we are equipped with the notion of sequences, we are able to add a lot of new function symbols to $\PA$.

\begin{prop}\label{prop:recursion1}
Let $f(x, y)$ be a function in two variables in $\PA$, by which we mean: Let $\varphi(x,y,z)$ be a formula such that $\PA \vdash \forall_{x, y} \exists^1_z \varphi(x,y,z)$, and let $f$ be a function symbol adjoined to represent this function. Moreover, let $t_0$ be a given term in $\LA$. Then, $\PA$ proves that there exists a unique function $g(x)$ such that
\begin{gather}
g(0) = t_0,\\
\forall_x \; g(x+1) = f(x, g(x)).
\end{gather}
\end{prop}

\begin{proof}
We define $\psi(x,z)$ by the formula
\begin{equation}
\psi(x,z) \colon \quad \exists_s (\len(s) = x+1 \land (s)_0 = t_0 \land \forall_{k < x} (s)_{k+1} = f(x, (s)_k) \land (s)_x = z).
\end{equation}

Then, one shows by induction (using \eqref{ax:eps} and \eqref{ax:ext}) that $\forall_x \exists_z \psi(x,z)$. Moreover, we have uniqueness of $z$ because, by induction on $k$, any two sequences $s$ of length $x+1$ satisfying $(s)_0 = t_0$ and $\forall_{k \leq x} (s)_{k+1} = f(x, (s)_k)$ agree for all $k$. In particular, they will agree at $k = x$, and thus the value of $z$ is uniquely determined from the value of $x$.
\end{proof}

\begin{remark}
Proposition \ref{prop:recursion1} is not nearly as general as it could be; it is intended rather to sketch the kind of thing that is possible, without being overburdened with excessive abstraction. A small modification of it, for example, allows us to prove the existence and uniqueness of a binary function representing exponentiation, which is determined by the property that $x^0 = 1$ and $x^{y+1} = x^y \times x$.
\end{remark}

\begin{remark}
A possible culmination, by which I mean `most general yet reasonable possible version', of proposition \ref{prop:recursion1} is the statement that the set of functions definable in $\PA$ are closed under the operations used to generate the primitive recursive functions.

I am taking care to avoid the phrasing `$\PA$ proves the existence of all primitive recursive functions', because given a PR function there is more than one way to construct over $\N$ it using the operations. In particular, one may replace $f(x)$ by the (\textit{a posteriori} PR) function $g(x)$ given by `if $x$ represents a proof that $\PA$ is inconsistent, return $0$, otherwise return $f(x)$'. Since $\PA$ is (hopefully) consistent, $f$ and $g$ agree over the natural numbers. However, \textit{a posteriori} we know that there exist models of $\PA$ where such an $x$ does exist, and on those models $f$ and $g$ will furnish two distinct extensions of the same PR function.
\end{remark}

\begin{remark}
{}[To do, write out how this looks in $\WPA$.] [Future self says: What?]
\end{remark}

Using Gödel's lemma, it is possible to encode the code for a Turing machine as a natural number, and likewise for the state of a Turing machine. Moreover, it is possible to do so in such a way that the function $\textrm{step}(tape, code)$ is PR. Finally, we may also encode a `step sequence', and both the predicate `is this step sequence a valid execution sequence for this code', and the function which extracts the output `number' from a tape, are also PR. As such, given a Turing machine encoded by the number $n \in \N$, we may attempt to encode the partial computable function corresponding to it by the formula
\begin{equation}
\varphi(x, y) \equiv \exists_{s} \; (\text{$s$ is a running sequence for $n$, with input $x$ and output $y$}).
\end{equation}

In order to better understand the subtleties of this definition, let us establish some notation.
\begin{definition}
We will now enumerate some Primitive Recursive functions on the natural numbers, and give them a name. In the sequel, we assume that these names have been added to the language as function symbols, axiomatized via some way to represent them in the Primitive Recursive schema.\footnote{In nonstandard models, distinct representations may lead to distinct functions. However, these representation will always agree over $\N$.}
\begin{itemize}
\item $\step(n, t)$: Where $t$ represents a tape state, and $n$ a Turing machine, this function symbol outputs (a number representing) the next state of the tape upon executing a step of the Turing machine $n$,

\item $\tapefrominput(x)$: This function symbol outputs (a number representing) a tape containing nothing but $x$ many ones after the pointer,

\item $\halted(t)$: Where $t$ represents a tape state, this predicate will evaluate as True if $t$ is in the halted state (i.e. computation has terminated) and False otherwise,

\item $\tapetooutput(t)$: Where $t$ represents a tape state, this function symbol extracts a natural number as output from the tape, in such a manner that $\tapetooutput(\tapefrominput(x)) = x+1$ holds for all $x$. The value $0$ is reserved as an error code, in the event that no discernible output may be obtained.
\end{itemize}

Implicit in the above definitions is the notion that $n$ and $t$ represent valid Turing machines and tapes, respectively. This verification is also PR, and we may assume that given invalid input, some fixed error code (e.g. zero) is produced as output.
\end{definition}

\begin{definition}\label{def:phin}
Let $f \colon \N \rightharpoonup \N$ be a partial computable function, and let $n$ be a code for a Turing machine which computes $f$. To this Turing machine we associate the $\Sigma_1$ formula
\begin{equation}
\varphi(n,x,y) \equiv \exists_s \left(
\begin{aligned}
&(s)_0 = \tapefrominput(x)\\
\land \; &[\forall_{i < \len(s) - 1} (s)_{i+1} = \step(n, (s)_i)]\\
\land \; &\halted((s)_{\len(s)-1})\\
\land \; &y+1 = \tapetooutput((s)_{\len(s) - 1})
\end{aligned} \right)
\end{equation}
\end{definition}

\begin{prop}
Let $f$, $n$, and $\varphi$ be as in definition \ref{def:phin}, and let $a \in \N$ be in the domain of $f$. Then, $\WPA \vdash \varphi(n,a,f(a))$.
\end{prop}

\begin{proof}
Direct consequence of proposition \ref{prop:wpasigma1}.
\end{proof}

\begin{remark}
It is not the case that, as stated, the output (from the POV of $\WPA$) is unique, as there may be nonstandard execution sequences $s$ which give wildly different results. This can be remedied by ensuring that $s$ is a standard element.

In general it is not possible to make this demand, but in this case we have the following work-around: We demand that $s$ is a minimal valid execution sequence. Indeed, in the scenario where $a$ is in the domain of $f$, a valid (standard) execution sequence exists by hypothesis, and any nonstandard execution sequence will be greater than it (by \ref{prop:leqrep}), so picking out the minimal sequence ensures that it is standard.
\end{remark}

\begin{prop}\label{prop:psin}
Define the formula $\psi(\eta,x,y)$ given by
\begin{equation}
\psi(\eta,x,y) \equiv \exists_s \left(
\begin{aligned}
&(s)_0 = \tapefrominput(x)\\
\land \; &[\forall_{i < \len(s) - 1} (s)_{i+1} = \step(\eta, (s)_i)]\\
\land \; &\halted((s)_{\len(s)-1})\\
\land \; &\text{$s$ is minimal under the above conditions}\\
\land \; &y+1 = \tapetooutput((s)_{\len(s) - 1})
\end{aligned} \right)
\end{equation}

Now, let $f \colon \N \rightharpoonup \N$ be a partial computable function, and $n$ a code for a Turing machine computing $f$. Then, for every natural number $a$ in the domain of $f$,
\begin{equation}
\left( \WPA \vdash \psi(n,a,b) \right) \text{ iff } b = f(a).
\end{equation}
\end{prop}

\begin{proof}
Let us briefly introduce the $\Delta_0$ formula $\psi_0(\eta,x,y,s)$ such that $\psi(\eta,x,y) \equiv \exists_s \psi_0(\eta,x,y,s)$.

$(\leftarrow)$ If $a$ is in the domain of $f$, there is an execution sequence for $n$, represented by a standard natural number $s$, which starts in the state $\tapefrominput(a)$ and ends in the state corresponding to the output $f(a)$. This execution sequence is (or may be chosen to be, depending on uniqueness properties of our encoding) minimal, hence (by \ref{prop:wpadelta0}) $\WPA \vdash \psi_0(n,a,f(a),s)$.

$(\rightarrow)$ Note that the expression for $\psi_0(\eta,x,y,s)$ contains the line $y = \tapetooutput(s)$. Moreover, $\WPA$ proves that, given $\eta$ and $x$, there is at most one value of $s$ making $\psi_0$ hold. Thus, we conclude that there is at most one value of $y$ making $\psi(n,a,y)$ hold, as we've seen $f(a)$ is such a value, and so $b$ must be the same.
\end{proof}

\begin{corollary}\label{cor:psin}
Let $f$, $\psi$, $n$ as above. Then, for all $a$ in the domain of $f$,
\begin{equation}
\WPA \vdash \forall_y (\psi(n,a,y) \leftrightarrow y=f(a)).
\end{equation}
\end{corollary}

\begin{proof}
We claim that $\WPA$ proves that $\forall_\eta \forall_x \exists^{\leq 1}_y \psi(\eta,x,y)$. Perhaps this is not true for the $s$ as stated and requires tinkering with the encoding a bit, but if we encode tapes in such a way that $\tapetooutput$ is simple enough (this could be as easy as making our encoding of Turing machines be a pair whose second element is the result of $\tapetooutput$) we can see that the line $y+1 = \tapetooutput((s)_{\len(s)-1})$ uniquely determines $y$ given $s$ (from the perspective of $\WPA$.

Once this is done, note that (reasoning in FOL) from $\forall_x \exists^{\leq 1}_y P(x,y)$ and $P(a,b)$, one obtains $\forall_y (P(a,y) \leftrightarrow y=b)$.
\end{proof}

\begin{remark}
If $a$ is not in the domain of $f$, it is unclear to me what $\WPA$ thinks of the sentence $\exists_y \psi(n,a,y)$. By proposition \ref{prop:wpasigma1}, $\WPA$ certainly cannot prove it true, but in general there is no reason to believe that it can prove it false either.
\end{remark}

\section{The First Incompleteness Theorem}

\subsection{Self-Reference}

A big ingredient in proving the first incompleteness theorem is the capacity to encode a sentence saying `this sentence is false', or $P \colon \text{`$P$ is false'}$. However, sentences cannot directly be self-referential, so we must find a way to work around this.

A way to get around this issue is to note that, as we've seen before, we can `encode computer programs inside arithmetic'. Moreover, it is known that we can make computer programs that print themselves, also known as Quines. As such, we might expect to encode inside arithmetic a formula that is able to refer to a code for itself in some indirect way. Formally, this is reflected in the proposition \ref{prop:selfref} below.

\begin{definition}
We assume a fixed way to encode formulas in the language of Arithmetic as natural numbers in a way amenable to computable operations, e.g. substituting variables for expressions, checking for closedness, etc. The number encoding a formula is called its \emph{Gödel number}. If $\varphi$ is a formula, its Gödel number is written $\gn\varphi$. It will also be useful to have a way to denote the reverse operation: If $n$ is a number, $\gf{n}$ symbolizes the formula encoded by $n$.
\end{definition}

\begin{prop}\label{prop:selfref}
Let $\theta(x)$ be a formula with one free variable in the language of arithmetic. Then, there is a sentence $P$ such that
\begin{equation}
\WPA \vdash P \leftrightarrow \theta(\gn P).
\end{equation}

Moreover, if $\theta$ is $\Pi_1$, then $P$ is also $\Pi_1$.
\end{prop}

\begin{remark}
This will allow us to find a sentence $P$ that cannot be proven nor disproven in a given theory $T$, roughly by setting $\theta(x) \colon \text{$T$ thinks $\gf x$ is false}$. Then, if $T$ is able to prove $P$, it will hold that (according to $T$) $P$ is false, which is a contradiction, and a similar argument works if $T$ were able to prove $\neg P$.

Of course, the truth is a lot more technical than the above paragraph.
\end{remark}

The remainder of this section consists of the proof of proposition \ref{prop:selfref}.

\smallskip

The main idea to construct $P$ is the following. We shall have a `template formula' $\tau(x)$, and $x$ being intended as some data from which the formula $P$ will reconstruct itself. More precisely, we will set $P \equiv \tau(\gn\tau)$, and the idea is that $\tau$ is able to take $x = \gn\tau$ and reconstruct itself by considering $\gf{x}(x)$.

To be a little more precise, let $f \colon \N \to \N$ be given by
\begin{equation}
f(n) = \gn{\gf{n}(n)},
\end{equation}
where $\gf{n}(n)$ represents replacing some fixed variable in $\gf{n}$, say $x$, by (some expression evaluating to) the numerical value of n.

\begin{remark}\label{rmk:rug}
We are sweeping under the rug details such as `what if $x$ is not the Gödel number of any formula?' In our view, these details are easily dealt with (pick some convention for an error code) and do not add anything to the exposition other than extra technical load.
\end{remark}

Now, under any reasonable choice of Gödel encoding, the function $f$ is computable and (see remark \ref{rmk:rug}) total. Therefore, it is represented in $\WPA$ by some $\Sigma_1$ formula $\varphi(x,y)$ as in proposition \ref{prop:psin}. We now have all the tools that we need to reverse-engineer the definition of $P$.

We want that, under $\WPA$, $P \leftrightarrow \theta(\gn P)$. Assuming that $P$ is constructed by feeding the Gödel number of some template formula $\tau$ to itself, this is the same as requiring that
\begin{equation}
\tau(\gn\tau) \leftrightarrow \theta(\gn{\tau(\gn\tau)}),
\end{equation}
or equivalently $\tau(\gn\tau) \leftrightarrow \theta(f(\gn\tau))$. This suggests setting $\tau(x) \colon \theta(f(x))$, but this is invalid because $f$ is not part of the language of arithmetic. So we replace $f$ by the representation given by $\varphi$, and set
\begin{equation}
\tau(x) \colon \forall_y(\varphi(x,y) \rightarrow \theta(y)), \quad P \colon \tau(\gn\tau).
\end{equation}

We now prove that $P$ does what is desired of it. Note that $\gn P = f(\gn \tau)$, so it is the case that $\WPA \vdash \varphi(\gn\tau, \gn P)$. Moreover, by corollary \ref{cor:psin} $\WPA$ proves $\varphi(\gn\tau, y) \leftrightarrow y=\gn P$, hence
\begin{equation}
\WPA \vdash \big[ \forall_y(\varphi(\gn \tau,y) \rightarrow \theta(y)) \big] \leftrightarrow \big[ \forall_y (y = \gn P \rightarrow \theta(y)) \big].
\end{equation}

The left-hand side is by definition $P$, and the right-hand side is evidently equivalent to $\theta(\gn P)$, and so the proof of proposition \ref{prop:selfref} is complete.

\begin{remark}
While in the above exposition we assumed that $\theta$ is a formula in the language of arithmetic, this is not a necessity. Indeed, it is actively undesirable when applying this theorem to more general contexts, such as $\mathrm{ZF}$ or second order arithmetic.

We remark that $\theta$ was effectively only used as a black box. As such, the only effective requirements on the underlying system are: The underlying language $\mathcal{L}$ must be computable in some sense (so that Gödel numbering makes sense), and there must be (possibly composite) predicates: `isNatural', `isSuccessor', `isZero', `isSumOf', `isProductOf', and $\leq$, such that the underlying theory $T$ proves (the translation to relational languages of) the axioms of $\WPA$, relativized to the class of elements satisfying isNatural.

The resulting translation will likely wreak havoc on the quantifier complexity of the formula, though one wonders to what extent complexity is meaningful to the underlying theory. This is strange because complexity, and in particular the completeness of $\WPA$ for bounded quantifier sentences, was essential on the path to where we stand, and it feels like the results we have gotten to should abstract to a context where complexity may be meaningless or useless.

One may try to define the complexity of a formula using only the predicates above, corresponding to a translation of the language of arithmetic to a relational language. This raises the question of how to define complexity such that that the formula $\varphi(x) \colon \exists_y (\mathrm{isSuc}(y,x) \land \exists_z (\mathrm{isSuc}(z,y) \land \mathrm{isZero}(z)))$ is of the lowest level of complexity, being as simple as $x = S(S(0))$.

(\textit{Post Scriptum:} It is my expectation after some discussion with Denis Hirschfeldt that, while the notion of $\Delta_0$ formula is severely weakened, all other steps on the hierarchy should stay intact.)

Anyhow, according to the above paragraphs, one obtains that the results that follow will hold for any language and theory which is strong enough to `express arithmetic to the level of $\WPA$'. This is not shocking for incompleteness, but more surprisingly undefinability of truth (section \ref{sec:tarski}) will hold even for languages and theories with additional expressive power beyond that of arithmetic.
\end{remark}

\subsection{The Gödel Sentence}

Now that we are able to construct self-referential sentences (or, perhaps more precisely, sentences that are able to refer to their own Gödel number), we begin to conceive how one may write a sentence $P$ saying `$P$ is false'. However, in a precise technical sense, it is not possible to write a formula which recovers the truth value of $P$ from its Gödel number; see section \ref{sec:tarski} below. However, there is a `close enough' analogue: it \emph{is} possible to encode the notion of proof, so we can consider a sentence $P \colon \text{$P$ cannot be proven}$.

More precisely, let $T$ be a theory in the language of arithmetic. Then, \emph{under the assumption that $T$ can be axiomatized by a recursively enumerable set}, there is a partial computable function $T\Proves(x)$, which halts if $T \vdash \gf x$, and runs forever otherwise.

Yet more specifically, there is a total computable predicate $T\ProofOf(q,x)$, which (under some suitable encoding of proof) checks whether $q$ is a proof of $T \vdash \gf x$. Then, we set $T\Proves(x)$ to mean $\exists_q T\ProofOf(q,x)$. Remarkably, if we are very particular about the form of the encoding, we can ensure that $T\ProofOf(q,x)$ is a bounded quantifier formula. (This is an application of a rather general principle; Since $T\ProofOf$ is (under a reasonable encoding) recursive, it may be encoded as a $\Sigma_1$ formula $\exists_s \varphi(q,x,s)$. If we change our encoding so that $q$ is replaced by $\braket{q,s}$, we can now represent $T\ProofOf$ in a bounded quantifier way.)

\begin{remark}
Since $T$ is assumed to be axiomatized by a recursively \emph{enumerable} set of axioms, and not necessarily recursive, one may be concerned about whether $T\ProofOf$ is total recursive. A naïve implementation might result in a partial recursive function: Loop over the statements, check for each of them whether it is an application of a logical rule, or a logical axiom, or an axiom of $T$, and this last step could hypothetically loop forever. However, it is possible to play with the encoding to make the function total.

Let $f \colon \N \to \N$ be an enumeration of the axioms of $T$. Then, we demand from our encoding of proofs that, when an axiom $A$ of $T$ is invoked, we include the value of $n$ that witnesses that the axiom is included in the enumeration, i.e. some value of $n$ such that $f(n) = \gn A$.
\end{remark}

That said, we can now encode the sentence $P \colon \text{`$T$ proves $\neg P$'}$, by applying proposition \ref{prop:selfref} to
\begin{equation}
\theta(x) \colon \exists_q T\ProofOf(q,\gn{\neg \gf x}) \equiv T\Proves(\gn{\neg \gf x}).
\end{equation}

\begin{remark}
There are two obvious ways to rewrite `$P$ is false' in terms of provability: Either `$T$ does not prove $P$', or `$T$ proves $\neg P$'. We chose the latter alternative. However, I think both alternatives yield similar results, and it does not matter which we take.
\end{remark}

\begin{prop}\label{prop:inc1g}
Let $T$ be a recursively enumerably axiomatizable theory in the language of arithmetic, and construct $P$ such that $\WPA \vdash P \leftrightarrow T\Proves(\gn{\neg P})$. This is called \emph{the Gödel sentence of $T$}.

Then, assuming that $\WPA \subseteq T \subseteq \Th(\N)$, $T$ can neither prove nor disprove $P$.
\end{prop}

\begin{remark}\label{rmk:omega}
The statement that $\WPA \subseteq T$ is a requirement that $T$ is `at least a little bit strong', in order to be able to reason about itself. This is extremely necessary; theories with weak enough reasoning may very well be complete and computable.

The statement that $T \subseteq \Th(\N)$ is a requirement that $T$ doesn't say anything false about the natural numbers. This requirement is much less necessary. For one, we will only use the much weaker statement about $T$: When $\varphi(x)$ is a $\Delta_0$ formula, $T$ cannot at the same time prove all the following sentences: $\varphi(0), \varphi(1), \varphi(2), \dots$ and $\exists_x \neg\varphi(x)$. This is known as $\omega$-consistency of $T$ for $\Delta_0$ formulas in one variable. Since $T$ contains $\WPA$, which is complete for $\Delta_0$ sentences, this property may be rewritten as: If $T \vdash \exists_x \psi(x)$, there is some natural number $n$ such that $T \vdash \psi(n)$, or equivalently that $\WPA \vdash \psi(n)$ or that $\N \vDash \psi(n)$.

In section \ref{sec:rosser} we will find a different sentence, for which the equivalent of proposition \ref{prop:inc1g} may be greatly relaxed, requiring only that $\WPA \subseteq T$ and that $T$ is consistent.
\end{remark}

\begin{proof}[Proposition \ref{prop:inc1g}]
Suppose first for contradiction that $T \vdash \neg P$. Then, if $n$ is a natural number encoding a proof of this fact, we the predicate $T\ProofOf(n,\gn{\neg P})$ evaluates as true. Therefore, by proposition \ref{prop:wpadelta0}, $\WPA \vdash T\ProofOf(n,\gn{\neg P})$, hence $\WPA \vdash T\Proves(\gn{\neg P})$, thus $\WPA \vdash P$ and so $T \vdash P$, a contradiction.

Suppose now that $T \vdash P$. Then, since $\WPA \subseteq T$, we obtain that $T \vdash T\Proves(\gn{\neg P})$, or equivalently $T \vdash \exists_q T\ProofOf(q, \gn{\neg P})$. Now, by remark \ref{rmk:omega}, we obtain that there is some natural number $n$ such that $\N \vDash T\ProofOf(n,\gn{\neg P})$, and so $n$ encodes an `honest' proof that $T \vdash \neg P$. This is a contradiction.
\end{proof}

\begin{corollary}
$\PA$ is incomplete.
\end{corollary}

\subsection{The Rosser Sentence}\label{sec:rosser}

The main place for improvement in proposition \ref{prop:inc1g} is the stringent requirement that (as per remark \ref{rmk:omega}) if the theory $T$ proves $\exists_x \varphi(x)$, for $\varphi$ in $\Delta_0$, then it really is the case (from the perspective of $\N$) that there exists someone satisfying $\varphi(x)$. This is necessary to go from `$T$ proves that there is a proof of $\neg P$' to `There is really a proof of $\neg P$'. If $T$ does not satisfy this, it may be the case that $T$ `sees' a proof of $\neg P$, encoded as an element of its universe $n$, but that from our outside perspective $n$ is a non-standard number and therefore cannot be turned into a proof of $T \vdash \neg P$.

The idea behind the Rosser sentence is to somehow ensure that the proof $n$ is really a standard integer. However, as we will see later in section \ref{sec:nonstd}, there is no first-order way to express that $x$ is `standard'. Therefore, we have to resort to imperfect ways of ensuring that $x$ is standard, and one such way is the following: Require that $x$ be less than some $y$, which is known to be standard. This works by proposition \ref{prop:leqrep}.

The Rosser sentence is now in sight. Suppose that $T$ proves $P$, where $P$ is the sentence `$T$ proves $\neg P$', plus some bells and whistles. Then, we want to ensure that this proof of $\neg P$ is a standard number, so we better say that it is smaller than something known to be standard. Well, we do have a `standard' proof $m$ of $T \vdash P$. So how about we let $P$ be `There is a proof of $T \vdash \neg P$, and it is smaller (as a number) than any proof of $T \vdash P$'? Then in particular this proof of $\neg P$ is smaller than $m$, and hence standard.

\begin{prop}\label{prop:inc1r}
Let $T$ be a recursively enumerably axiomatizable theory in the language of arithmetic, and construct $P$ such that
\begin{equation}
\WPA \vdash P \leftrightarrow \left(\exists_q \left(T\ProofOf(q,\gn{\neg P}) \land \forall_{p<q} \neg T\ProofOf(p, \gn P) \right) \right).
\end{equation}
This is called \emph{the Rosser sentence of $T$}.

Then, assuming that $\WPA \subseteq T$ and that $T$ is consistent, $T$ can neither prove nor disprove $P$.
\end{prop}

\begin{proof}
Suppose that $T$ proves $\neg P$. Then, there is some proof (encoded by) $n$ of $T \vdash \neg P$, and since $T$ is consistent there is no (standard) natural number $m$ such that $\N \vDash T\ProofOf(m, \gn{P})$. In particular, since $T\ProofOf$ is $\Delta_0$, $\WPA \vdash \forall_{p < n} \neg T\ProofOf(p,\gn{P})$, and from here one easily proves $T \vdash P$, a contradiction.

Suppose now that $T$ proves $P$; let $n$ encode such a proof. Then, $\WPA \vdash T\ProofOf(n,\gn{P})$, and therefore
\begin{equation}
\WPA \vdash \left( \forall_{p<q} \neg T\ProofOf(p,\gn P) \right) \rightarrow q \leq n.
\end{equation}

Therefore, since $T \vdash P$, it proves $\exists_q \left( T\ProofOf(q,\gn{\neg P}) \land q \leq n \right)$, and so, since $T$ contains $\WPA$, there is some $m \leq n$ such that $\N \vDash T\ProofOf(m, \gn{\neg P})$, and so $T \vdash \neg P$, a contradiction.
\end{proof}

The following proposition justifies why we care about this, perhaps at first mild-seeming, generalization of proposition \ref{prop:inc1g}. After all, why should we care about theories which extend $\WPA$ but contain falsehoods about the natural numbers?

\begin{corollary}
Any computable theory $T$ in the language of arithmetic which contains $\WPA$ has $2^{\aleph_0}$ consistent extensions.

As a consequence, $\PA$ has continuum many distinct countable models.
\end{corollary}

\begin{proof}
Build an infinite binary tree as follows: The base node contains $T$. For each node, which corresponds to an extension $T_s$ of $T$ by finitely many axioms (and therefore is recursively enumerably axiomatizable), pick a sentence $P$ which $T_s$ neither proves nor disproves. Then, create two branches for this node, one by adding $P$ and the other by adding $\neg P$ to the list of axioms.

The resulting tree has at each node a consistent extension of $T$, and any two nodes at the same depth will explicitly disagree on some statement. Therefore, the continuum-many paths on the tree will each provide a distinct consistent extension of $T$.
\end{proof}

\subsection{Undefinability of Truth}\label{sec:tarski}

\begin{prop}[Tarski's Undefinability of Truth]\label{prop:tarski}
Let $M$ be a model of $\WPA$ over the language of arithmetic. Then, there is no formula $\theta(x)$ (in the language of arithmetic) such that, for all sentences $\varphi$, $\varphi$ holds in $M$ iff $\theta(\gn\varphi)$ holds in $M$.
\end{prop}

\begin{proof}
Suppose that $\theta$ were such a formula. Apply proposition \ref{prop:selfref} to obtain a sentence $P$ such that $\WPA \vdash P \leftrightarrow \neg\theta(\gn P)$. This provides an obvious contradiction, regardless of whether or not $P$ holds in $M$.
\end{proof}

\section{Definability of (Some) Truth}

As we saw in proposition \ref{prop:tarski}, there is no formula which successfuly `interprets the truth of' arbitrary Gödel numbers of formulas. However, as we will see in this section, under $\PA$, for any finite level of complexity (more precisely, for any finite place in the arithmetic hierarchy) there is indeed a formula that embodies truth in that complexity.

\subsection{Bounded Quantifier Truth}

The goal of this section is to establish the existence of a predicate $\Sat_{\Delta_0}(x, y)$ which represents bounded quantifier truth in the following way.

\begin{theorem}\label{thm:satdelta0}
There exists a $\Delta_1(\PA)$ formula $\Sat_{\Delta_0}(x,y)$, in the language of arithmetic, such that, whenever $\varphi$ is a bounded quantifier formula in the language of arithmetic in $n$ free variables, say $y_1, \dots, y_n$, we have
\begin{equation}\label{eq:satdelta0}
\PA \vdash \forall_y (\Sat_{\Delta_0}(\gn{\varphi}, y) \leftrightarrow \varphi((y)_1, \dots, (y)_n)).
\end{equation}
\end{theorem}

The main idea should not come across as a surprise: We want to define $\Sat_{\Delta_0}$ inductively in the (Gödel name of the) formula $\varphi$. However, it is not evident that this would map to a well-defined formula in the language of arithmetic.

We recall from proposition \ref{prop:recursion1} that $\PA$ is able to express functions (and hence predicates) by primitive recursion on pre-existing functions. Moreover, while in principle the principle of primitive recursion allows you only to use $g(x)$ when computing $g(x+1)$, if you make your function output not just the result you want, but instead a sequence encoding all the results obtained thus far, you may actually assume that you have access to all prior results. This is quite useful when defining functions by induction on formula structure, as the results you will need to refer to when computing the result for $\gn\varphi$ are in general much smaller than $\gn\varphi - 1$.

To be a bit more precise, here is a modified version of proposition \ref{prop:recursion1} to take the previous paragraph into account.

\begin{prop}\label{prop:recursionacc}
Let $f(x, y)$ be a function in two variables in $\PA$, as in proposition \ref{prop:recursion1}. Moreover, let $t_0$ be a given term in $\LA$. Then, $\PA$ proves that there exists a unique function $g(x)$ such that
\begin{gather}
g(0) = t_0,\\
\forall_z \; g(z+1) = f(z, a(z)),
\end{gather}
where $a(z)$ is any sequence of length at least $z+1$ such that, for $y \leq z$, $(a(z))_y = g(y)$.

Moreover, if $f$ is represented by a $\Sigma_1$, $\Pi_1$ or $\Delta_1(\PA)$ predicate, so is $g$.
\end{prop}

The goal is now to find the appropriate recursion function $f(z,a)$. The input $z$ represents the pair $\braket{x,y}$, with $x$ `representing the Gödel number of a formula', and $y$ the list of inputs to it. Moreover, $\braket{}$ is an appropriate pairing function, e.g. $(x+y)^2 + y$. For our purposes, we need only that it and the projections are not complex (in our case, $\Delta_0$), and that it is monotone in each of its arguments.

Now, we begin describing the behavior of $f(\braket{x,y},a)$. First, we check if $x$ is the Gödel number of a formula; there is a PR way to do so for standard values of $x$, and we will never care about what happens for nonstandard values.

Now, if $x$ is indeed the Gödel number of some $\varphi$, we do cases on its structure [depending on the encoding]. For example, if $\varphi$ is $\varphi_0 \land \varphi_1$, we define $f$ via (in this case) $a_{\braket{\ssgn{\varphi_0}, y}} \times a_{\braket{\ssgn{\varphi_1}, y}}$. There are only two tricky cases to consider: The case where $\varphi$ is an atomic formula, and the case where $\varphi$ starts with a (bounded) quantifier.

Let us first consider the case where $\varphi$ is of the form $\forall_{x < t(y_1, \dots, y_n)} \psi(x, y_1, \dots, y_n)$. Without loss of generality, assume that $x$ is $y_{n+1}$; this is because there is a PR way to replace every instance of $x$ by $y_{n+1}$ and vice versa. Then, we would like to set $f(\braket{\gn\varphi, y},a)$ to be given by (this should be defined via an appropriate primitive recursion as a function of $a$, $t$, $y$, and $\gn\psi$)
\begin{equation}
f(\braket{\gn\varphi, y},a) \overset?= \prod_{i = 0}^{\eval(t,y)} (a)_{\braket{\ulcorner\!\psi\!\urcorner, (y, i)}}.
\end{equation}

The first problem the reader might notice is the undefined expression $\eval(t,y)$, which we'll define soon. The second problem, and most crucial one, is that we have no guarantee that $\braket{\gn\psi, (y,i)}$ is less than $\braket{\gn\varphi, y}$.

To fix the latter issue, we apply the following trick. Given a bounded quantifier formula, as well as parameters for it, it is possible to compute in a primitive recursive way a universal upper bound for all variables that will be iterated over in the course of checking the veracity of the formula. Indeed, for every quantifier $\forall_{y_{k+1} < t}$, where $t$ is a term depending on previously seen variables $y_1, \dots, y_k$, we evaluate $t$ on the maximal possible value of the variables we've seen so far (still pending the definition of $\eval$). This uses the fact that $S$, $+$, and $\times$ are monotone in their arguments, and thus any term in the language of arithmetic will be as well.

Now we may proceed with our definition of $\Sat_{\Delta_0}(x,y)$. We begin by processing the formula represented by $x$, and constructing a tuple $\bar y = (y,M,\dots, M)$, where $M$ is an upper bound for all the variables as per the previous paragraph, and it is added once for every new variable that will be considered in the subsequent iteration. Then, when recursing on the formula structure and coming across a new quantifier $\forall_{y_{n+1} < t(y_1, \dots, y_n)} \psi$, we recurse down from $p_0 = \braket{\gn\varphi, (y,M,M,\dots,M)}$ to $p_1 = \braket{\gn\psi, (y, y_{n+1}, M, \dots, M)}$, for all admissible values of $y_{n+1}$. Note: This may require changing the encoding of sequences to ensure that our encoding is monotone in each coordinate. An example of such an encoding would be one via prime factorization. We also assume that our Gödel numbering is monotone in formula structure, but this assumption will hold of any reasonable encoding of formulas. Once this is done, we are guaranteed by monotonicity that $p_1 < p_0$, hence the recursion will function all the way down until the base case.

So, let us finally tackle the case where $\varphi$ is an atomic formula, so either $t_1 < t_2$ or $t_1 = t_2$. It is evident that to solve either case it suffices to have a way to evaluate a term $t$ on a given assignment of parameters. This boils down to an easier version of the recursion we were doing before: Given a pair $\braket{\gn t, y}$, we recurse on the structure of $t$, applying the evaluation function to subterms. This is guaranteed to work because (assumption) the Gödel numbering decreases when passing to subformulas, and we will never need to modify $y$.

There are two things left to do. First, we would like to control the complexity of the predicate we have wound up defining. Second, we would like to sketch a proof that the resulting predicate satisfies \eqref{eq:satdelta0}.

For the complexity: It should be noted that all functions we have defined above were done so in a primitive-recursive-like way. We hesitate to say that they're \emph{actually} primitive recursive, because we're taking care to make them work with nonstandard numbers, but for sure there are only three big tools we're using: Primitive recursion as in Theorem \ref{prop:recursionacc}, definitions `by cases', and compositions of previously defined things. Moreover, none of these will make the complexity of previously defined things jump up above $\Delta_1(\PA)$, so we conclude that $\Sat_{\Delta_0}(x,y)$ as we've defined it is a $\Delta_1(\PA)$ predicate.

Now, let's verify that equation \eqref{eq:satdelta0} holds. This proof is performed by induction on the formula structure of $\varphi$, boiling down to proving rules like $\PA \vdash \Sat_{\Delta_0}(\gn{\varphi_1 \land \varphi_2}, y) \leftrightarrow (\Sat_{\Delta_0}(\gn{\varphi_1}, y) \land \Sat_{\Delta_0}(\gn{\varphi_2}, y))$, most of which turn out to be true by virtue of how we set up the recursion for $\Sat_{\Delta_0}$. The least trivial ones are the rule for quantifiers, and the rule for atomic formulas.

For quantifiers, we note that our definition allows us to prove (something like)
\begin{equation}
\PA \vdash \Sat_{\Delta_0}(\gn{\forall_{x < t(\vec y)} \psi(x,\vec y)}, y) \leftrightarrow \forall_{x < \eval(\ssgn t,y)} \Sat_{\Delta_0}(\gn\psi, (y,x)).
\end{equation}

Finally, and crucial for both quantified formulas and for atomic formulas, we can show by induction on the structure of the term $t$ that $\PA \vdash \eval(\gn t, y) = t((y)_1, \dots, (y)_n)$.

Anyway, a lot of details are being omitted or even misrepresented. But going the whole five miles would be a lot of work. Maybe someday I'll improve this exposition. If the reader is interested, \cite{kaye} goes into great detail on this subject in chapter 9. I understood very little of it.

\subsection{$\Sigma_n$ and $\Pi_n$ Truth}

Fortunately, defining bounded quantifier truth was the hard part. We can now define $\Sigma_n$ and $\Pi_n$ truth inductively.

\begin{theorem}\label{thm:satgeq1}
Let $n \geq 1$. Then, there exists a $\Sigma_n(\PA)$ formula $\Sat_{\Sigma_n}(x,y)$, in the language of arithmetic, such that, whenever $\varphi$ is a $\Sigma_n$ formula in the language of arithmetic in $n$ free variables, say $y_1, \dots, y_n$, we have
\begin{equation}\label{eq:satdelta0}
\PA \vdash \forall_y (\Sat_{\Sigma_n}(\gn{\varphi}, y) \leftrightarrow \varphi((y)_1, \dots, (y)_n)).
\end{equation}

A similar theorem holds if $\Sigma$ is replaced by $\Pi$.
\end{theorem}

\begin{proof}
We simply show it for $\Sigma_1$. The remainder, as well as $\Pi$, is obtained by an analogous inductive process.

Set $\Sat_{\Sigma_1}(x,y)$ to be something of the following form. First, check (in a primitive recursive way) if $x$ is the Gödel number of some formula $\exists_z \varphi(\vec y,z)$, where $\varphi$ is a bounded quantifier formula. Then, evaluate $\exists_z \Sat_{\Delta_0}(\gn\varphi, (y,z))$. Since $\Sat_{\Delta_0}$ is $\Delta_1(\PA)$, the result is (mod logical equivalence) a $\Sigma_1$ formula.
\end{proof}


\section{The Complexity of Nonstandard Theorems}\label{sec:nonstd}

In the following, we study nonstandard models of $\PA$. That is, we look at countable models $M \vDash \PA$ which are not (necessarily) the natural numbers.

It is worth noting that any model of $\PA$, even the nonstandard ones, will contain a copy of $\N$ as an initial segment. In fact, this holds of any model of $\WPA$: The set of elements which may be expressed as $S^k(0)$ for some natural number $k$ forms a subset of any model of $\WPA$, and $\WPA$ is strong enough to ensure that this subset behaves as the natural numbers expect it to, in the sense that e.g. $\WPA \vdash S^k(0) + S^\ell(0) = S^{k+\ell}(0)$. We will often identify this initial segment of any such model with $\N$ without further comment.

\subsection{Overspill and The Standard System}

Overspill is a very useful technique that allows us to extend (usually trivial) finite results to nonstandard elements, thereby recovering infinite information.

\begin{lemma}[Overspill]\label{lem:overspill}
Let $M$ be a nonstandard element of $\PA$. Then, there is no formula $\varphi(x)$ which identifies the natural numbers. In particular, if $M \vDash \varphi[n]$ for all natural numbers $n$, then $M \vDash \varphi[a]$ for some $a \in M \setminus \N$.

This result also holds with parameters: If $\vec b \in M$ and $M \vDash \varphi[n,\vec b]$ for all $n \in \N$ then there is some nonstandard $a \in M$ such that $M \vDash \varphi[a,\vec b]$.
\end{lemma}

\begin{proof}
Suppose by contradiction that $M$ thinks that $\varphi$ holds exactly on the natural numbers. In particular it does so for zero, and for every such $a \in M$ for which $\varphi$ holds, it also holds for $a+1$. Thus, by the principle of induction, so we apply induction to get that it holds for all elements of $M$, and in this case, looking at any $a \in M \setminus \N$ will lead to the desired contradiction.
\end{proof}

\begin{corollary}\label{cor:nsrep}
Let $M$ be a nonstandard model of $\PA$, and $A \subseteq \N$ a subset of $\N$ definable in $\PA$, i.e. there is a formula $\varphi$ such that $n \in A$ iff $\PA \vdash \varphi(S^n(0))$. Then, there is some $a \in M$ representing a sequence of zeros and ones (see section \ref{sec:seqenc}) such that
\begin{equation}
A = \{\, n \in \N \mid M \vDash (a)_n = 1 \,\}.
\end{equation}
\end{corollary}

\begin{proof}
Consider the formula
\begin{equation}
\psi(x) \colon \exists_y \forall_{z < x} (\varphi(z) \leftrightarrow (y)_z = 1).
\end{equation}

Then, $\psi$ evidently holds for all natural numbers $x$, hence by Overspill it must hold for some nonstandard element $b$. We conclude by setting $a$ to be the $y$ obtained by knowing $M \vDash \psi[a]$, and noting that every natural number is less than $a$.\footnote{Proof: In any model of $\WPA$, by proposition \ref{prop:leqrep}, any element which is less than or equal to a standard element is itself standard. Thus, $a$ must be bigger than all standard elements.}
\end{proof}

(write a bit about ssys?)

\subsection{Tennenbaum's Theorem}

Tennenbaum's theorem states that every nonstandard model of $\PA$ is `complicated'.

\begin{theorem}[Tennenbaum]\label{thm:tennenbaum}
Let $M$ be a countable nonstandard model of $\PA$, and assume that its domain is $\N$. Then, the operations $S^M$, $+^M$, $\times^M$, and $<^M$ are not all computable. (For a more precise result, see corollary \ref{cor:tennenbaum} below.)
\end{theorem}

\begin{proof}
The first step of the proof is the following. By applying Corollary \ref{cor:nsrep} together with the definability of $\Sigma_1$ truth, we obtain that there is some $a \in M$ such that, for any $\Sigma_1$ formula $\varphi$ of Gödel number $k$, $(a)_{S^k(0)} = 1$ if $\varphi$ holds in $M$, and $0$ otherwise. Thus, if we are able to compute the successor function and indexation of sequences, we will be able to compute $\Sigma^1$ truth in $M$. This is a contradiction, as we explain in the next paragraph.

Let $T$ be the set of $\Sigma_1$ sentences that hold in $M$. It should be noted that these contain $\WPA$, and moreover $T$ is complete for $\Sigma^1$ sentences. If $T$ is computable, we may apply proposition \ref{prop:inc1r} to obtain a Rosser sentence for $T$, but it should be noted that $P$ is equivalent (in $\WPA$) to a $\Sigma_1$ sentence. Thus, per the beginning of this paragraph, we conclude that $T$ \emph{must} make a decision on the truth of $P$, which is a contradiction.

Now all to remains is to investigate what it takes to evaluate sequence indexation. It is worthy of note that we have been very noncommittal about the particular schema we use to encode sequences. Recall that such a schema amounts to a formula in three free variables, say $\sigma(x,y,z)$, satisfying certain properties in $\PA$. A very common encoding will have $x$ encode a triple of numbers, say $N$, $a_0$, $b_0$, and compute $z$ as the remainder of division of $N$ by $a_0 y + b_0$. So, with this encoding, all that is required to index a sequence is to decode pairs, and to perform Euclidean division. Both of these may be performed by looping through all elements of $M$, and at each stage performing a certain check. For example, to decode a pair $p = \braket{i,j}$, loop through all pairs $x,y \in M$ and for each of them compute $(x +^M y) \times^M (x +^M y) +^M y$ and compare the output with $p$. If $p$ does represent a pair, this is guaranteed to eventually halt, and once it does the pair $(x,y)$ is the pair $(i,j)$. Euclidean division is slightly more complex, in that it requires a comparison to check that the (guessed) remainder is as small as it should be.

This concludes the proof. Note that indeed we used all four operations in the language of arithmetic, so all we've shown is that they cannot all be computable at the same time.
\end{proof}

\begin{corollary}\label{cor:tennenbaum}
Let $M$ be a countable nonstandard model of $\PA$, and without loss of generality assume that its domain is $\N$. Then, neither $+^M$ nor $\times^M$ is computable.
\end{corollary}

\begin{proof}
The proof boils down to noticing that the bottleneck for the previous proof was the work it takes to index a sequence. Thus, if we are able to provide a sequence encoding that (for our purposes) requires only addition or multiplication to decode, we will have shown that neither of these operations can be computable.

First, a surprising result. In order to perform Euclidean division \emph{by a standard element}, we need only know how to add. Indeed, suppose we are attempting to perform the division of $m$, a nonstandard element, by $S^n(0)$, a standard element. To do so, we iterate over all nonstandard numbers $x$ and over all $0 \leq r < n$, and ask whether $m = (x +^M \dots +^M x) +^M (1 +^M \dots +^M 1)$, where $x$ is added to itself $n$ times, and $1$ is added to itself $r$ times. Since $\PA$ shows that Euclidean division works, and that any element less than $n$ is a sum of less-than-$n$ many ones, this algorithm will eventually halt.

As a particular instance of the above paragraph, given a \emph{standard} prime number $p$, it is possible to check whether a \emph{nonstandard} number $m$ is divisible by $p$. Thus, if we encode a sequence of zeros and ones as a product of primes (the $i$-th primes divides $a$ iff $(a)_i = 1$) we are able to index it over standard elements (because the standard $n$-th prime agrees with the $n$-th prime in $M$), and hence by considering an encoding of the $\Sigma_1$ sentences which hold in $M$ we get a contradiction as in theorem \ref{thm:tennenbaum}. This shows that addition \emph{cannot} be computable.

The case for multiplication consists of noticing that, say, the map $x \mapsto 2^x$ is an isomorphism between $(M,+)$ and a submonoid of $(M,\times)$. Thus, by replacing $a$ by $2^a$ (which is definable in any model of $\PA$) we are able to encode our sequence in a way that requires only multiplication to index over standard elements.
\end{proof}


\section{Miscellaneous Curiosities}

\subsection{Parikh's Theorem}

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}