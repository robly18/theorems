\documentclass[11pt]{amsart}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}

\usepackage{showlabels}

\usepackage{lipsum}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\HH}{\mathcal{H}}
\newcommand{\BB}{\mathcal{B}}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}

\newtheorem*{remark}{Remark}

\title{\textbf{On optimal bounds for comparing Binary (and $n$-ary) Nest Measures with the Hausdorff Measure on $\R$}}


\author{Duarte Maia}
\address{Department of Mathematics, Instituto Superior Técnico}
\email{duarte.nascimento@tecnico.ulisboa.pt}

\author{Jorge Drumond Silva}
\address{Department of Mathematics, Instituto Superior Técnico}
\email{jsilva@math.ist.utl.pt}

\date{}


\begin{document}


\begin{abstract}
\lipsum[1]
\end{abstract}

\maketitle


\section{Introduction}

\lipsum[1]

\section{Hausdorff and Binary measures: a review}

\subsection{Hausdorff}

Let $X$ be a metric space, with distance $d$. We define the \emph{$s$-dimensional Hausdorff measure on $X$} as follows:

First, define, for $E \subseteq X$, $s \in \R^+_0$ and $\delta > 0$, $\HH_s^\delta(E) := \inf \sum_i \lvert U_i \rvert^s$, where:

\begin{itemize}

\item $\lvert E \rvert$ denotes the \emph{diameter of $E$}, defined by the $\sup$ of distances between elements of $E$;\footnote{We follow the convention that the diameter of the empty set be 0.}

\item The infimum is taken over countable coverings $\{U_i\}_{i \in \N}$ of $E$ such that the diameter of all $U_i$ is less than $\delta$. This mouthful is usually abbreviated to \emph{$\delta$-coverings}.

\end{itemize}

It is easy to see that, as $\delta$ decreases, this quantity increases. Hence, the limit $\lim_{\delta \to 0} \HH_s^\delta(E)$ exists in $\left[ 0, \infty \right]$. It is this quantity that we call the \emph{$s$-dimensional Hausdorff measure of $E$}:

\begin{definition}(Hausdorff Measure)

 \[\HH_s(E) := \lim_{\delta \to 0} \HH_s^\delta(E)\]
\end{definition}

\subsection{Dimension}

Fixed any set $E$ in a metric space $X$, an interesting phenomenon occurs: there exists a dimension $\sigma \in \left[0, \infty\right]$ such that:

\begin{itemize}
\item For $s < \sigma$, $\HH_s(E) = \infty$;

\item For $s > \sigma$, $\HH_s(E) = 0$;
\end{itemize}

To see that this is so, the following lemma is key:

\begin{lemma}\label{helperdimension}
Let $t < s$ be real nonnegative numbers. Then, if $\HH_t(E) < \infty$ we have $\HH_s(E) = 0$.
\end{lemma}

\begin{proof}
Suppose $t < s$ and $\HH_t(E) < \infty$. Put $M = \HH_t(E) + 1$. Then, for any $\delta > 0$ we may find a $\delta$-covering $\{U_i\}$ of $E$ such that $\sum \lvert U_i \rvert^t < M$. Hence, 

\begin{align*}
\sum \lvert U_i \rvert^s &= \sum \lvert U_i \rvert^t \lvert U_i \rvert^{s - t}\\
&\leq \sum \lvert U_i \rvert^t \delta^{s-t}\\
&\leq \delta^{s-t} M
\end{align*}

Therefore, $\HH_s^\delta(E) \leq \delta^{s-t} M$, whence making $\delta \to 0$ we get $\HH_s(E) = 0$, as desired.
\end{proof}

With this in mind, define, for a set $E$, its dimension

\begin{definition} (Hausdorff dimension of a set)

\[\sigma_E := \inf \{\, s \mid \HH_s(E) < \infty \,\}\]
\end{definition}

We can now show:

\begin{lemma}
(Well-definedness of the dimension of a set) Let $E \subseteq X$, where $X$ is a metric space.

\begin{itemize}
\item For $s < \sigma_E$, $\HH_s(E) = \infty$;

\item For $s > \sigma_E$, $\HH_s(E) = 0$;
\end{itemize}

\end{lemma}

\begin{proof}
The first inequality is trivial by definition of $\sigma_E$.

As for the second inequality, notice that if $s > \sigma_E$ then there exists $t < s$ such that $\HH_t(E) < \infty$. By lemma \ref{helperdimension}, we have $\HH_s(E) = 0$, as desired.
\end{proof}

This shows that the dimension of a set is the only dimension for which its Hausdorff measure may be nontrivial, that is, different from $0$ or $\infty$.

\begin{definition}
We will say $E \subseteq X$ is an \emph{$s$-set} if $\HH_s(E) \in \left]0, \infty \right[$.

It is obvious that an $s$-set has dimension $s$.
\end{definition}

\begin{remark}
Not every $s$-dimensional set is an $s$-set.
\end{remark}

\subsection{Net measures}

Hausdorff measure, and by extension Hausdorff dimension, is sometimes rather unwieldy to calculate, seeing as its definition requires one to look at all possible $\delta$-coverings. As such, there is interest in simplifying this process.

We will restrict our attention to $\R^n$, and later on to $\R$, as unfortunately a lot of what follows is not generalizable to other contexts.

First, notice that it is not without precedent for one to restrict their attention to specific coverings. Indeed, the reader may easily show that, if in the definition of $\HH_s^\delta$ one takes the infimum over \emph{open} $\delta$-coverings instead of arbitrary ones, the value of $\HH_s^\delta$ may change, but the limit as $\delta \to 0$ remains the same. Hence, one could consider the Hausdorff measure defined using open $\delta$-coverings with no loss of generality.

The notion of net measure arises from the idea of redefining the Hausdorff measure with a more manageable collection of sets to use for coverings. In the context of $\R^n$, Besicovitch (1952) used the so-called binary intervals, construction which we will make for the case of $n = 1$, but the reader can satisfy any curiosity they might have regarding the general case in \cite{falconer} \cite{rogers}.

\begin{definition}
Define the so-called \emph{binary intervals} in $\R$ as the set of intervals of the form $\left[ \frac k {2^j}, \frac {k+1} {2^j} \right[$, for $k, j \in \Z$.

The binary measure is defined analogously to the Hausdorff measure, except instead of arbitrary coverings one restricts themselves to $\delta$-coverings by binary intervals. It is denoted by $\BB_s(E) = \lim_{\delta \to 0} \BB_s^\delta(E)$.
\end{definition}

The usefulness of this definition lies in that, even though these measures do \emph{not} coincide in general with the Hausdorff measure, one can find bounds for one given the other.

The following theorem is found in \cite{falconer} \cite{rogers} and is left here without proof, though in the sequence of this document we will prove stronger results for the particular case of $n = 1$.

\begin{theorem}
Consider the Hausdorff and Binary measures defined in $\R^n$. The following inequalities hold for any set $E$:

\[ \HH_s(E) \leq \BB_s(E) \leq 3^n 2^{n^2} \HH_s(E) \]
\end{theorem}

\begin{remark}
Even though the preceding theorem will not be proven, it should be noticed that one of the inequalities is trivial.

Indeed, for any $\delta$ we have $\HH_s^\delta(E) \leq \BB_s^\delta(E)$, since both are infima taken over coverings of $E$, but the set of coverings `accepted' by the Hausdorff measure is a superset of those considered in the binary measure. Making $\delta \to 0$, we have inequality $\HH_s(E) \leq \BB_s(E)$.
\end{remark}

The preceding theorem has the following consequence: defining the ``binary dimension'' of a set analogously to how we defined the Hausdorff dimension, these two concepts would coincide. To see why, simply notice that the Hausdorff measure of a set is zero iff the binary measure is zero, and same for infinity.

Hence, if we are interested in the Hausdorff dimension of a set, we may begin by investigating its binary measure.

Notice, however, that the provided bound is, in simple terms, \emph{awful}. Indeed, for $n = 1$ the obtained constant amounts to 6, but we will see below that it can be significantly lowered without much effort. (And then lowered more, with significantly more effort.)

Of course, this is of no consequence for dimensional considerations, which is where (as far as the author is aware) their main utility is found. However, the results that follow allow for much tighter bounds, and hopefully better understanding of how these two relate.

\section{Better elementary bounds, and a few notes on notation}

\lipsum[1]


\begin{thebibliography}{1}
\bibitem{falconer}
K. J. Falconer, \textit{The Geometry of Fractal Sets}

\bibitem{rogers}
C. A. Rogers, \textit{Hausdorff Measures}

\end{thebibliography}


\end{document}
