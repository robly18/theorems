\documentclass{article}

\usepackage[utf8]{inputenc}

\usepackage[thmmarks]{ntheorem}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathtools}

\usepackage{enumitem}

\usepackage{braket}
\usepackage{diffcoeff}

\usepackage{cite}

\usepackage{tikz}


\title{Measurement Spaces in Finite Dimension}
\author{Duarte Maia}

\theoremstyle{plain}
\theoremseparator{.}
\theorembodyfont{\rm}
\newtheorem{problem}{Problem}
\newtheorem{definition}{Definition}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}
\renewtheorem*{prop*}{Proposition}
\newtheorem*{idea}{Idea}
\newtheorem*{remark}{Remark}

\theoremstyle{nonumberplain}
\theorembodyfont{\upshape}
\theoremheaderfont{\slshape}
\theoremsymbol{\ensuremath{\blacksquare}}
\newtheorem{proof}{Proof}

\DeclareMathOperator{\spann}{span}
\DeclareMathOperator{\ext}{ext}
\DeclareMathOperator{\Max}{Max}
\DeclareMathOperator{\Aut}{Aut}

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}


\newcommand{\e}{\mathrm{e}}
\newcommand{\I}{\mathrm{i}}


\newcommand{\HH}{\mathcal{H}}

\newcommand{\ps}{\mathcal{P}}
\newcommand{\pr}{\mathbb{P}}

\newcommand{\id}{\mathrm{id}}

\newcommand{\two}{\mathbf{2}}

\newcommand{\conj}[1]{\overline{#1}}

\begin{document}
\maketitle

\section{Showing that $\Max A$ is a Measurement Space, when $A$ is an Involutive Algebra of Matrices}

First, we recall the definitions at play. Some of these are not done with the greatest generality for the sake of simplicity.

\begin{definition}
Let $V$ be a finite dimensional complex vector space. We denote by $\Max V$ the topological space defined as follows:

\begin{itemize}
\item The points of $\Max V$ are the subspaces of $V$,
\item The topology on $\Max V$ is the one generated by the following subbasis: For each open $U$ of $V$, construct $\tilde U \subseteq \Max V$ as
\[\tilde U = \{\, \text{$m$ subspace of $V$} \mid m \cap U \neq \emptyset\,\}.\]
\end{itemize}
\end{definition}

\begin{definition}\label{defmaxa}
Let $A$ be a finite dimensional involutive complex algebra. In this case, $\Max A$ inherits the following operations from $A$:
\begin{itemize}
\item The multiplication of elements of $A$ induces a multiplication of elements of $\Max A$, by taking pairwise products and then considering the span;
\item The involution of $A$ induces involution on elements of $\Max A$, by taking pointwise involutions.
\end{itemize}
\end{definition}

\begin{definition}
Let $X$ be a topological space. A nonempty closed set $C \subseteq X$ is said to be irreducible if it cannot be written as the union of two closed sets, neither of which is equal to $C$. To each point $x \in X$ corresponds the irreducible closed set $\overline{\{x\}}$. We say that $X$ is sober if this correspondence is a bijection.
\end{definition}

\begin{definition}
Let $X$ be a topological space. We order its points by the specialization order: $x \leq y$ iff every open which contains $x$ also contains $y$. This is a partial order so long as $X$ is $T_0$.
\end{definition}

\begin{definition}\label{def:ms}
A measurement space is a topological space $M$ such that:
\begin{enumerate}[label=\roman*)]
\item \label{msober} $M$ is sober,
\item \label{leastelem} $M$ contains a least element in the specialization order, called $0$,
\item \label{binsup} The specialization order on $M$ is closed under binary suprema,
\item \label{contsup} The supremum operation $\lor$ is a continuous function $M \times M \to M$,
\item \label{binop} $M$ is equipped with a continuous binary operation called `composition', satisfying the axioms:
\begin{enumerate}
\item \label{assoc} $(mn)p = m(np)$, \quad \textit{(associativity)}
\item \label{dist} $(m \lor n)p = mp \lor np$, \quad \textit{(distributivity)}
\item \label{absorp} $0p = 0$,
\end{enumerate}
\item \label{inv1} $M$ is equipped with a continuous unary operation $(\cdot)^*$ which is an involution,
\item \label{inv2} $(mn)^* = n^* m^*$, and
\item \label{symmetry} If $m m^* m \leq m$ then $m m^* m = m$. \quad \textit{(symmetry)}
\end{enumerate}
\end{definition}

The goal of this document is to show the following proposition:

\begin{prop*}
Let $A$ be an involutive algebra of matrices, that is, a linear subspace of $M_{n \times n}(\C)$ which is closed under products and conjugate transposition. Then, $\Max A$, equipped with the operations of definition \ref{defmaxa}, is a measurement space.
\end{prop*}

\begin{remark}
Properties \ref{msober} to \ref{contsup} refer only to the topological structure of $M$, and not to its operations. Therefore, they remain valid as properties of $\Max V$, where $V$ is a complex vector space (which is not necessarily an involutive algebra). Therefore, in the sequence we will, when appropriate, state the results for vector spaces $V$ as opposed to involutive algebras of matrices $A$.

Whenever the letter $A$ appears below, it should be assumed to represent an involutive algebra of matrices.
\end{remark}

\subsection{The Specialization Order}

First, we study the specialization order on $\Max V$, where $V$ is a complex vector space, in order to prove properties \ref{leastelem}, \ref{binsup} and \ref{contsup}. To begin, we show that the specialization order is simply the subset order.

\begin{prop}
Let $m$ and $n$ be elements of $\Max V$, that is, subspaces of $V$. Then, $m \leq n$ iff $m \subseteq n$.
\end{prop}

\begin{proof}
One of the implications is obvious. Indeed, if $m \subseteq n$, any subbasic open $\tilde U$ which contains $m$ must also contain $n$, for if $U$ intersects $m$ it also intersects $n$. This result can be extended to arbitrary opens, as if $W$ is an open in $\Max V$, and $m \in W$, then there exists an intersection of subbasic opens $B = \tilde U_1 \cup \dots \tilde U_k$ with $m \in B \subseteq W$, and trivially $n \in B \subseteq W$ as well.

Now, suppose that $m$ is \emph{not} a subset of $n$. We will construct an open which contains $m$ but not $n$.

Let $U$ be the complement of $n$. Since we are in finite dimension, this is an open set, so that $\tilde U$ is an open set in $\Max V$. Then, $n \not \in \tilde U$, and furthermore the hypothesis that $m \nsubseteq n$ is equivalent to the claim that $m \cap U \neq \emptyset$, and so $m \in \tilde U$.
\end{proof}

With this in mind, properties \ref{leastelem} and \ref{binsup} become trivial. The least element is simply the zero subspace, and binary suprema are given by subspace sums. Slightly less trivial is \ref{contsup}:

\begin{prop}
Let $V$ be a finite dimensional complex vector space. Then, the operation of subspace addition (which coincides with the join $\vee$ in the specialization order)
\[ + \colon \Max A \times \Max A \to \Max A\]
is continuous.
\end{prop}

\begin{proof}
To show that subspace addition is continuous, by unfurling the definition of product topology and subbasis it suffices to prove the following. Let $m,n \in \Max V$, and let $\tilde U$ be a subbasic neighborhood of $m+n$. Then, we wish to show that there exist neighborhoods $V$ and $W$ of $m$ and $n$ such that, for all $m' \in V$ and $n' \in W$, $m'+n' \in \tilde U$.

To this effect, let us introduce an auxiliary tool into the problem. Since $V$ is a finite dimensional complex vector space, we may introduce on it a norm (simply pick an arbitrary basis and take the Euclidean norm making it an orthonormal basis), and it is known that all norms are equivalent on finite dimensional vector spaces, so that this norm generates the topology of $V$.

Now, suppose that $\tilde U$ is a subbasic neighborhood of $m+n$. Then, there exists some point $x+y \in U$, with $x \in m$ and $y \in n$. Consequently, some ball around $x+y$ is contained in $U$, with a positive radius $\delta$. That said, we may now define $V_0$ and $W_0$ as balls, around $x$ and $y$ respectively, of radius $\delta/2$. Then, it is trivial to check that $V = \tilde{V_0}$ and $W = \tilde{W_0}$ are the desired neighborhoods of $m$ and $n$.
\end{proof}

\subsection{The Operations}

We now turn to showing the properties regarding the composition on $\Max A$, which is the one induced from matrix multiplication, as well as the involution, which is induced from matrix adjunction.

\begin{prop}
The induced composition on $\Max A$ satisfies property \ref{binop}, that is: it is continuous, associative, distributes over $\lor$ and $0p = 0$ for all $p$.
\end{prop}

\begin{proof}
Associativity and $0p = 0$ are both trivial to prove, using the following characterization of the operation:
\[mn = \{\, x_1 y_1 + \dots + x_k y_k \mid x_i \in m, y_i \in n \,\}.\]

Distributivity is also easy, as we have already seen that $m \lor n = m + n$. Therefore, the only thing left to show is that composition is continuous in $\Max A$.

As in the proof of continuity of the join, it suffices to show: If $m,n \in \Max A$ and $U$ is an open in $A$ such that $mn \in \tilde U$, there exists a neighborhood $V$ of $m$ and a neighborhood $W$ of $n$ such that for all $m' \in V$ and $n' \in W$ we have $m'n' \in \tilde U$. The rest of the proof is also very simple, stemming from the continuity of matrix multiplication, with a minor change due to the fact that the elements of $mn$ are \emph{sums} of pairwise products.

In short: pick some element of $mn$ which is in $U$. Say that such an element is $p = x_1 y_1 \dots + x_k y_k$; since $U$ is open, some ball of radius $\varepsilon$ around $p$ is contained in $U$. Now, by continuity of matrix multiplication, we may find some $\delta_1$ such that, if $x' \in B_{\delta_1}(x_1)$ and $y' \in B_{\delta_1}(y_1)$, then $x' y' \in B_{\varepsilon/k} (x_1 y_1)$. Repeat for the other indices, finding $\delta_2, \dots, \delta_k$. Finally, we may find our neighborhood of $m$ as
\[V = \widetilde{B_{\delta_1}(x_1)} \cap \dots \cap \widetilde{B_{\delta_k}(x_k)},\]
and a similar construction yields $W$. The proof that for all $m' \in V$ and $n' \in W$ we have $m' n' \in \tilde U$ is simple repeated application of the triangle inequality and is left to the reader.
\end{proof}

The proof of continuity of the involution is also similar and left to the reader:

\begin{prop}
The involution on $\Max A$ induced by matrix adjunction is continuous.
\end{prop}

There are only three properties left to show: \ref{msober} ($\Max A$ is a sober topological space), \ref{inv2} ($(mn)^* = n^* m^*$) and \ref{symmetry} (If $m m^* m \leq m$ then $m m^* m = m$). Even though the last two are both related to the operations of involution and composition, we delegate the proof of \ref{symmetry} to the next section, as it is not that simple.

We then conclude this section with the proof of
\begin{prop}
The involution on $\Max A$ satisfies
\[ (mn)^* = n^* m^*.\]
\end{prop}

\begin{proof}
A generic element of $(mn)^*$ is of the form
\[(x_1 y_1 + \dots + x_k y_k)^* = y_1^* x_1^* + \dots + y_k^* x_k^*,\]
which is evidently an element of $n^* m^*$. The other inclusion is equally easy.
\end{proof}

\section{Symmetry}

In this section we show that for an algebra of matrices $A$, the space $\Max A$ satisfies property \ref{symmetry} of the definition of measurement space, that is:
\begin{prop}\label{propsymmetry}
If $m \in \Max A$ satisfies $m m^* m \leq m$, then $m m^* m = m$.
\end{prop}

To prove this, we actually prove a rather stronger general statement:

\begin{theorem}\label{propstrongsymmetry}
If $m \in \Max A$, then $\dim(m m^* m) \geq \dim(m)$.
\end{theorem}

\begin{proof}[Theorem \ref{propstrongsymmetry} implies Proposition \ref{propsymmetry}]
Let $m \in \Max A$ satisfy $m m^* m \leq m$. Recall that the (specialization) order on $\Max A$ is the subset order, so we are assuming that $m m^* m$ is a subspace of $m$. However, proposition \ref{propstrongsymmetry} tells us that $m m^* m$ is a subspace of $m$, with dimension at least $\dim(m)$. Consequently, basic linear algebra tells us that these two spaces must coincide.
\end{proof}

In preparation for the proof of theorem \ref{propstrongsymmetry}, consider the function
\begin{align*}
\rho \colon A &\to A\\
x &\mapsto x x^* x.
\end{align*}

The crux of the proof is that the function $\rho$ is injective. This may not seem obvious at first, but is slightly more believable once one considers the particular case $A = \C$. In this case, $\rho(r \e^{\I \theta}) = r^3 \e^{\I \theta}$, which is a kind of cube but only on the radius. And indeed, even though the cube function is not injective on $\C$, this modification is.

\begin{prop}
The function $\rho$ is injective.
\end{prop}

\begin{proof}
We begin by recalling the spectral theorem on finite-dimensional complex spaces: Any self-adjoint matrix $T$ can be written in the form
\[T = U^* D U,\]
for $U$ a unitary matrix and $D$ a diagonal matrix. With this in mind, suppose that $x$ and $y$ satisfy $\rho(x) = \rho(y)$, that is,
\[x x^* x = y y^* y.\]

Notice that $\rho(x) \rho(x)^* = \rho(y) \rho(y)^*$, or, in other words,
\[(x x^*)^3 = (y y^*)^3.\]

Now, apply the spectral theorem to $T = x x^*$ and $S = y y^*$, writing
\[x x^* = U^* D U, \quad y y^* = U'^* D' U',\]
and conclude therefore that
\[U^* D^3 U = U'^* D'^3 U'.\]

We may rewrite this expression as
\begin{equation}
U'' D^3 = D'^3 U'',\label{eq1}
\end{equation}
for $U'' = U' U^*$. The first part of our proof is to show that \eqref{eq1} implies that $U'' D = D' U''$, and therefore that $x x^* = y y^*$.

Let $w_1, \dots, w_n$ be the column vectors of $U''$. Then, \eqref{eq1} tells us that $D'^3 w_j = D_{jj}^3 w_j$, i.e. $w_j$ is an eigenvector of $D'^3$. Consequently, $w_j$ is also an eigenvector of $D'$, because the indices $k$ such that $(w_j)_k \neq 0$ must be those such that $D'^3_{kk} = D_{jj}^3$, and therefore that $D'_{kk} = D_{jj}$. Then we may compute directly that $D' w_j = D_{jj} w_j$, and hence that $U'' D = D' U''$.

We have now shown that $x x^* = y y^*$. We now show that $x = y$. Note that if $x x^*$ is invertible, the proof is complete, because
\begin{equation}
x = (x x^*)^{-1} x x^* x = (y y^*)^{-1} y y^* y = y. 
\end{equation}

We now work around this problem. Let $x x^* = y y^* = U^* D U$, for $U$ unitary and $D$ diagonal. Then, since $x x^* x = y y^* y$,
\begin{equation}
U^* D U x = U^* D U y \Rightarrow D U x = D U y.
\end{equation}

Let $x' = U x$ and $y' = U y$. Since $U$ is invertible, it suffices to show that $x' = y'$.

For all $k$ such that $D_{kk} \neq 0$ we immediately have $y'_k = x'_k$. On the other hand, if $D_{kk} = 0$, given that
\begin{equation}
D = U x x^* U^* = x' x'^*,
\end{equation}
we get $x'_k = 0$. Likewise, $y'_k = 0$. This completes the proof that $x' = y'$, and hence that $x = y$ and finally that $\rho$ is injective.
\end{proof}

The proof of theorem 1 now follows from the following lemma, which comes from elementary differential geometry.

\begin{lemma}\label{lemma1}
Let $M$ and $N$ be smooth nonempty manifolds, and suppose that $f \colon M \to N$ is an injective smooth function. Then, $\dim N \geq \dim M$.
\end{lemma}

\begin{proof} (Sketch)
Let $p$ be a point where $\dl f$ has maximal rank, say $R$. Then there exists a neighborhood of $p$ on which $\dl f$ has maximal rank. Restrict the function $f$ to this neighborhood, and apply the Rank theorem (5.13 from \cite{leesmooth}) to obtain the existence of coordinate neighborhoods of $p$ and $f(p)$ on which the coordinate representation of $f$ is of the form
\begin{equation}
(x_1, \dots, x_{\dim M}) \mapsto (x_1, \dots, x_R, 0, \dots, 0).
\end{equation}

The injectivity of $f$ guarantees that $R = \dim M$, and clearly $R \leq \dim N$, which completes the proof.
\end{proof}

\begin{proof}[Theorem \ref{propstrongsymmetry}]
First, note that $\rho$ is a smooth function, and we have shown that it is injective. Furthermore, we can see $m$ as a submanifold of $A$ and it is easy to show that $\rho|_m$ is also a smooth function from $m$ to $m m^* m$. Therefore, by lemma \ref{lemma1}, $\dim(m m^* m) \geq \dim(m)$, which completes the proof.
\end{proof}

\section{Sobriety}

We now show that $\Max V$ is a sober topological space, when $V$ is a finite dimensional complex vector space. To do so, we recall the definition: $\Max V$ is said to be sober if the map $x \mapsto \overline{\{x\}}$ which takes the elements of $\Max V$ to its irreducible closed sets is a bijection.

\begin{theorem}\label{thm:sober}
Let $V$ be a finite dimensional vector space. Then, $\Max V$ is a sober topological space.
\end{theorem}

We begin with a standard fact which establishes injectivity of the map $x \mapsto \overline{\{x\}}$.

\begin{lemma}\label{lemma:2}
If $X$ is a $T_0$ topological space, the map $x \mapsto \overline{\{x\}}$ is injective.
\end{lemma}

\begin{proof}
Suppose that $\overline{\{x\}} = \overline{\{y\}}$. Then, any closed set which contains $x$ must also contain $y$ and vice-versa, and therefore the same applies for open sets. In other words, $x$ and $y$ are topologically indistinct, and since $X$ is $T_0$ they must be the same point.
\end{proof}

\begin{lemma}\label{maxist0}
If $V$ is a finite dimensional complex vector space, the space $\Max V$ is $T_0$. More specifically, given any two distinct subspaces of $V$, there exists an open subset of $V$ which intersects exactly one of these subspaces (which then generates a subbasic open which distinguishes the two subspaces).
\end{lemma}

\begin{proof}
Let $m_1$ and $m_2$ be two distinct subspaces of $V$. Without loss of generality, suppose that $m_1$ is not contained in $m_2$. Then, the complement of $m_2$ is an open subset of $V$ which does not intersect $m_2$, but does intersect $m_1$.
\end{proof}

Now, let us investigate surjectivity. To this effect, it is useful to inspect what the closed sets of the form $\overline{\{m\}}$ look like, and then show that any irreducible set is of this form.

\begin{lemma}
The closed set $\overline{\{m\}}$ is the collection of subspaces of $m$.
\end{lemma}

\begin{proof}
First, we show that if $m'$ is a subspace of $m$ then any open subset of $\Max V$ which contains $m'$ also contains $m$. To this effect, it suffices to show that any open subset of $V$ which intersects $m'$ also intersects $m$, but this is obvious.

Now, let us suppose that $m'$ is a subspace of $V$ which is not contained in $m$. Then, the argument used in the proof of lemma \ref{maxist0} provides a neighborhood of $m'$ (in $\Max V$) which does not contain $m$.
\end{proof}

Now, let us investigate the structure of an irreducible closed set.

\begin{lemma}\label{lemma:big}
Let $F$ be an irreducible closed subset of $\Max V$, and let $m$ be an element of $F$ of maximal dimension. Then, $F$ is the collection of subspaces of $m$. In particular, $m$ is uniquely determined by $F$, and $F = \overline{\{m\}}$.
\end{lemma}

\begin{proof}
Defining $m$ as above, it is evident that $F$ contains all subspaces of $m$, given that it contains $\overline{\{m\}}$. Therefore, we suppose that $F$ contains some element $m'$ which is not a subspace of $m$, and we will show that $F$ is in fact reducible, a contradiction with the hypothesis that $F$ is irreducible. Without loss of generality, pick $m'$ of maximal dimension.

The proof now divides into two cases: either $m'$ has the same dimension as $m$, or it has a smaller dimension.

If $\dim m' < \dim m$, we decompose $F = F_0 \cup F_1$, with $F_0 = \overline\{m\}$ and $F_1 = F \setminus \{m\}$. Evidently, $F_0$ is closed and neither $F_0$ or $F_1$ are equal to $F$, so all that remains to show is that $F_1$ is closed. To this effect, note that $F_1 = F \cap G$, where $G$ is the collection of subspaces of $V$ with dimension less than $\dim m$, so it suffices to show that $G$ is closed, i.e. that $G^c$, the collection of spaces whose dimension is at least $\dim m$, is open.

Given some space $w \in G^c$, with $G$ as above, we will find a basic neighborhood of $w$ whose elements are all at least $k$-dimensional, where $k = \dim m$. Indeed, since $\dim w \geq k$, we may find $k$ linearly independent vectors $e_1, \dots, e_k \in w$. Intuitively, small enough perturbations of these vectors are still linearly independent, and so if we consider small enough opens $U_1, \dots, U_k$ around $e_1, \dots, e_k$, any element of $\tilde U_1 \cap \dots \cap \tilde U_k$ will contain $k$ linearly independent vectors, thereby having at least $k$ dimensions and hence being an element of $G^c$.

So, let $e_1, \dots, e_k$ be $k$ linearly independent elements of $V$. Extending these to a basis of $V$ and applying the corresponding isomorphism between $V$ and $\C^n$ (with $n = \dim V$), we may without loss of generality assume that $e_1, \dots, e_k$ are the first $k$ elements of the canonical basis of $\C^n$. For $i = 1, \dots, k$, set $U_i$ equal to the open ball of radius $\frac1k$ around $e_i$ (in the canonical Euclidean norm). Now, we claim that if $v_1, \dots, v_k \in V$ such that $v_i \in U_i$ for $i = 1, \dots, k$ then the $v_i$ are linearly independent. Indeed, consider some linear combination of the $v_i$ that equals zero:
\begin{equation}
z_1 v_1 + \dots + z_k v_k = 0.
\end{equation}

Of the coefficients $z_i$, suppose without loss of generality that $z_1$ is maximal in absolute value. Then, we claim that $z_1 = 0$. To this effect, consider the inner product between the above linear combination and $e_1$:
\begin{equation}\label{eq:thesum}
z_1 \braket{v_1,e_1} + \dots + z_k \braket{v_k, e_1} = 0.
\end{equation}

Now, through application of the Cauchy-Schwarz inequality and seeing the $v_i$ as perturbations of the $e_i$, it is possible to conclude that
\begin{equation}
\braket{v_i, e_j} = \delta_{ij} + E_{ij}, \quad \abs{E_{ij}} < \frac1n.
\end{equation}

Therefore, the sum \eqref{eq:thesum} is, up to an error of absolute value strictly less than $\frac{\abs{z_1} + \dots + \abs{z_k}}k$, equal to $z_1$. Since the absolute value of the error is strictly less than $\abs{z_1}$, \eqref{eq:thesum} implies that $z_1 = 0$.  This completes the proof that $G^c$ is open, and hence that (if $\dim m' < \dim m$) $F$ is not irreducible.

\medskip

Let us now consider the case where $\dim m' = \dim m = k$. In this event, we will prove a property which is reminiscent of the Hausdorff property: If $m, m' \in \Max V$ are distinct elements with the same dimension, there exist neighborhoods $W, W'$ of $m$ and $m'$ respectively whose intersection does not contain any $k$-dimensional element.

This proof will reuse some ideas from the previous case. To begin, consider $e_1, \dots, e_p$ a basis of $m \cap m'$; note that by hypothesis $p < k$. Then, extend it through $e_{p+1}, \dots, e_k$ to a basis of $m$, and through $e_{k+1}, \dots, e_{2k-p}$ to a basis of $m'$.

As above, we may without loss of generality assume that $e_1, \dots, e_{2k-p}$ form a subset of the canonical basis of $\C^n$. Also as above, define $U_i$ as the ball of radius $\frac1{2k-p}$ around $e_i$. To conclude, set
\begin{equation}
\begin{gathered}
W_0 = \tilde U_1 \cap \dots \cap \tilde U_p,\\
W = W_0 \cap \tilde U_{p+1} \cap \dots \cap \tilde U_k, \qquad W' = W_0 \cap \tilde U_{k+1} \cap \dots \cap \tilde U_{2k-p}.
\end{gathered}
\end{equation}

Evidently, $W$ and $W'$ are neighborhoods of $m$ and $m'$ respectively. Moreover, using the same argument as in the previous case, we may conclude every element of $W \cap W' = \tilde U_1 \cap \dots \cap \tilde U_{2k-p}$ has dimension equal to at least $2k-p \geq k+1$. This completes the proof of the `Hausdorff-like property'.

Now we may show that, under the assumption that $\dim m' = \dim m$, $F$ is not irreducible. Indeed, simply set $F = (F \setminus W) \cup (F \setminus W')$.

\medskip

Starting with the assumption that $F \neq \overline{\{m\}}$, we have proven that $F$ is reducible, which yields the desired contradiction and concludes the proof.
\end{proof}

We may now finish the proof of theorem \ref{thm:sober}.

\begin{proof}[$\Max V$ is sober]
Lemmas \ref{lemma:2} and \ref{maxist0} show that the map $m \mapsto \overline{\{m\}}$ is injective, for $m \in \Max V$. Moreover, lemma \ref{lemma:big} establishes surjectivity, as if $F$ is an irreducible closed set it shows that $F = \overline{\{m\}}$, where $m$ is the unique element of $F$ with maximal dimension.
\end{proof}

\section{Conclusion}

We have shown that if $A$ is an involutive algebra of matrices then $\Max A$ satisfies all items in definition \ref{def:ms}, i.e. $\Max A$ is a measurement space.

This theorem extends easily to any finite-dimensional involutive algebra, as it is a standard theorem [reference?] that every finite-dimensional involutive algebra is isomorphic to an algebra of matrices.

This is also true in the infinite-dimensional case, under the hypothesis that $A$ is a $C^*$ algebra, but by that point heavier machinery is necessary to prove the result. We refer the reader to Theorem 4.7 in \cite{measurement2} [more references?].

\nocite{measurement}

\bibliography{bibliography}{}
\bibliographystyle{plain}

\end{document}
