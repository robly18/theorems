\documentclass{article}

\usepackage[utf8]{inputenc}

\usepackage[thmmarks]{ntheorem}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}

\usepackage{enumitem}

\usepackage{braket}

\usepackage{cite}

\usepackage{tikz}


\title{Measurement Spaces in Finite Dimension}
\author{Duarte Maia}

\theoremstyle{plain}
\theoremseparator{.}
\theorembodyfont{\rm}
\newtheorem{problem}{Problem}
\newtheorem{definition}{Definition}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}
\renewtheorem*{prop*}{Proposition}
\newtheorem*{idea}{Idea}

\theoremstyle{nonumberplain}
\theorembodyfont{\upshape}
\theoremheaderfont{\slshape}
\theoremsymbol{\ensuremath{\blacksquare}}
\newtheorem{proof}{Proof}

\DeclareMathOperator{\spann}{span}
\DeclareMathOperator{\ext}{ext}
\DeclareMathOperator{\Max}{Max}
\DeclareMathOperator{\Aut}{Aut}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}


\newcommand{\e}{\mathrm{e}}
\newcommand{\I}{\mathrm{i}}


\newcommand{\HH}{\mathcal{H}}

\newcommand{\ps}{\mathcal{P}}
\newcommand{\pr}{\mathbb{P}}

\newcommand{\id}{\mathrm{id}}

\newcommand{\two}{\mathbf{2}}

\newcommand{\conj}[1]{\overline{#1}}

\begin{document}
\maketitle

\section{Showing that $\Max A$ is a Measurement Space, when $A$ is an Involutive Algebra of Matrices}

First, we recall the definitions at play. Some of these are not done with the greatest generality for the sake of simplicity.

\begin{definition}
Let $V$ be a finite dimensional complex vector space. We denote by $\Max V$ the topological space defined as follows:

\begin{itemize}
\item The points of $\Max V$ are the subspaces of $V$,
\item The topology on $\Max V$ is the one generated by the following subbasis: For each open $U$ of $V$, construct $\tilde U \subseteq \Max V$ as
\[\tilde U = \{\, \text{$m$ subspace of $V$} \mid m \cap U \neq \emptyset\,\}.\]
\end{itemize}
\end{definition}

\begin{definition}\label{defmaxa}
Let $A$ be a finite dimensional involutive complex algebra. In this case, $\Max A$ inherits the following operations from $A$:
\begin{itemize}
\item The multiplication of elements of $A$ induces a multiplication of elements of $\Max A$, by taking pairwise products and then considering the span;
\item The involution of $A$ induces involution on elements of $\Max A$, by taking pointwise involutions.
\end{itemize}
\end{definition}

\begin{definition}
Let $X$ be a topological space. A nonempty closed set $C \subseteq X$ is said to be irreducible if it cannot be written as the union of two closed sets, neither of which is equal to $C$. To each point $x \in X$ corresponds the irreducible closed set $\overline{\{x\}}$. We say that $X$ is sober if this correspondence is a bijection.
\end{definition}

\begin{definition}
Let $X$ be a topological space. We order its points by the specialization order: $x \leq y$ iff every open which contains $x$ also contains $y$. This is a partial order so long as $X$ is $T_0$.
\end{definition}

\begin{definition}
A measurement space is a topological space $M$ such that:
\begin{enumerate}[label=\roman*)]
\item \label{msober} $M$ is sober,
\item \label{leastelem} $M$ contains a least element in the specialization order, called $0$,
\item \label{binsup} The specialization order on $M$ is closed under binary suprema,
\item \label{contsup} The supremum operation $\lor$ is a continuous function $M \times M \to M$,
\item \label{binop} $M$ is equipped with a continuous binary operation called `composition', satisfying the axioms:
\begin{enumerate}
\item \label{assoc} $(mn)p = m(np)$, \quad \textit{(associativity)}
\item \label{dist} $(m \lor n)p = mp \lor np$, \quad \textit{(distributivity)}
\item \label{absorp} $0p = 0$,
\end{enumerate}
\item \label{inv1} $M$ is equipped with a continuous unary operation $(\cdot)^*$ which is an involution,
\item \label{inv2} $(mn)^* = n^* m^*$, and
\item \label{symmetry} If $m m^* m \leq m$ then $m m^* m = m$. \quad \textit{(symmetry)}
\end{enumerate}
\end{definition}

The goal of this chapter is to show the following proposition:

\begin{prop*}
Let $A$ be an involutive algebra of matrices, that is, a linear subspace of $M_{n \times n}(\C)$ which is closed under products and conjugate transposition. Then, $\Max A$, equipped with the operations of definition \ref{defmaxa}, is a measurement space.
\end{prop*}

\subsection{The Specialization Order}

First, we study the specialization order on $\Max A$, in order to prove properties \ref{leastelem}, \ref{binsup} and \ref{contsup}. The following results are valid in the case where $A$ is a finite dimensional vector space; the algebra operations are not relevant.

Indeed, the specialization order is very simply the subset order.

\begin{prop}
Let $m$ and $n$ be elements of $\Max A$, that is, subspaces of $A$. Then, $m \leq n$ iff $m \subseteq n$.
\end{prop}

\begin{proof}
One of the implications is obvious. Indeed, if $m \subseteq n$, any subbasic open $\tilde U$ which contains $m$ must also contain $n$, for if $U$ intersects $m$ it also intersects $n$. This result can be extended to arbitrary opens, as if $W$ is an open in $\Max A$, and $m \in W$, then there exists an intersection of subbasic opens $B = \tilde U_1 \cup \dots \tilde U_k$ with $m \in B \subseteq W$, and trivially $n \in B \subseteq W$ as well.

Now, suppose that $m$ is \emph{not} a subset of $n$. We will construct an open which contains $m$ but not $n$.

Let $U$ be the complement of $n$. Since we are in finite dimension, this is an open set, so that $\tilde U$ is an open set in $\Max A$. Then, $n \not \in \tilde U$, and furthermore the hypothesis that $m \nsubseteq n$ is equivalent to the claim that $m \cap U \neq \emptyset$, and so $m \in \tilde U$.
\end{proof}

With this in mind, properties \ref{leastelem} and \ref{binsup} become trivial. The least element is simply the zero subspace, and binary suprema are given by subspace sums. Slightly less trivial is \ref{contsup}:

\begin{prop}
Let $A$ be a finite dimensional complex vector space. Then, the operation of subspace addition
\[ + \colon \Max A \times \Max A \to \Max A\]
is continuous.
\end{prop}

\begin{proof}
To show that subspace addition is continuous, by unfurling the definition of product topology and subbasis it suffices to prove the following. Let $m,n \in \Max A$, and let $\tilde U$ be a subbasic neighborhood of $m+n$. Then, we wish to show that there exist neighborhoods $V$ and $W$ of $m$ and $n$ such that, for all $m' \in V$ and $n' \in W$, $m'+n' \in \tilde U$.

To this effect, let us introduce an auxiliary tool into the problem. Since $A$ is a finite dimensional complex vector space, we may introduce on it a norm (simply pick an arbitrary basis and take the Euclidean norm making it an orthonormal basis), and it is known that all norms are equivalent on finite dimensional vector spaces, so that this norm generates the topology of $V$.

Now, suppose that $\tilde U$ is a subbasic neighborhood of $m+n$. Then, there exists some point $x+y \in U$, with $x \in m$ and $y \in n$. Consequently, some ball around $x+y$ is contained in $U$, with a positive radius $\delta$. That said, we may now define $V_0$ and $W_0$ as balls, around $x$ and $y$ respectively, of radius $\delta/2$. Then, it is trivial to check that $V = \tilde{V_0}$ and $W = \tilde{W_0}$ are the desired neighborhoods of $m$ and $n$.
\end{proof}

\subsection{The Operations}

We now turn to showing the properties regarding the composition on $\Max A$, which is the one induced from matrix multiplication, as well as the involution, which is induced from matrix adjunction.

\begin{prop}
The induced composition on $\Max A$ satisfies property \ref{binop}, that is: it is continuous, associative, distributes over $\lor$ and $0p = 0$ for all $p$.
\end{prop}

\begin{proof}
Associativity and $0p = 0$ are both trivial to prove, using the following characterization of the operation:
\[mn = \{\, x_1 y_1 + \dots + x_k y_k \mid x_i \in m, y_i \in n \,\}.\]

Distributivity is also easy, as we have already seen that $m \lor n = m + n$. Therefore, the only thing left to show is that composition is continuous in $\Max A$.

As in the proof of continuity of the join, it suffices to show: If $m,n \in \Max A$ and $U$ is an open in $A$ such that $mn \in \tilde U$, there exists a neighborhood $V$ of $m$ and a neighborhood $W$ of $n$ such that for all $m' \in V$ and $n' \in W$ we have $m'n' \in \tilde U$. The rest of the proof is also very simple, stemming from the continuity of matrix multiplication, with a minor change due to the fact that the elements of $mn$ are \emph{sums} of pairwise products.

In short: pick some element of $mn$ which is in $U$. Say that such an element is $p = x_1 y_1 \dots + x_k y_k$; since $U$ is open, some ball of radius $\varepsilon$ around $p$ is contained in $U$. Now, by continuity of matrix multiplication, we may find some $\delta_1$ such that, if $x' \in B_{\delta_1}(x_1)$ and $y' \in B_{\delta_1}(y_1)$, then $x' y' \in B_{\varepsilon/k} (x_1 y_1)$. Repeat for the other indices, finding $\delta_2, \dots, \delta_k$. Finally, we may find our neighborhood of $m$ as
\[V = \widetilde{B_{\delta_1}(x_1)} \cap \dots \cap \widetilde{B_{\delta_k}(x_k)},\]
and a similar construction yields $W$. The proof that for all $m' \in V$ and $n' \in W$ we have $m' n' \in \tilde U$ is simple repeated application of the triangle inequality and is left to the reader.
\end{proof}

The proof of continuity of the involution is also similar and left to the reader:

\begin{prop}
The involution on $\Max A$ induced by matrix adjunction is continuous.
\end{prop}

There are only three properties left to show: \ref{msober} ($\Max A$ is a sober topological space), \ref{inv2} ($(mn)^* = n^* m^*$) and \ref{symmetry} (If $m m^* m \leq m$ then $m m^* m = m$). Even though the last two are both related to the operations of involution and composition, we delegate the proof of \ref{symmetry} to the next section, as it is not that simple.

We then conclude this section with the proof of
\begin{prop}
The involution on $\Max A$ satisfies
\[ (mn)^* = n^* m^*.\]
\end{prop}

\begin{proof}
A generic element of $(mn)^*$ is of the form
\[(x_1 y_1 + \dots + x_k y_k)^* = y_1^* x_1^* + \dots + y_k^* x_k^*,\]
which is evidently an element of $n^* m^*$. The other inclusion is equally easy.
\end{proof}

\section{Symmetry}

In this section we show that for an algebra of matrices $A$, the space $\Max A$ satisfies property \ref{symmetry} of the definition of measurement space, that is:
\begin{prop}\label{propsymmetry}
If $m \in \Max A$ satisfies $m m^* m \leq m$, then $m m^* m = m$.
\end{prop}

To prove this, we actually prove a rather stronger general statement:

\begin{theorem}\label{propstrongsymmetry}
If $m \in \Max A$, then $\dim(m m^* m) \geq \dim(m)$.
\end{theorem}

\begin{proof}[Theorem \ref{propstrongsymmetry} implies Proposition \ref{propsymmetry}]
Let $m \in \Max A$ satisfy $m m^* m \leq m$. Recall that the (specialization) order on $\Max A$ is the subset order, so we are assuming that $m m^* m$ is a subspace of $m$. However, proposition \ref{propstrongsymmetry} tells us that $m m^* m$ is a subspace of $m$, with dimension at least $\dim(m)$. Consequently, basic linear algebra tells us that these two spaces must coincide.
\end{proof}

In preparation for the proof of theorem \ref{propstrongsymmetry}, consider the function
\begin{align*}
\rho \colon A &\to A\\
x &\mapsto x x^* x.
\end{align*}

The crux of the proof is that the function $\rho$ is injective. This may not seem obvious at first, but is slightly more believable once one considers the particular case $A = \C$. In this case, $\rho(r \e^{\I \theta}) = r^3 \e^{\I \theta}$, which is a kind of cube but only on the radius. And indeed, even though the cube function is not injective on $\C$, this modification is.

\begin{prop}
The function $\rho$ is injective.
\end{prop}

\begin{proof}
We begin by recalling the spectral theorem on finite-dimensional complex spaces: Any self-adjoint matrix $T$ can be written in the form
\[T = U^* D U,\]
for $U$ a unitary matrix and $D$ a diagonal matrix. With this in mind, suppose that $x$ and $y$ satisfy $\rho(x) = \rho(y)$, that is,
\[x x^* x = y y^* y.\]

Notice that $\rho(x) \rho(x)^* = \rho(y) \rho(y)^*$, or, in other words,
\[(x x^*)^3 = (y y^*)^3.\]

Now, apply the spectral theorem to $T = x x^*$ and $S = y y^*$, writing
\[x x^* = U^* D U, \quad y y^* = U'^* D' U',\]
and conclude therefore that
\[U^* D^3 U = U'^* D'^3 U'.\]

We may rewrite this expression as
\begin{equation}
D^3 = U''^* D'^3 U'',\label{eq1}
\end{equation}
for $U'' = U' U^*$. The first part of our proof is to show that \eqref{eq1} implies that $D = U''^* D' U''$, and therefore that $x x^* = y y^*$.

Let $w_1, \dots, w_n$ be the column vectors of $U''$. Then, \eqref{eq1} tells us that $\braket{w_i, D'^3 w_j} = 0$ for $i \neq j$, and furthermore $\braket{w_j, D'^3 w_j} = D_{jj}^3$. Consequently, given that $\{w_i\}$ is an orthonormal basis we conclude that $D'^3 w_j = D_{jj}^3 w_j$, i.e. $w_j$ is an eigenvector of $D'^3$. Consequently, $w_j$ is also an eigenvector of $D'$, because the indices $k$ such that $(w_j)_k \neq 0$ must be those such that $D'^3_{kk} = D_{jj}^3$, and therefore that $D'_{kk} = D_{jj}$. In conclusion, $\braket{w_k, D' w_j} = D_{kj}$, i.e. $D = U''^* D' U''$.

We have now shown that $x x^* = y y^*$. We now show that $x = y$. Note that if $x x^*$ is invertible, the proof is complete, because
\begin{equation}
x = (x x^*)^{-1} x x^* x = (y y^*)^{-1} y y^* y = y. 
\end{equation}

We now work around this problem. Let $x x^* = y y^* = U^* D U$, for $U$ unitary and $D$ diagonal. Then, since $x x^* x = y y^* y$,
\begin{equation}
U^* D U x = U^* D U y \Rightarrow D U x = D U y.
\end{equation}

Let $x' = U x$ and $y' = U y$. Since $U$ is invertible, it suffices to show that $x' = y'$.

For all $k$ such that $D_{kk} \neq 0$ we immediately have $y'_k = x'_k$. On the other hand, if $D_{kk} = 0$, given that
\begin{equation}
D = U x x^* U^* = x' x'^*,
\end{equation}
we get $x'_k = 0$. Likewise, $y'_k = 0$. This completes the proof that $x' = y'$, and hence that $x = y$ and finally that $\rho$ is injective.
\end{proof}

The proof of theorem 1 now follows from the following lemma, which comes from elementary differential geometry.

\begin{lemma}\label{lemma1}
Let $M$ and $N$ be smooth nonempty manifolds, and suppose that $f \colon M \to N$ is an injective smooth function. Then, $\dim N \geq \dim M$.
\end{lemma}

\begin{proof} (Sketch)
Let $p$ be a point where $\dl f$ has maximal rank, say $R$. Then there exists a neighborhood of $p$ on which $\dl f$ has maximal rank. Restrict the function $f$ to this neighborhood, and apply the Rank theorem (5.13 from \cite{leesmooth}) to obtain the existence of coordinate neighborhoods of $p$ and $f(p)$ on which the coordinate representation of $f$ is of the form
\begin{equation}
(x_1, \dots, x_{\dim M}) \mapsto (x_1, \dots, x_R, 0, \dots, 0).
\end{equation}

The injectivity of $f$ guarantees that $R = \dim M$, and clearly $R \leq \dim N$, which completes the proof.
\end{proof}

\begin{proof}[Theorem \ref{propstrongsymmetry}]
First, note that $\rho$ is a smooth function, and we have shown that it is injective. Furthermore, we can see $m$ as a submanifold of $A$ and it is easy to show that $\rho|_m$ is also a smooth function from $m$ to $m m^* m$. Therefore, by lemma \ref{lemma1}, $\dim(m m^* m) \geq \dim(m)$, which completes the proof.
\end{proof}

\section{Sobriety}

xyz

\nocite{measurement}

\bibliography{bibliography}{}
\bibliographystyle{plain}

\end{document}
